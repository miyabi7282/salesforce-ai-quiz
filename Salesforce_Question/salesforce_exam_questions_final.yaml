- question_id: 1
  question_text: '顧客には、Data Cloud 組織内で各セグメントが最後に公開された日時を表示できるという要件があります。

    この要件に最もよく対応するためにコンサルタントが推奨すべき 2 つの機能はどれですか?

    2つの回答を選択してください'
  choices:
    A: プロファイルエクスプローラー
    B: 計算された洞察力
    C: ダッシュボード
    D: レポート
  correct_answer: C,D
  japanese_explanation: 'Data Cloud 組織内で各セグメントが最後に公開された日時を確認したいお客様は、ダッシュボードとレポート機能を使用してこの要件を満たすことができます。ダッシュボードは、主要な指標、傾向、比較を表示できるデータの視覚的な表現です。レポートは、詳細、要約、計算を表示できる表形式またはマトリックス形式のデータビューです。ダッシュボードとレポートの両方の機能により、ユーザーはニーズや好みに応じてデータビューを作成、カスタマイズ、共有できます。各セグメントが最後に公開された日時を確認するには、セグメントオブジェクトのセグメント名、公開日、公開ステータスフィールドを表示するダッシュボードまたはレポートを作成できます。また、これらのフィールドでデータをフィルタリング、並べ替え、グループ化、またはグラフ化して、より多くの洞察と分析を得ることもできます。必要に応じて、ダッシュボードまたはレポートデータをスケジュール、更新、またはエクスポートすることもできます。参考資料:
    ダッシュボード、レポート'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 2
  question_text: 'Cumulus Financial は、Data Cloud ユーザー向けに Salesforce CRM アカウント データを国別に分離したいと考えています。

    これを達成するためにコンサルタントは何をすべきでしょうか?'
  choices:
    A: ストリーミング変換を使用して、国に基づいてアカウント データをフィルター処理し、それに応じて個別のデータ モデル オブジェクトにマップします。
    B: データ スペース機能を使用し、国に基づいてアカウント データ レイク オブジェクトにフィルターを適用します。
    C: アカウント オブジェクトで Salesforce 共有ルールを使用して、国に基づいてレコードをフィルタリングおよび分離します。
    D: アカウントの国フィールドに基づいて数式フィールドを使用して、受信レコードをフィルタリングします。
  correct_answer: B
  japanese_explanation: データスペースは、データクラウドユーザーがフィルターと権限に基づいてデータのサブセットを作成できる機能です。データスペースは、地域、事業部門、製品ラインなどのさまざまな基準に基づいてデータを分離するために使用できます。この場合、コンサルタントはデータスペース機能を使用して、アカウントデータレイクオブジェクトに国に基づいてフィルタリングを適用できます。これにより、データクラウドユーザーはそれぞれの国に属するアカウントデータのみにアクセスできるようになります。参考資料：データスペース、データスペースの作成
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 3
  question_text: 'Salesforce CRMのキャンペーンにキャンペーンメンバーをインポートするには、セグメントをAmazon S3にエクスポートする必要があります。エクスポートしたファイルの名前には、Salesforce
    CRMのキャンペーンIDを含める必要があります。

    この結果を達成するための 2 つの方法は何ですか?

    2つの回答を選択してください'
  choices:
    A: アクティベーション名にキャンペーン識別子を含めます。
    B: キャンペーンアクティベーションでキャンペーン識別子を新しい属性としてハードコードします。
    C: ファイル名の指定にキャンペーン識別子を含めます。
    D: セグメント名にキャンペーン識別子を含めます。
  correct_answer: A,C
  japanese_explanation: 'この結果を実現するには、AとCの2つの方法があります。アクティベーション名にキャンペーン識別子を含める方法と、ファイル名の指定にキャンペーン識別子を含める方法です。これらの2つのオプションにより、ユーザーはAmazon
    S3にエクスポートされるファイル名にSalesforce CRMキャンペーンIDを指定できます。アクティベーション名とファイル名の指定はどちらもアクティベーションウィザードで設定可能で、ユーザーはキャンペーン識別子をテキストまたは変数として入力できます。アクティベーション名はファイル名のプレフィックスとして使用され、ファイル名の指定はファイル名のサフィックスとして使用されます。例えば、アクティベーション名が

    「Campaign_123」でファイル名の指定が「{segmentName}_{date}」の場合、結果のファイル名は次のようになります。

    「Campaign_123_SegmentA_2023-12-18.csv」。これにより、ユーザーはキャンペーンに対応するファイルを簡単に識別し、Salesforce
    CRMにインポートできます。

    その他の選択肢は正しくありません。選択肢Bは、キャンペーンIDをキャンペーンアクティベーションの新しい属性としてハードコーディングできないため、正しくありません。キャンペーンアクティベーションには属性はなく、設定のみがあります。選択肢Dは、セグメント名にキャンペーンIDを含めるだけでは不十分であるため、正しくありません。

    セグメント名は、ファイル名の指定で指定されない限り、エクスポートされたファイルのファイル名には使用されません。そのため、ユーザーはファイル名に含まれるキャンペーン識別子を確認できません。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 4
  question_text: '顧客は最近、統合率が上昇していることに気づき、コンサルタントに連絡してその理由を尋ねました。

    この増加の理由として考えられる 2 つのことは何でしょうか?

    2つの回答を選択してください'
  choices:
    A: 既存のプロファイルと大部分が重複する新しいデータ ソースが Data Cloud に追加されました。
    B: ソース システム データ ストリームから重複が削除されました。
    C: 一致するプロファイルの数を減らすために、ID 解決ルールが削除されました。
    D: 一致するプロファイルの数を増やすために、ルールセットに ID 解決ルールが追加されました。
  correct_answer: A,D
  japanese_explanation: '統合率は、Data Cloud で統合プロファイルを作成するためにソースプロファイルが統合される量を測定する指標であり、1
    - (統合プロファイルの数 / ソースプロファイルの数) で計算されます。統合率が高いほど、より多くのソースプロファイルが一致して統合プロファイルに統合され、統合プロファイルの数が少なくなることを意味します。一方、統合率が低いほど、一致するソースプロファイルが少なくなり、統合プロファイルの数が増えることを意味します。最近、お客様の統合率が上昇した理由としては、以下の2つが考えられます。

    Data Cloud には、既存のプロファイルと大部分が重複する新しいデータソースが追加されました。つまり、新しいデータソースには、既存のデータソースのプロファイルと類似または同一のプロファイルが多数含まれることになります。例えば、お客様が新しい
    CRM システムを追加し、そのシステムが古い CRM システムと同じ顧客レコードを持っている場合、新しいデータソースは既存のデータソースと重複することになります。Data
    Cloud は新しいデータソースを取り込む際に、ID 解決ルールセットを使用して重複するプロファイルを照合し、統合されたプロファイルに統合します。これにより、統合率が向上します。

    一致するプロファイルの数を増やすため、ルールセットにアイデンティティ解決ルールが追加されました。これは、お客様がアイデンティティ解決ルールセットを変更し、より多くの一致ルールまたは一致基準を追加することで、より多くのプロファイルを同一個人に属するものとして識別できるようにすることを意味します。例えば、お客様がメールアドレスだけでなく、メールアドレスと電話番号に基づいてプロファイルを一致させる一致ルールを追加した場合、ルールセットは同じメールアドレスと電話番号を持つより多くのプロファイルを一致させることができるため、統合率が向上します。

    アイデンティティ解決の計算された洞察: 統合プロファイルの統合率、アイデンティティ解決ルールセットの構成'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 5
  question_text: 'Northern Trail Outfittersは、毎日新しい顧客データをAmazon S3バケットにアップロードし、Data
    Cloudに取り込みます。このデータに基づいて、過去30日間の顧客あたりの総支出を示すインサイトが生成されます。

    新しくインポートされたデータがどのセグメントでも使用可能であることを確認するには、各プロセスをどの順序で実行する必要がありますか?'
  choices:
    A: データストリームの更新 > アイデンティティ解決 > 計算された洞察
    B: データストリームの更新 > 計算された洞察 > ID解決
    C: 計算された洞察 > データストリームの更新 > ID解決
    D: アイデンティティ解決 > データストリームの更新 > 計算された洞察
  correct_answer: A
  japanese_explanation: '新しくインポートしたデータがどのセグメントでも使用可能であることを確認するには、以下の順序でプロセスを実行する必要があります：データストリームの更新
    > Identity Resolution > Calculated Insight。その理由は次のとおりです。

    要件を理解する

    Northern Trail Outfitters は、毎日新しい顧客データを Amazon S3 バケットにアップロードし、それが Data Cloud
    に取り込まれます。

    過去 30 日間の顧客あたりの総支出を表示するために計算されたインサイトが作成されます。

    目標は、データがセグメントで使用される前に適切に更新、解決、および処理されるようにすることです。

    なぜこのシーケンスなのでしょうか?

    ステップ1: データストリームを更新する

    処理を実行する前に、データストリームを更新して、Amazon S3 バケットから最新のデータを取り込む必要があります。

    これにより、最新の顧客データが Data Cloud で利用できるようになります。

    ステップ2: アイデンティティ解決

    データ ストリームを更新した後、関連するレコードを統合プロファイルにマージするために ID 解決を実行する必要があります。

    このステップにより、顧客データが統合され、分析の準備が整います。

    ステップ3：計算された洞察

    ID 解決が完了すると、計算された洞察が生成され、過去 30 日間の顧客あたりの総支出を計算できるようになります。

    これにより、洞察は最新かつ最も正確なデータに基づくものになります。

    その他のオプションが間違っています:

    B. データ ストリームの更新 > 計算されたインサイト > ID 解決: 計算されたインサイトは統合プロファイルに依存しているため、ID 解決の前に生成することはできません。

    C . 計算されたインサイト > データ ストリームの更新 > ID 解決: 計算されたインサイトには最新のデータと解決済みの ID の両方が必要なので、このシーケンスは無効です。

    D . ID 解決 > データ ストリームの更新 > 計算された洞察: 最初にデータ ストリームを更新して最新のデータを取り込まなければ、ID 解決は実行できません。

    結論

    正しい順序は、「データ ストリームの更新」>「アイデンティティ解決」>「計算されたインサイト」であり、セグメントで使用される前にデータが適切に更新、解決、および処理されることが保証されます。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 6
  question_text: '個人にセグメントを作成するときに、以下に示すように AND でリンクされた 2 つの個別のコンテナーを使用すると、どのような結果になりますか?

    商品 | 個数 | 最小 | 1

    色 | 等しい | 赤

    そして

    商品 | 個数 | 最小 | 1

    PrimaryProductCategory | 等しい | 靴'
  choices:
    A: 少なくとも1つの「赤色」製品を購入し、さらに少なくとも1足の「靴」を購入した個人
    B: 購入時に単一の品目として「赤い靴」を少なくとも1つ購入した個人
    C: 少なくとも1つの「赤い靴」を購入した個人。他には何も購入していない。
    D: 少なくとも1つの「赤」製品を購入した、または少なくとも1組の'靴'
  correct_answer: A
  japanese_explanation: '個人にセグメントを作成する際に、AND でリンクされた 2 つの別々のコンテナを使用する場合、その個人はコンテナ内の両方の条件を満たす必要があります。この場合、個人は色属性が「赤」である商品を少なくとも
    1 つ、主要商品カテゴリ属性が「靴」である商品を少なくとも 1 つ購入している必要があります。これらの商品は同一である必要はなく、同じ取引で購入される必要もありません。したがって、正解は
    A です。

    その他のオプションは、異なる論理演算子または条件を意味しているため、正しくありません。オプション B は、色属性が「赤」で、主要製品カテゴリ属性が「靴」である製品を
    1 つだけ購入した必要があることを意味します。オプション C は、色属性が「赤」で、主要製品カテゴリ属性が「靴」である製品を 1 つだけ購入し、他の製品は購入していない必要があることを意味します。オプション
    D は、色属性が「赤」である製品を 1 つ、または主要製品カテゴリ属性が「靴」である製品を 1 つ、あるいはその両方を購入した必要があることを意味します。これは、AND
    演算子ではなく OR 演算子を使用するのと同じです。

    参考文献:

    * セグメンテーション用のコンテナを作成する

    * データクラウドでセグメントを作成する

    * データクラウドセグメンテーションをナビゲート'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 7
  question_text: DMO を作成するときに、セグメンテーションの属性の値の提案はどこで有効になりますか?
  choices:
    A: データマッピング
    B: データ変換
    C: セグメント設定
    D: データストリームのセットアップ
  correct_answer: C
  japanese_explanation: セグメンテーションにおける属性の値の提案は、セグメントフィルターを作成する際にテキスト項目の可能な値を表示して選択できる機能です。この機能は、データモデルオブジェクト（DMO）レコードホームの各DMO項目に対して有効または無効にできます。値の提案は、組織全体で最大500個の属性に対して有効にできます。提案された値が表示されるまで最大24時間かかる場合があります。セグメントフィルターの作成時に値の提案を使用するには、属性をキャンバスにドラッグし、属性の「値」項目に入力を開始する必要があります。一部の演算子では複数の値を選択することもできます。値の提案は、255文字を超える属性、または1対多（1:N）の関係では利用できません。参考：セグメンテーションにおける値の提案の使用、関連属性の選択に関する考慮事項
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 8
  question_text: Data Cloud が CRM データを取り込む方法に関連する考慮事項のうち正しいものはどれですか?
  choices:
    A: CRMデータは手動で更新できず、次回のスケジュールされた同期まで待つ必要があります。
    B: CRM コネクタの同期時間は、最大 15 分間隔にカスタマイズできます。
    C: 数式フィールドは定期的な同期間隔で更新され、次回の完全更新時に更新されます。
    D: CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。
  correct_answer: D
  japanese_explanation: '正解は D です。CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。

    つまり、CRMデータソースの標準フィールドへの変更は、次回のスケジュールされた同期を待たずに、ほぼ瞬時にData Cloudに反映されます。この機能により、Data
    Cloudはセグメンテーションとアクティベーションに必要な最新かつ正確なCRMデータを保持できます1。

    その他のオプションは、次の理由により正しくありません。

    * A. CRMデータは、データストリーム詳細ページ2の「更新」ボタンをクリックすることで、いつでも手動で更新できます。このオプションは無効です。

    * B. CRMコネクタの同期時間は、最大60分間隔までカスタマイズできます。

    15分間隔3。このオプションは無効です。

    * C. 数式フィールドは定期的な同期間隔ではなく、次回の完全更新時のみ更新されます4。完全更新とは、24時間ごと、または手動でトリガーされたときに実行される完全なデータ取り込みプロセスです。

    このオプションは偽です。

    参考文献:

    * 1: Salesforceヘルプの「Data Cloudでのデータの接続と取り込み」の記事

    * 2: Trailheadのデータクラウドユニットのデータソース

    * 3: Trailheadの管理者向けデータクラウドモジュール

    * 4: Trailheadの[データクラウドの数式フィールド]ユニット

    * : Trailhead の [Data Cloud のデータストリーム] ユニット'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 9
  question_text: 'コンサルタントは、携帯電話番号を含むプロフィール情報を持つデータ ストリームの取り込みを計画しています。

    今後のSMSキャンペーンで電話番号を確実に使用できるようにするには、電話番号フィールドが適切なE164電話番号形式であることを確認する必要があります。しかし、ファイル内の電話番号の形式は様々であるようです。

    さまざまな電話番号の形式が標準化されていることを保証する最も効率的な方法は何ですか?'
  choices:
    A: 形式を標準化するための数式フィールドを作成します。
    B: Data Cloud に送信する前に、ソース システムでデータを編集および更新します。
    C: データ ストリームを作成するときに、PhoneNumber フィールド タイプを割り当てます。
    D: 取り込み後に計算されたインサイトを作成します。
  correct_answer: C
  japanese_explanation: '様々な電話番号形式を標準化するための最も効率的な方法は、データストリームを作成する際にPhoneNumberフィールド型を指定することです。PhoneNumberフィールド型は、電話番号を国際標準の電話番号であるE164形式に自動的に変換する特別なフィールド型です。E164形式は、プラス記号（+）、国番号、国内番号で構成されます。例えば、

    +1-202-555-1234 は、米国の電話番号の E164 形式です。PhoneNumber フィールドタイプを使用することで、コンサルタントは電話番号の一貫性を確保し、将来の
    SMS キャンペーンで使用できるようにすることができます。他のオプションは、より時間がかかり、手動による介入が必要になり、フォーマットの問題を解決できません。参考資料：データストリームのフィールドタイプ、E164
    電話番号形式、Salesforce Data Cloud 試験問題'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 10
  question_text: 'Northern Trail Outfitters (NTO) は、CRM データを Data Cloud に取り込み始める準備を進めています。

    コネクタを設定する際、データ ストリームが初めて展開されるときに、NTO はどのようなタイプの更新を予期する必要がありますか?'
  choices:
    A: 増分
    B: 手動更新
    C: 部分更新
    D: 完全更新
  correct_answer: D
  japanese_explanation: 'データ ストリームのデプロイメント: Salesforce Data Cloud でデータ ストリームを設定する場合、最初のデプロイメントでは包括的なデータ
    ロードが必要です。

    リフレッシュの種類:

    * 増分更新: 前回の更新以降の新規データまたは変更されたデータのみを更新します。

    * 手動更新: ユーザーがデータのロードを手動で開始する必要があります。

    * 部分更新: データのサブセットのみが更新されます。

    * 完全更新: データセット全体をシステムに読み込みます。

    初回のデプロイメント: データ ストリームの最初のデプロイメントでは、ソース システムのすべてのデータが Salesforce Data Cloud に確実に取り込まれるように、完全な更新が必要です。

    参考文献:

    * Salesforceドキュメント: データストリームの設定

    * Salesforce データクラウドガイド'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 11
  question_text: 検出中に、複数のデータ ソースがあり、個人に関するデータを 1 つの統合プロファイルに一致させて調整する必要がある顧客に対して、コンサルタントはどの機能を強調する必要がありますか?
  choices:
    A: データクレンジング
    B: 調和
    C: データ統合
    D: アイデンティティ解決
  correct_answer: D
  japanese_explanation: 'アイデンティティ照合は、データクラウドが複数のデータソースから個人に関するデータを照合し、単一の統合プロファイルに統合する機能です。アイデンティティ照合では、ルールセットを使用して、名前、メールアドレス、電話番号、当事者IDなどの共通属性に基づいて、ソースプロファイルの照合と統合方法を定義します。アイデンティティ照合により、データクラウドは、異なるデータソースやシステムにわたって各顧客の360度ビューを作成できます12。他のオプションは、以下の理由により、この顧客ニーズに最適な機能ではありません。

    * A. データクレンジングとは、重複、欠損値、無効な形式など、データ内のエラーや不整合を検出し、修正するプロセスです。データクレンジングはデータの品質と精度を向上させますが、異なるデータソース間のデータの照合や調整を行うものではありません3。

    * B. ハーモナイゼーションとは、異なるデータソースから取得したデータを標準化し、共通の形式と構造に変換するプロセスです。ハーモナイゼーションによってデータの統合と相互運用性は実現できますが、異なるデータソース間でデータの整合性や調整を行うことはできません4。

    * C. データ統合とは、異なるソースからのデータを単一のデータセットまたはシステムに統合するプロセスです。データ統合によってデータの冗長性と複雑さを軽減できますが、異なるデータソース間のデータのマッチングや調整は行いません5。参考文献：1:
    Data and Identity in Data Cloud | Salesforce Trailhead、2: Data Cloud Identiy Resolution
    | Salesforce AI Research、3: [データクレンジング - Salesforce]、4: [Harmonization - Salesforce]、5:
    [データ統合 - Salesforce]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 12
  question_text: 'Cumulus Financialは、Data Cloudを利用して銀行顧客をセグメント化し、クラウドファイルストレージのアクティベーションを通じてダイレクトメールの配信対象者を絞り込んでいます。また、過去2年間にセグメントに含まれていた個人を分析したいと考えています。

    どの Data Cloud コンポーネントがこれを可能にしますか?'
  choices:
    A: セグメント除外
    B: ネストされたセグメント
    C: セグメントメンバーシップデータモデルオブジェクト
    D: 計算された洞察
  correct_answer: C
  japanese_explanation: 'Data Cloud では、セグメントメンバーシップデータモデルオブジェクトを使用して、個人のセグメントメンバーシップ履歴を分析できます。このオブジェクトには、個人がセグメントに参加または離脱した時期に関する情報が保存されており、レポートやダッシュボードを作成してセグメントのパフォーマンスを時系列で追跡できます。Cumulus
    Financial はこのオブジェクトを使用して、過去 2 年以内にセグメントに所属していた個人をフィルタリングし、他の指標と比較することができます。

    その他のオプションは、この分析を可能にするData Cloudコンポーネントではありません。セグメント除外は、別のセグメントに基づいてセグメントから個人を除外できる機能です。ネストされたセグメントは、論理演算子を使用して他のセグメントから作成されたセグメントです。計算されたインサイトは、既存のデータから数式を使用して作成された派生属性です。

    参照：

    セグメントメンバーシップデータモデルオブジェクト

    データクラウドレポートとダッシュボード

    データクラウドでセグメントを作成する'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 13
  question_text: 'コンサルタントは、セグメント化したい従業員のリストを人事データベースから取り込んでいます。

    このデータを取り込むときにコンサルタントはどのデータ ストリーム カテゴリを選択する必要がありますか?'
  choices:
    A: プロファイルデータ
    B: 連絡先データ
    C: その他のデータ
    D: エンゲージメントデータ
  correct_answer: C
  japanese_explanation: '* データストリームのカテゴリ:

    プロファイル データ: 顧客プロファイルと人口統計情報。

    連絡先データ: 電子メールや電話番号などの連絡先。

    その他のデータ: 他のカテゴリに当てはまらないさまざまなデータ。

    エンゲージメント データ: インタラクションと行動のデータ。

    参照：

    * 従業員データの取り込み:

    従業員データは通常、顧客データ用のプロファイル、連絡先、エンゲージメントのカテゴリには当てはまりません。

    「その他のデータ」は、従業員情報など、顧客固有ではないデータに適しています。

    * 従業員データを取り込む手順:

    Salesforce Data Cloud のデータ取り込み設定に移動します。

    「新しいデータ ストリームの作成」を選択し、「その他のデータ」カテゴリを選択します。

    HR データベースのフィールドを Data Cloud の対応するフィールドにマップします。

    * 実用的な応用:

    例: 企業は従業員データを取り込んで、社内コミュニケーションをセグメント化したり、従業員の指標を分析したりします。

    「その他のデータ」カテゴリを選択すると、顧客以外のデータが正しく管理および利用されるようになります。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 14
  question_text: '顧客は、顧客生涯価値に基づいてユーザーのセグメントを作成したいと考えています。

    ただし、Data Cloud に取り込まれるソース データには、その主要業績評価指標 (KPI) は含まれていません。

    この要件を満たすためにコンサルタントはどのような手順を踏む必要がありますか?'
  choices:
    A: データの取り込み > データモデルへのデータのマッピング > 計算されたインサイトの作成 > セグメンテーションでの使用
    B: 計算されたインサイトの作成 > データモデルへのデータのマッピング > データの取り込み > セグメンテーションでの使用
    C: 計算されたインサイトの作成 > データの取り込み > データをデータモデルにマッピング > セグメンテーションでの使用
    D: データの取り込み > 計算されたインサイトの作成 > データのデータモデルへのマッピング > セグメンテーションでの使用
  correct_answer: A
  japanese_explanation: 顧客生涯価値（CLV）に基づいてユーザーセグメントを作成するには、コンサルタントが「データの取り込み」>「データモデルへのデータのマッピング」>「計算されたインサイトの作成」>「セグメンテーションでの使用」という手順に従う必要があります。これは、最初のステップでデータストリーム1を使用してソースデータをData
    Cloudに取り込むためです。2番目のステップでは、ソースデータをデータモデルにマッピングし、データの構造と属性を定義します2。3番目のステップでは、計算されたインサイトを作成します。これは、ソースデータまたは統合データに基づいて計算される派生属性です3。この場合、計算されたインサイトはCLVであり、販売注文データ4に基づく数式またはクエリを使用して計算できます。4番目のステップでは、計算されたインサイトをセグメンテーションで使用します。セグメンテーションとは、個人またはエンティティの属性と行動に基づいてグループを作成するプロセスです。CLV計算されたインサイトを使用することで、コンサルタントはブランドとの関係の存続期間から予測される収益に基づいてユーザーをセグメント化できます。その他のオプションは、要件を満たすための正しい手順に従っていないため、正しくありません。選択肢Bは不正解です。計算されたインサイトはデータモデルオブジェクト3に依存するため、データの取り込みとマッピング前には作成できません。選択肢Cは不正解です。計算されたインサイトはデータモデルオブジェクト3に依存するため、データのマッピング前には作成できません。選択肢Dは不正解です。計算されたインサイトは正しいデータモデル構造と属性3を反映していない可能性があるため、データのマッピング前に作成することは推奨されません。参考資料：データストリームの概要、データモデルオブジェクトの概要、計算されたインサイトの概要、Salesforceを使用した顧客生涯価値（CLV）の計算、[セグメンテーションの概要]
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 15
  question_text: 'Cumulus Financialは現在、Data Cloudを活用し、S3コネクタを介してバックエンドシステムから取引データをアップサートモードで取り込みています。6ヶ月前の初期設定時に、同社はData
    Cloudにカスタム分類を作成するための数式フィールドを作成しました。現在、より多くの分類に対応するために、この数式を更新する必要があります。

    S3 コネクタを使用する場合、コンサルタントは数式フィールドの更新に関してどのような点に留意する必要がありますか?'
  choices:
    A: Data Cloud は $3 からデータの完全更新を開始し、すべてのレコードの数式を更新します。
    B: Data Cloud は、新しいレコードに対してのみ、今後数式を更新します。
    C: Data Cloud は、upsert タイプのデータ ストリームの数式フィールドの更新をサポートしていません。
    D: Data Cloud は、次回の増分アップサート更新時にすべてのレコードの数式を更新します。
  correct_answer: D
  japanese_explanation: '数式フィールドとは、他のフィールドまたは定数に基づいて値を計算するフィールドです。S3 コネクタを使用して Amazon
    S3 バケットからデータを取り込む場合、Data Cloud は、S3 ソースのデータを格納するデータレイクオブジェクト (DLO) 上の数式フィールドの作成と更新をサポートします。ただし、数式フィールドの更新はすぐには適用されず、データストリームの次回の増分アップサート更新時に適用されます。増分アップサート更新とは、主キーフィールドに基づいて、S3
    ソースから DLO に新しいレコードを追加し、既存のレコードを更新するプロセスです。したがって、コンサルタントは、数式フィールドの更新は新しいレコードと既存のレコードの両方に影響しますが、データストリームの次回の増分アップサート更新後にのみ適用されることを念頭に置く必要があります。Data
    Cloud は S3 からのデータの完全更新を開始せず、新しいレコードに対してのみ数式を更新せず、アップサートタイプのデータストリームに対する数式フィールドの更新をサポートしているため、他のオプションは正しくありません。参考資料:
    数式フィールドの作成、Amazon S3 接続、Data Lake オブジェクト'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 16
  question_text: Salesforce Data Cloud の典型的な使用例は何ですか?
  choices:
    A: Salesforceエコシステム全体でのデータ同期
    B: CRMデータをPromiseに保存する
    C: 複数のプラットフォーム間でのデータの調和
    D: 大規模なパーソナライズメールの送信
  correct_answer: C
  japanese_explanation: 'Salesforce Data Cloud の典型的なユースケースは、複数のプラットフォーム間でのデータの調和です。その理由は次のとおりです。

    Salesforce データクラウドを理解する

    Salesforce Data Cloud は、CRM、Marketing Cloud、外部システム、サードパーティ プラットフォームなどの複数のソースから顧客データを集約、統合、分析するように設計されています。

    その主な目的は、パーソナライズされたエクスペリエンスと実用的な洞察のために顧客データの統合ビューを提供することです。

    複数のプラットフォーム間でデータを調和させる理由

    データの調和：

    Data Cloud は、さまざまなソースからのデータを標準化およびクレンジングすることで、データを調和させます。

    これにより、プラットフォーム間の一貫性と正確性が確保され、組織は顧客データの唯一の信頼できるソースを作成できるようになります。

    ユースケースの調整:

    データの調和は Data Cloud のコア機能であり、提供されるオプションの中で最も関連性の高いユースケースとなります。

    その他のオプションはあまり重要ではありません:

    A . Salesforce エコシステム全体でのデータ同期: Data Cloud は Salesforce 製品と統合されますが、主な焦点は Salesforce
    だけでなく複数のプラットフォームからのデータを統合することにあります。

    B. CRM データをオンプレミスで保存: Data Cloud はクラウドベースのソリューションであり、オンプレミスのストレージをサポートしていません。

    D. パーソナライズされたメールを大規模に送信する: これは、Data Cloud ではなく Marketing Cloud のユースケースです。

    データの調和を実現するための手順

    ステップ1: データの取り込み

    複数のソース (CRM、Marketing Cloud、外部システムなど) から顧客データを Data Cloud に取り込みます。

    ステップ2: データの標準化とクレンジング

    バッチ変換またはストリーミング変換を使用して、形式を標準化し、重複を削除し、データをクレンジングします。

    ステップ3: 統合プロファイルを作成する

    ID 解決を使用して、関連するレコードを 1 つの統合プロファイルにマージします。

    ステップ4: インサイトを有効にする

    調整されたデータを活用して、セグメンテーション、パーソナライゼーション、分析を行います。

    結論

    Salesforce Data Cloud の最も一般的な使用例は、複数のプラットフォーム間でのデータの調和であり、組織が顧客データを効果的に統合して活用できるようにします。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 17
  question_text: どのソリューションが、Marketing Cloud の加入者プロファイル属性を毎日 Data Cloud に取り込む簡単な方法を提供しますか?
  choices:
    A: Automation Studio およびプロファイル ファイル API
    B: マーケティングクラウド接続 API
    C: Marketing Cloud データ拡張機能のデータストリーム
    D: Email Studio スターター データ バンドル
  correct_answer: C
  japanese_explanation: 'Marketing Cloud の購読者プロファイル属性を Data Cloud に日々簡単に取り込むソリューションが、Marketing
    Cloud データ拡張機能「データストリーム」です。Marketing Cloud データ拡張機能「データストリーム」は、Marketing Cloud データ拡張機能から
    Data Cloud データスペースにデータをストリーミングできる機能です。ストリーミングするデータ拡張機能を選択すると、Data Cloud がデータスペース内に対応するデータモデルオブジェクト
    (DMO) を自動的に作成し、更新します。

    お客様は、ユーザーインターフェースまたはAPIを使用して、データ拡張フィールドをDMO属性にマッピングすることもできます。Marketing Cloudデータ拡張のデータストリームを使用すると、コードを記述したり複雑な統合を設定したりすることなく、Marketing
    CloudからData Cloudにサブスクライバープロファイル属性などのデータを取り込むことができます。

    その他のオプションは、Marketing Cloud の購読者プロファイル属性を Data Cloud に日常的に簡単に取り込むことができるソリューションではありません。Automation
    Studio と Profile file API は、Marketing Cloud から外部システムにデータをエクスポートするために使用できるツールですが、スクリプトの作成、ファイル転送の設定、自動化のスケジュール設定など、お客様自身で行う必要があります。Marketing
    Cloud Connect API は、Sales Cloud や Service Cloud などの他の Salesforce ソリューションで Marketing
    Cloud のデータにアクセスするために使用できる API ですが、Data Cloud へのデータのストリーミングはサポートしていません。Email Studio
    Starter Data Bundle は、Email Studio 用のサンプルデータとセグメントを含むデータキットですが、購読者プロファイル属性は含まれておらず、Data
    Cloud へのデータのストリーミングもサポートされていません。

    参考文献:

    * マーケティングクラウドデータ拡張データストリーム

    * データクラウドデータ取り込み

    * [Marketing Cloud データ拡張データストリーム API]

    * [マーケティングクラウドコネクトAPI]

    * [Email Studio スターター データ バンドル]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 18
  question_text: 'Northern Trail Outfittersは毎日、過去24時間の店舗取引の概要をAmazon S3バケット内の新しいファイルにアップロードしています。7日以上経過したファイルは自動的に削除されます。各ファイルには、標準化された命名規則に従ってタイムスタンプが付けられています。

    このデータ ストリームを取り込むときにコンサルタントが設定する必要がある 2 つのオプションはどれですか。

    2つの回答を選択してください'
  choices:
    A: 古いファイルの削除が有効になっていることを確認します。
    B: 更新モードが「Upsert」に設定されていることを確認します。
    C: タイムスタンプを収容するためにファイル名にワイルドカードが含まれていることを確認します。
    D: 更新モードが「完全更新」に設定されていることを確認します。
  correct_answer: B,C
  japanese_explanation: 'Amazon S3 バケットからデータを取り込む場合、コンサルタントは次のオプションを設定する必要があります。

    更新モードは「Upsert」に設定する必要があります。これは、新規レコードと更新されたレコードがData Cloudに追加または更新され、既存のレコードは保持されることを意味します。これにより、データは常に最新の状態になり、ソースとの整合性が確保されます。

    ファイル名には、タイムスタンプに対応するワイルドカードを含める必要があります。つまり、ファイル名のパターンには、タイムスタンプの形式に一致する変数部分を含める必要があります。例えば、ファイル名がstore_transactions_2023-12-18.csvの場合、ワイルドカードはstore_transactions_*.csvとなります。これにより、取り込みプロセスは毎日正しいファイルを識別して処理できるようになります。

    その他のオプションは、このシナリオには必要ありません。

    古いファイルの削除はAmazon S3バケットの機能であり、Data Cloudの取り込みプロセスではありません。Data Cloudはソースからファイルを削除することはなく、取り込み後にソースファイルを削除する必要もありません。

    フルリフレッシュは、Data Cloud 内の既存のレコードをすべて削除し、ソースファイルのレコードに置き換えるリフレッシュモードです。このモードは、特にソースファイルに過去
    24 時間のトランザクションの概要のみが含まれている場合、データの損失と不整合が発生する可能性があるため、このシナリオには適していません。参考：Amazon
    S3 からのデータの取り込み、リフレッシュモード'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 19
  question_text: 'Northern Trail Outfitters (NTO) は、B2C コマース データを Data Cloud に接続し、2
    年間の取引履歴を Data Cloud に取り込むことを望んでいます。

    これを達成するために NTO は何を使うべきでしょうか?'
  choices:
    A: B2Cコマーススターターバンドル
    B: 直接販売注文エンティティの取り込み
    C: 直接販売製品エンティティの取り込み
    D: B2C コマース スターター バンドルとカスタム抽出
  correct_answer: D
  japanese_explanation: 'B2C Commerceスターターバンドルは、B2C Commerceから注文データと商品データをData Cloudに取り込むための事前定義されたデータストリームです。ただし、スターターバンドルはデフォルトで過去90日間のデータのみを取得します。2年間の取引履歴を取り込むには、NTOはB2C
    Commerceから履歴データを含むカスタム抽出を使用し、そのカスタム抽出をソースとして使用するようにデータストリームを設定する必要があります。他の方法では、以下の理由により、この目的を達成できません。

    A. B2C Commerce スターターバンドルは、デフォルトでは過去 90 日間のデータのみを取り込みま す。

    B. 直接販売注文エンティティの取り込みは、B2C CommerceデータをData Cloudに接続するためのサポートされていない方法です。Data CloudはB2C
    Commerceデータへの直接アクセス接続を提供しておらず、データの取り込みのみを提供しています。

    C. 直接販売商品エンティティの取り込みは、B2C CommerceデータをData Cloudに接続するためのサポートされていない方法です。Data CloudはB2C
    Commerceデータへの直接アクセス接続を提供しておらず、データの取り込みのみを提供しています。参考：B2C Commerceデータバンドルの作成 - Salesforce、B2C
    Commerceコネクタ - Salesforce、Salesforce B2C Commerceの料金プランと費用'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 20
  question_text: Interaction SDK または Mobile SDK を介して収集されたデータに対して 15 分間のウィンドウで集計を実行する場合、コンサルタントはどの方法を使用する必要がありますか?
  choices:
    A: バッチ変換
    B: 計算された洞察力
    C: ストリーミングの洞察
    D: 数式フィールド
  correct_answer: C
  japanese_explanation: ストリーミングインサイトは、Interaction SDK または Mobile SDK を介して収集されたデータに対して、15
    分間隔で集計を実行できる手法です。ストリーミングインサイトは、Web、モバイル、IoT デバイスなど、さまざまなソースからのストリーミングデータに基づいて、リアルタイムの指標とインサイトを作成できる機能です。ストリーミングインサイトを使用すると、カウント、合計、平均、最小、最大、パーセンタイルなどの集計ルールを定義し、15
    分間隔でストリーミングデータに適用できます。例えば、ストリーミングインサイトを使用して、ウェブサイトまたはアプリの訪問者数、平均セッション継続時間、コンバージョン率を
    15 分間隔で計算できます。また、ストリーミングインサイトを使用すると、集計データをダッシュボード、グラフ、または表で視覚化して調査することもできます。参考：ストリーミングインサイト、ストリーミングインサイトの作成
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 21
  question_text: '小売顧客はさまざまなソースから顧客データを取得したいと考えています

    そして、アイデンティティ解決を利用して、

    セグメンテーションに使用されます。

    アクティベーション メンバーシップではどのエンティティにセグメント化する必要がありますか?'
  choices:
    A: 加入者
    B: 統合された個体
    C: 統合連絡先
    D: 個人
  correct_answer: B
  japanese_explanation: '正解はB（統合個人）です。統合個人とは、異なるデータソースにまたがる顧客を表すレコードで、ID解決ルールセットを適用することで作成されます。ID解決ルールセットとは、共通属性に基づいて異なるソースのデータをリンクおよびマージする方法を定義する、一致および調整ルールのセットです。Data
    Cloudは、ID解決ルールセットを使用して複数のデータソースにまたがるデータを解決し、データの取得元に関係なく、顧客ごとに1つのレコードを作成できるようにします1。異なるソースから顧客データを取得し、ID解決をセグメンテーションに使用したい小売顧客は、解決済みおよび統合済みの顧客データを含む統合個人エンティティでセグメント化する必要があります。その他の選択肢は、異なるソースにまたがる解決済みの顧客データを表していないため、不正解です。購読者とは、マーケティングコミュニケーションの受信をオプトインした顧客を表すレコードです。統合連絡先とは、特定の事業部門と関係のある顧客を表すレコードです。個人とは、単一のデータソースからの顧客のプロファイルデータを表すレコードです。参考：

    アイデンティティ解決ルールセットの処理結果

    セグメンテーションにおけるデータの影響を考慮する

    Salesforce データクラウド コンサルタント資格取得の準備

    AIベースのID解決：多様な顧客データをリンク'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 22
  question_text: 'ある顧客が、過去30日間に注文を行った顧客の大規模なセグメントを作成し、…から関連属性をアクティベーションに追加しました。Marketing
    Cloudでアクティベーションを確認すると、30日以上前の注文が含まれていることに気付きました。

    この問題を解決するためにコンサルタントは何をすべきでしょうか?'
  choices:
    A: Marketing Cloud Engagement で SQL を使用して、30 日以上経過した注文を削除します。
    B: データ スペース フィッターを適用して、30 日以上経過した注文を除外します。
    C: 購入注文日にフィルターを適用して、30 日以上経過した注文を除外します。
    D: 30 日間のデータのみを含むデータ グラフを使用します。
  correct_answer: C
  japanese_explanation: ''
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 23
  question_text: 信頼に基づくファーストパーティ データ資産を構築するとはどういう意味ですか?
  choices:
    A: 使用に同意し、その見返りに価値を受け取る個人から収集したデータの透明性とセキュリティを確保するため
    B: すべてのコンプライアンス規制に準拠した、信頼できるファーストパーティデータをデータクラウドマーケットプレイスで提供する
    C: 法律で義務付けられているすべての電子メールマーケティングでオプトインの同意が収集されるようにするため
    D: インタビュー、アンケート、世論調査を通じて信頼できる情報源から競合データを入手する
  correct_answer: A
  japanese_explanation: 信頼に基づくファーストパーティデータ資産を構築するということは、顧客や見込み客のプライバシーと嗜好を尊重しながらデータを収集、管理、活用することを意味します。また、データの使用方法、データ共有によるメリット、そしてデータの管理方法について、明確かつ誠実な情報を顧客に提供することも意味します。そうすることで、顧客と相互に有益な関係を築き、責任ある倫理的なデータ利用を信頼してもらえるようになり、より関連性の高いパーソナライズされたエクスペリエンスを提供できるようになります。信頼に基づくファーストパーティデータ資産は、顧客ロイヤルティ、顧客維持率、顧客成長の向上、そしてデータ保護規制や標準への準拠に役立ちます。参考資料：ファーストパーティデータを活用し、強力なデジタルエクスペリエンスを実現する、ファーストパーティデータがデータプライバシーの鍵となる理由、ファーストパーティデータ戦略の構築
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 24
  question_text: '世界的なファッション小売業者は、AMFR、FMFA、APAC 全体でオンライン販売プラットフォームを運営しています。顧客、注文、製品情報のデータ形式は地域によって異なり、コンプライアンス規制では元のデータ
    ソースでデータを変更せずに維持することが求められています。また、リアルタイムのパーソナライゼーションと分析のために、顧客プロファイルの統合ビューも必要です。

    これらの要件を考慮すると、企業は受信データ ストリームを標準化およびクレンジングするためにどのような変換アプローチを実装する必要がありますか?'
  choices:
    A: ストリーミング データ変換を実装します。
    B: バッチデータ変換を実装します。
    C: Apex を使用してデータを変換およびクレンジングします。
    D: Data Cloud に取り込む前にデータを変換します。
  correct_answer: A
  japanese_explanation: ''
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 25
  question_text: 'ある銀行は、ローン申込者と富裕層顧客の顧客データを収集しています。顧客はローン申込者と富裕層顧客の両方である可能性があり、その結果、データが重複することになります。

    コンサルタントはどのようにしてこのデータを Data Cloud に取り込み、マッピングすればよいでしょうか?'
  choices:
    A: データを 2 つの DLO に取り込み、それぞれを個人および連絡先の電子メール DMO にマップします。
    B: データを 2 つの DLO に取り込み、2 つのカスタム DMO にマップします。
    C: データ変換を使用してデータを 1 つの DLO に統合し、それを個々の DMO と連絡先メール DMO にマップします。
    D: データを 1 つの DLO に取り込み、1 つのカスタム DMO にマップします。
  correct_answer: C
  japanese_explanation: ''
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 26
  question_text: 'Data Cloud コンサルタントが、アカウント DMO と連絡先ポイント アドレス DMO 間の新しい 1 対 1 の関係を保存しようとしましたが、エラーが発生します。

    このエラーを修正するにはコンサルタントは何をすべきでしょうか?'
  choices:
    A: 追加フィールドを連絡先アドレス DMO にマップします。
    B: アカウント レコードの合計数が ID 解決に十分な大きさであることを確認します。
    C: アカウントごとに複数の連絡先に対応するために、カーディナリティを多対 1 に変更します。
    D: アカウントを連絡先の電子メールと連絡先の電話にもマッピングします。
  correct_answer: C
  japanese_explanation: '* リレーションシップのカーディナリティ: Salesforce Data Cloud では、データ モデル オブジェクト
    (DMO) 間の正しいリレーションシップのカーディナリティを定義することが、正確なデータ表現と統合に不可欠です。

    * 1 対 1 の関係エラー: アカウント DMO と連絡先ポイント アドレス DMO の関係が 1 対 1 に設定されているため、各アカウントが持つことができる連絡先ポイント
    アドレスは 1 つだけであるために、エラーが発生します。

    * 解決：

    カーディナリティの変更：リレーションシップのカーディナリティを多対1に変更します。これにより、複数の連絡先アドレスを単一のアカウントに関連付けることができ、実際のシナリオをより正確に反映できます。

    手順:

    Data Cloud のデータ モデル構成に移動します。

    アカウント DMO と連絡先アドレス DMO の関係を見つけます。

    関係タイプを 1 対 1 から多対 1 に変更します。

    * 利点：

    正確な表現: アカウントに複数の連絡先がある可能性がある実際のデータ シナリオに対応します。

    エラー解決: エラーを解決し、スムーズなデータ統合を保証します。

    * 参照：

    Salesforce Data Cloud ドキュメント: リレーションシップ

    Salesforce ヘルプ: Data Cloud でのデータモデリング'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 27
  question_text: '顧客は、特定のセグメントのアクティベーションが失敗するたびに通知を受け取る必要があります。

    このユースケースを解決するためにコンサルタントはどの機能を使用する必要がありますか?'
  choices:
    A: フロー
    B: レポート
    C: アクティベーションアラート
    D: ダッシュボード
  correct_answer: C
  japanese_explanation: コンサルタントがこのユースケースを解決するために活用すべき機能は、C. アクティベーションアラートです。アクティベーションアラートとは、セグメントのアクティベーションが失敗または成功した際にユーザーに送信される通知です。アクティベーションアラートは「アクティベーション設定」ページで設定でき、コンサルタントはアラートの受信者、頻度、送信条件を指定できます。アクティベーションアラートは、顧客がアクティベーションのステータスを監視し、発生する可能性のある問題をトラブルシューティングするのに役立ちます。参考：Salesforce
    Data Cloud コンサルタント試験ガイド、アクティベーションアラート
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 28
  question_text: '顧客は、Salesforce CRMの標準連絡先オブジェクトに関連付けられたカスタム顧客メールオブジェクトを保有しています。このカスタムオブジェクトには、アクティベーションに使用する連絡先のメールアドレスが格納されます。

    どのデータ エンティティがマップされますか?'
  choices:
    A: 連絡先
    B: 連絡先メールアドレス
    C: カスタム顧客 Email__c オブジェクト
    D: 個人
  correct_answer: B
  japanese_explanation: 'Contact Point_Email オブジェクトは、Data Cloud 内の個人に関連付けられたメールアドレスを表すデータエンティティです。これは、顧客データの共通エンティティとリレーションシップを定義する標準化されたデータモデルである
    Customer 360 データモデルの一部です。Contact Point_Email オブジェクトは、Salesforce CRM 内のメールアドレスを格納する任意のカスタムオブジェクトまたは標準オブジェクト（カスタム
    Customer Email__c オブジェクトなど）にマッピングできます。その他のオプションは、以下の理由により、マッピングする適切なデータエンティティではありません。

    A. 連絡先オブジェクトは、Salesforce CRMの顧客、パートナー、または競合他社の取引先に関連付けられた個人を表すデータエンティティです。Data
    Cloudのメールアドレスを表すデータエンティティではありません。

    C. カスタム Customer Email__c オブジェクトは、Data Cloud のデータエンティティではなく、Salesforce CRM のカスタムオブジェクトです。Contact
    Point_Email オブジェクトなどの Data Cloud のデータエンティティにマッピングできますが、それ自体はデータエンティティではありません。

    D . 個人オブジェクトは、Data Cloud において固有の個人を表すデータエンティティです。同意とプライバシー設定を管理するための中核エンティティであり、メールアドレス、電話番号、ソーシャルメディアのハンドルなど、1
    つ以上の連絡先に関連付けることができます。Data Cloud においてメールアドレスを表すデータエンティティではありません。参考資料: Customer
    360 データモデル: 個人と連絡先 - Salesforce、Contact Point_Email | Salesforce Platform のオブジェクトリファレンス
    | Salesforce Developers、[連絡先 | Salesforce Platform のオブジェクトリファレンス | Salesforce
    Developers]、[個人 | Salesforce Platform のオブジェクトリファレンス | Salesforce Developers]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 29
  question_text: '顧客は生涯価値について計算された洞察力を持っています。

    計算された洞察の場合、コンサルタントは何に注意する必要がありますか。

    変更が必要ですか?'
  choices:
    A: 新しいディメンションを追加できます。
    B: 既存のディメンションを削除できます。
    C: 既存の対策を削除できます。
    D: 新しい対策を追加できます。
  correct_answer: B
  japanese_explanation: '計算インサイトとは、SQL式を用いてデータから定義・計算される多次元指標です。計算インサイトには、ディメンションとメジャーを含めることができます。ディメンションとは、顧客ID、製品カテゴリ、地域など、データをグループ化またはフィルタリングするために使用されるフィールドです。メジャーとは、売上高、数量、平均注文額など、計算や集計を実行するために使用されるフィールドです。計算インサイトは、SQL式を編集するか、データスペースを変更することで変更できます。ただし、コンサルタントは計算インサイトを変更する際に、以下の制限事項と考慮事項に注意する必要があります12。

    既存のディメンションは削除できません。SQL式からディメンションを削除すると、計算インサイトの実行に失敗し、エラーメッセージが表示されます。これは、そのディメンションが計算インサイトオブジェクトの主キーの作成に使用されているため、削除すると既存のデータとの競合が発生するためです。したがって、正解はBです。

    新しいディメンションを追加できます。SQL式にディメンションを追加すると、計算インサイトが実行され、計算インサイトオブジェクトにそのディメンション用の新しいフィールドが作成されます。ただし、コンサルタントはディメンションを追加しすぎないように注意する必要があります。ディメンションを追加しすぎると、計算インサイトのパフォーマンスとユーザビリティに影響する可能性があります。

    既存のメジャーは削除可能です。SQL式からメジャーを削除すると、計算インサイトが実行され、計算インサイトオブジェクトからそのメジャーのフィールドが削除されます。ただし、コンサルタントは、メジャーを削除すると、計算インサイトを使用している既存のセグメントやアクティベーションに影響する可能性があることに注意する必要があります。

    新しいメジャーを追加できます。SQL式にメジャーを追加すると、計算インサイトが実行され、計算インサイトオブジェクト内にそのメジャー用の新しいフィールドが作成されます。ただし、コンサルタントはメジャーを追加しすぎないように注意する必要があります。計算インサイトのパフォーマンスとユーザビリティに影響を及ぼす可能性があります。参考資料：計算インサイト、データスペースにおける計算インサイト。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 30
  question_text: 'ある企業は顧客データを Marketing Cloud に保存し、Marketing Cloud Connector を使用してデータを
    Data Cloud に取り込みます。

    データ削除または忘れられる権利の要求はどこに提出すればよいですか?'
  choices:
    A: データクラウド設定
    B: データクラウドの個々のデータプロファイルについて
    C: マーケティングクラウドの設定
    D: Consent API 経由
  correct_answer: C
  japanese_explanation: 'データ削除リクエスト: Salesforce Marketing Cloud および Data Cloud を使用している企業にとって、データのプライバシーと削除リクエストの管理は不可欠です。

    Marketing Cloud コネクタ: このコネクタは Marketing Cloud と Data Cloud 間のデータ統合を容易にしますが、データ削除リクエストは特定の手順に従う必要があります。

    Marketing Cloud での削除リクエスト:

    * データ管理: データの削除または忘れられる権利のリクエストは、顧客データが元々保存および管理されている Marketing Cloud 設定を通じて送信されます。

    * 伝播: リクエストが Marketing Cloud で処理されると、変更はコネクタを通じて Data Cloud に伝播されます。

    参考文献:

    * Salesforce Marketing Cloud ドキュメント: データ管理

    * Salesforce データクラウドコネクタガイド'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 31
  question_text: 'Northern Trail Outfitters (NTO) は、メール キャンペーンの特定のセグメントに該当する連絡先のリストを
    Data Cloud コンサルタントに依頼しました。

    コンサルタントはこのリストを NTO にどのように提供すればよいでしょうか?'
  choices:
    A: セグメントを作成し、「ダウンロード」をクリックして、NTO に提供するセグメント メンバーシップの詳細を取得します。
    B: 新しいファイル ストレージ アクティベーション ターゲットを作成し、セグメントを作成してから、新しいアクティベーション ターゲットに対してセグメントをアクティベートします。
    C: セグメントを作成し、アクティベーション ターゲットとして電子メールを選択し、NTO に近いセグメントをアクティベートします。
    D: セグメントを作成し、そのセグメントを NTO の Salesforce CRM に対してアクティブ化します。
  correct_answer: B
  japanese_explanation: 'Data Cloud でのセグメント作成: Salesforce Data Cloud を使用すると、ターゲットを絞ったマーケティング
    キャンペーンの特定の基準に基づいてセグメントを作成できます。

    アクティベーションターゲット：セグメントを作成したら、データを利用できるようにするにはアクティベーションを行う必要があります。セグメントデータの使用方法に応じて、様々なアクティベーションターゲットを設定できます。

    ファイルストレージアクティベーションターゲット：セグメントに適合する連絡先リストを提供するために、ファイルストレージアクティベーションターゲットを作成すると、セグメントデータをファイルとしてエクスポートできます。このファイルは、NTOのメーリングキャンペーンで共有できます。

    プロセス：

    * Salesforce Data Cloud でセグメント基準を定義します。

    * 新しいファイルストレージアクティベーションターゲットを作成します。

    * このターゲットに対してセグメントをアクティブ化すると、セグメント メンバーシップの詳細を含むダウンロード可能なファイルが生成されます。

    参考文献:

    * Salesforce Data Cloud ドキュメント: セグメンテーション

    * Salesforce データクラウドのアクティベーション'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 32
  question_text: 'Cumulus Financialは、Data Cloudを利用して銀行顧客をセグメント化し、クラウドファイルストレージのアクティベーションを通じてダイレクトメールの配信対象者を絞り込んでいます。また、過去2年間にセグメントに含まれていた個人を分析したいと考えています。

    どの Data Cloud コンポーネントがこれを可能にしますか?'
  choices:
    A: ネストされたセグメント
    B: セグメント除外
    C: 計算された洞察
    D: セグメントメンバーシップデータモデルオブジェクト
  correct_answer: D
  japanese_explanation: 'セグメントメンバーシップデータモデルオブジェクトは、特定の期間内にセグメントに所属していた個人を分析できるData
    Cloudコンポーネントです。セグメントメンバーシップデータモデルオブジェクトは、どの個人がどのセグメントに属しているか、またいつセグメントに追加または削除されたかに関する情報を格納するテーブルです。このオブジェクトは、セグメントのサイズ、セグメントの期間、セグメントの重複、セグメントの保持率など、セグメンテーションおよびアクティベーション戦略の有効性を測定するのに役立つ計算されたインサイトを作成するために使用できます。セグメントメンバーシップデータモデルオブジェクトは、セグメント名、セグメントタイプ、セグメントの日付範囲などのセグメントメンバーシップ基準に基づいて、ネストされたセグメントまたはセグメント除外を作成するためにも使用できます。その他のオプションは、過去2年以内にセグメントに所属していた個人を分析できるData
    Cloudコンポーネントではないため、正しくありません。ネストされたセグメントとセグメント除外は、既存のセグメントに基づいてより複雑なセグメントを作成できる機能ですが、セグメントメンバーシップに関する履歴データは提供しません。計算されたインサイトは、データモデルオブジェクトまたはデータレイクオブジェクトから派生したカスタム指標またはメジャーですが、それ自体ではセグメントメンバーシップ情報を保存しません。参照:
    セグメント メンバーシップ データ モデル オブジェクト、計算されたインサイトの作成、ネストされたセグメントの作成'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 33
  question_text: 'コンサルタントは、顧客の注文の住所詳細が統合プロファイルに保存するために最適に選択されていることを確認したいと考えています。

    これを達成するためにコンサルタントは何をすべきでしょうか?'
  choices:
    A: 連絡先アドレスのアドレス詳細を選択します。特定のアドレス属性の照合ルールを「ソース優先度」に変更し、個人DMOを一番下に移動します。
    B: 連絡先アドレスのデフォルトの調整ルールを使用します。
    C: 連絡先アドレスのアドレス詳細を選択します。特定のアドレス属性の照合ルールを「ソース優先度」に変更し、「注文DMO」を最上位に移動します。
    D: 個別のデフォルトの調整ルールをソース優先度に変更します。
  correct_answer: C
  japanese_explanation: '統合プロファイル: Salesforce Data Cloud で統合された顧客プロファイルを作成するには、さまざまなソースからのデータを統合する必要があります。

    照合ルール：これらのルールは、競合するデータが発生した場合にどのデータソースが「最適」であると判断されるかを決定します。照合ルールを変更することで、特定のソースを優先することができます。

    ソースの優先順位: ソースの優先順位を設定するには、特定の属性に対してどのデータ ソースを他のデータ ソースよりも優先させるかを定義する必要があります。

    プロセス：

    * ステップ 1: 調整ルールの Data Cloud 設定にアクセスします。

    * ステップ 2: 連絡先の住所の詳細を選択します。

    * ステップ 3: アドレス属性の調整ルールを「ソース優先度」に変更します。

    * ステップ4：注文DMOを優先リストの一番上に移動します。これにより、顧客の注文の住所情報が優先され、統合プロファイルに保存するのに最適なデータとして選択されます。

    利点：

    * 精度: 統合プロファイルで最も正確で信頼性の高い住所データが使用されるようにします。

    * 関連性: 最も関連性が高く、頻繁に更新されるソース (顧客の注文) を優先します。

    参考文献:

    * Salesforce Data Cloud 調整ルール

    * Salesforce統合顧客プロファイル'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 34
  question_text: 'データ クラウド コンサルタントは、新しいサービスベースのデータ ソースのデータ ストリームを設定中です。

    ケースデータを取り込む場合、どのフィールドをイベント時間フィールドに関連付けることが推奨されますか?'
  choices:
    A: 最終更新日
    B: 解決日
    C: エスカレーション日
    D: 作成日
  correct_answer: A
  japanese_explanation: イベント時間フィールドは、データストリーム内のイベントのタイムスタンプを取得する特別なフィールドタイプです。イベントの時系列を追跡し、時間ベースのセグメンテーションとアクティベーションを可能にするために使用されます。ケースデータを取り込む際に、イベント時間フィールドに関連付ける推奨フィールドは、最終更新日フィールドです。このフィールドはケースの最新の更新を反映し、ケースの期間、解決時間、顧客満足度を測定するために使用できます。解決日、エスカレーション日、作成日などの他のフィールドは、ケースの最新のステータスを取得できないか、すべてのケースに適用できない可能性があるため、イベント時間フィールドには適していません。参考資料：データストリームフィールドタイプ、Salesforce
    Data Cloud 試験問題
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 35
  question_text: 組織は、在庫管理システムからデータ クラウドに在庫レベルを高速かつスケーラブルに、ほぼリアルタイムでストリーミングするために何を使用すればよいでしょうか。
  choices:
    A: クラウドストレージコネクタ
    B: コマースクラウドコネクタ
    C: インジェスチョンAPI
    D: マーケティングクラウドパーソナライゼーションコネクタ
  correct_answer: C
  japanese_explanation: 'Ingestion APIは、あらゆるソースから高速かつスケーラブルにデータをデータクラウドにストリーミングできるRESTful
    APIです。Ingestion APIを使用すると、在庫管理システムからJSONオブジェクトとしてデータクラウドに送信し、データクラウドを使用して在庫データに基づいたデータモデル、セグメント、インサイトを作成できます。Ingestion
    APIはバッチモードとストリーミングモードの両方をサポートし、最大

    1秒あたり10万件のレコードを処理できます。Ingestion APIは、データ検証、暗号化、圧縮、再試行メカニズムなどの機能も提供し、データの品質とセキュリティを確保します。参考資料：Ingestion
    API開発者ガイド、データクラウドへのデータの取り込み'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 36
  question_text: データクラウド コンサルタントは、セグメンテーション中に同意を適切に適用するにはどうすればよいでしょうか?
  choices:
    A: 該当するエンゲージメント チャネルのアクティベーション中に、ゴールデン レコードからの同意ステータスを含めます。
    B: 各セグメントのフィルター条件に、該当するエンゲージメント チャネルのパーティ ID を含めます。
    C: 該当するエンゲージメント チャネルのセグメンテーション中に、統合プロファイルを含めます。
    D: 各セグメントのフィルター条件に、該当するエンゲージメント チャネルの同意ステータスを含めます。
  correct_answer: D
  japanese_explanation: '* Salesforce Data Cloud における同意管理について:

    同意管理は、GDPRやCCPAなどのデータ保護規制へのコンプライアンスを維持するために不可欠です。これにより、顧客データが付与された許可に従って使用されることが保証されます。

    参照：

    * セグメンテーションにおける同意ステータスの役割:

    同意ステータスは、顧客が特定の種類の通信またはデータ処理アクティビティに同意またはオプトインしたかどうかを示します。

    セグメンテーション中に正しい同意ステータスを適用することで、必要な許可を提供した顧客だけが対象キャンペーンに含まれるようになります。

    * セグメンテーションにおける同意ステータスの実装:

    セグメントを作成するときに、フィルター条件に同意ステータスを含めると、同意の設定に基づいてオーディエンスを動的にセグメント化するのに役立ちます。

    これにより、コンプライアンスが確保され、コミュニケーションの関連性とパーソナライゼーションが向上します。

    例: 電子メールによるアウトリーチのマーケティング キャンペーンを作成する場合、セグメントには電子メールによる通信を許可する同意ステータスを持つ顧客のみが含まれます。

    * 実用的な応用:

    Salesforce Data Cloud 内のセグメンテーション ツールに移動します。

    フィルター条件に、エンゲージメント チャネルに関連する同意ステータス属性を追加します。

    準拠した顧客プロファイルのみが含まれるように、値 (例: オプトイン、サブスクライブ済み) を定義します。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 37
  question_text: Data Cloud が CRM データを取り込む方法に関連する考慮事項のうち正しいものはどれですか?
  choices:
    A: CRMデータは手動で更新できず、次回のスケジュールされた同期まで待つ必要があります。
    B: CRM コネクタの同期時間は、最大 15 分間隔にカスタマイズできます。
    C: 数式フィールドは定期的な同期間隔で更新され、次回の完全更新時に更新されます。
    D: CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。
  correct_answer: D
  japanese_explanation: '正解は D です。CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。

    つまり、CRMデータソースの標準フィールドへの変更は、次回のスケジュールされた同期を待たずに、ほぼ瞬時にData Cloudに反映されます。この機能により、Data
    Cloudはセグメンテーションとアクティベーションに必要な最新かつ正確なCRMデータを保持できます1。

    その他のオプションは、次の理由により正しくありません。

    A: CRMデータは、データストリーム詳細ページ2の「更新」ボタンをクリックすることで、いつでも手動で更新できます。このオプションは無効です。

    B: CRMコネクタの同期時間は、最大60分間隔までカスタマイズできます。

    15分間隔3。このオプションは無効です。

    C: 数式フィールドは定期的な同期間隔ではなく、次回の完全更新4時にのみ更新されます。完全更新とは、24時間ごと、または手動でトリガーされたときに実行される完全なデータ取り込みプロセスです。このオプションはFalseです。

    参考文献:

    1: Salesforce ヘルプの「Data Cloud でデータを接続して取り込む」の記事

    2: Trailhead の Data Cloud ユニットのデータソース

    3: Trailheadの管理者向けデータクラウドモジュール

    4: Trailheadの[Data Cloudの数式項目]ユニット

    5: Trailhead の [Data Cloud のデータストリーム] ユニット'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 38
  question_text: 空の値を無視するオプションは、ID 解決で何を行いますか?
  choices:
    A: カスタムマッチルールを実行するときに空のフィールドを無視します
    B: 照合ルールを実行するときに空のフィールドを無視します
    C: アイデンティティ解決ルールを実行するときに、空のフィールドを持つ個々のオブジェクトレコードを無視します。
    D: 標準の一致ルールを実行するときに空のフィールドを無視します
  correct_answer: B
  japanese_explanation: 'アイデンティティ解決の「空の値を無視」オプションを使用すると、調整ルールの実行時に空のフィールドを無視できます。調整ルールは、さまざまなソースの値に基づいて、統合された個人プロファイルの属性の最終的な値を決定するために使用されます。調整ルール内の各属性に対して、「空の値を無視」オプションを
    true または false に設定できます。true に設定すると、調整ルールはその属性の値が空であるソースをスキップし、優先順位の次のソースに進みます。false
    に設定すると、調整ルールはその属性の値が空であるソースを有効なソースと見なし、それを使用して統合された個人プロファイルの属性値を入力します。

    他のオプションは、アイデンティティ解決における「空の値を無視」オプションの動作を正しく説明していません。「空の値を無視」オプションは、異なるソース間で属性に基づいて個人を識別およびリンクするために使用されるカスタム一致ルールおよび標準一致ルールには影響しません。また、「空の値を無視」オプションは、アイデンティティ解決ルールの実行時に空のフィールドを持つ個々のオブジェクトレコードを無視しません。これは、アイデンティティ解決ルールがレコードレベルではなく属性レベルで実行されるためです。

    参考文献:

    * データクラウドアイデンティティ解決調整ルール入力

    * アイデンティティ解決ルールセットを構成する

    * データクラウドにおけるデータとアイデンティティ'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 39
  question_text: 'Northern Trail Outfitters は Data Cloud を実装したいと考えており、いくつかのユースケースを考えています。

    Data Cloud に適していると考えられるユースケースはどれですか?

    2つの回答を選択してください'
  choices:
    A: さまざまなソースからデータを取り込み統合し、顧客IDを調整する
    B: クロスチャネルマーケティングメッセージを作成し、調整する
    C: 調和されたデータを使用して、顧客とビジネスへの影響をより正確に理解する
    D: ビジネスインテリジェンスとITデータ管理ツールを別々に用意する必要がなくなる
  correct_answer: A,C
  japanese_explanation: 'Data Cloudは、Salesforceや外部の様々なソースからデータを接続、準備、調和、統合、クエリ、分析し、それらに基づいて行動するのに役立つデータプラットフォームです。Data
    Cloudに適したユースケースとしては、以下のようなものが挙げられます。

    * 顧客IDを統合するために、様々なソースからデータを取り込み、統合します。Data Cloudは、ストリーミングデータからバッチデータまで、あらゆるデータをSalesforceに取り込み、共通のデータモデルにマッピングするお手伝いをします。また、Data
    Cloudは、異なるチャネルやソースにまたがるIDを解決し、顧客の統合プロファイルを作成するお手伝いもします。

    * 調和されたデータを活用し、顧客とビジネスへの影響をより正確に把握します。Data Cloudは、お客様がデータを利用する前に変換・クレンジングし、計算されたインサイトや関連属性でデータを拡充するお手伝いをします。また、Data
    Cloudは、お客様がデータに基づいてセグメントやオーディエンスを作成し、あらゆるチャネルで活用できるよう支援します。さらに、AIを活用して顧客の行動や成果を予測するお手伝いもします。

    他の2つのオプションは、Data Cloudに適したユースケースとは考えられません。Data Cloudには、クロスチャネルマーケティングメッセージの作成とオーケストレーションの機能はありません。これは通常、Marketing
    Cloudなどの他のSalesforceソリューションで処理されます。また、Data CloudはビジネスインテリジェンスツールやITデータ管理ツールと連携し、それらの機能を補完するように設計されているため、別途ビジネスインテリジェンスツールやITデータ管理ツールを用意する必要がなくなるわけではありません。

    参考文献:

    * データクラウドの仕組みを学ぶ

    * Salesforce Data Cloudについて

    * プラットフォームのユースケースを発見する

    * 一般的なデータ分析のユースケースを理解する'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 40
  question_text: 'ある組織では、ユーザーがオプションの選択リストからテキスト属性を識別して選択できるようにしたいと考えています。

    このユースケースに役立つ Data Cloud の機能はどれですか?'
  choices:
    A: 値の提案
    B: データの調和
    C: 変換式
    D: グローバル選択リスト
  correct_answer: A
  japanese_explanation: 値の提案は、セグメントフィルターを作成する際にテキストフィールドに入力可能な値を表示して選択できるデータクラウド機能です。値の提案は、データモデルオブジェクト（DMO）レコードホームの各DMOフィールドに対して有効または無効にできます。値の提案により、ユーザーは正確な値を入力したり記憶したりすることなく、選択肢からテキスト属性を特定して選択できます。また、値の提案は、セグメントフィルターの一貫性と有効性を確保することで、エラーを削減し、データ品質を向上させることができます。参考資料：セグメンテーションにおける値の提案の使用、関連属性の選択に関する考慮事項
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 41
  question_text: '小売顧客はさまざまなソースから顧客データを取得したいと考えています

    そして、アイデンティティ解決を利用して、

    セグメンテーションに使用されます。

    アクティベーション メンバーシップではどのエンティティにセグメント化する必要がありますか?'
  choices:
    A: 加入者
    B: 統合された個体
    C: 統合連絡先
    D: 個人
  correct_answer: B
  japanese_explanation: '正解はB（統合個人）です。統合個人とは、異なるデータソースにまたがる顧客を表すレコードで、ID解決ルールセットを適用することで作成されます。ID解決ルールセットとは、共通属性に基づいて異なるソースのデータをリンクおよびマージする方法を定義する、一致および調整ルールのセットです。Data
    Cloudは、ID解決ルールセットを使用して複数のデータソースにまたがるデータを解決し、データの取得元に関係なく、顧客ごとに1つのレコードを作成できるようにします1。異なるソースから顧客データを取得し、ID解決をセグメンテーションに使用したい小売顧客は、解決済みおよび統合済みの顧客データを含む統合個人エンティティでセグメント化する必要があります。その他の選択肢は、異なるソースにまたがる解決済みの顧客データを表していないため、不正解です。購読者とは、マーケティングコミュニケーションの受信をオプトインした顧客を表すレコードです。統合連絡先とは、特定の事業部門と関係のある顧客を表すレコードです。個人とは、単一のデータソースからの顧客のプロファイルデータを表すレコードです。参考資料：

    * アイデンティティ解決ルールセットの処理結果

    * セグメンテーションにおけるデータの影響を考慮する

    * Salesforce データクラウドコンサルタント資格取得の準備

    * AIベースのID解決：多様な顧客データをリンク'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 42
  question_text: 'Cumulus Financial のリーダーシップ チームは、過去 5 年間に 25 万ドル以上を預金し、アドバイザリー サービスを利用していない顧客を、来年のすべての新規キャンペーンの中心に据えることを決定しました。

    このユースケースをサポートする機能はどれですか?'
  choices:
    A: 計算された洞察とデータアクション
    B: 計算された洞察とセグメント
    C: ストリーミングの洞察とセグメント
    D: ストリーミングの洞察とデータアクション
  correct_answer: B
  japanese_explanation: 'ユースケースを理解する:

    * 経営陣は、過去 5 年間に 25 万ドル以上を預け入れており、アドバイザリ サービスを利用していない顧客に重点を置きたいと考えています。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 43
  question_text: Data Cloud はどのようにして顧客データの高可用性とフォールト トレランスを確保するのでしょうか?
  choices:
    A: 複数の地域やデータセンターにデータを分散することで
    B: 堅牢なバックアップを備えたデータセンターを使用することで
    C: 自動データ回復手順を実装することにより
    D: データアクセスを必須の担当者に制限することで
  correct_answer: A
  japanese_explanation: '* 高可用性とフォールトトレランスの確保:

    高可用性とは、継続的に動作し、アクセス可能なシステムを指します。一方、フォールト トレランスは、障害が発生した場合でも機能を継続する能力を指します。

    参照：

    * 複数の地域とデータセンターにわたるデータ分散:

    Salesforce Data Cloud は、複数の地理的地域とデータセンターにデータを複製することで高可用性を確保します。この分散により、局所的な障害に伴うリスクが軽減されます。

    1 つのデータ センターがダウンした場合でも、データとサービスは別の場所から引き続き提供されるため、中断のないサービスが保証されます。

    * 地域データ配信のメリット:

    冗長性: 複数のリージョンにデータのコピーを複数保存すると冗長性が確保され、災害復旧に重要になります。

    負荷分散: トラフィックをデータセンター全体に分散して、パフォーマンスを最適化し、待ち時間を削減できます。

    規制コンプライアンス: データをさまざまな地域に保存すると、ローカルのデータ保存要件を満たすのに役立ちます。

    * Salesforce Data Cloud への実装:

    Salesforce は、データの整合性と可用性を維持するために、データ複製とフェイルオーバー メカニズムを含む堅牢なアーキテクチャを活用します。

    このアーキテクチャにより、地域的な障害が発生した場合でも、顧客データは安全に保護され、アクセス可能になります。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 44
  question_text: 'Northern Trail Outfittersは毎日、過去24時間の店舗取引の概要をAmazon S3バケット内の新しいファイルにアップロードしています。7日以上経過したファイルは自動的に削除されます。各ファイルには、標準化された命名規則に従ってタイムスタンプが付けられています。

    このデータ ストリームを取り込むときにコンサルタントが設定する必要がある 2 つのオプションはどれですか。

    2つの回答を選択してください'
  choices:
    A: 古いファイルの削除が有効になっていることを確認します。
    B: 更新モードが「Upsert」に設定されていることを確認します。
    C: タイムスタンプを収容するためにファイル名にワイルドカードが含まれていることを確認します。
    D: 更新モードが「完全更新」に設定されていることを確認します。
  correct_answer: B,C
  japanese_explanation: 'Amazon S3 バケットからデータを取り込む場合、コンサルタントは次のオプションを設定する必要があります。

    * 更新モードは「Upsert」に設定する必要があります。これは、新規レコードと更新されたレコードがData Cloudに追加または更新され、既存のレコードは保持されることを意味します。これにより、データは常に最新の状態になり、ソースとの整合性が確保されます。

    * ファイル名には、タイムスタンプに対応するワイルドカードを含める必要があります。つまり、ファイル名のパターンには、タイムスタンプの形式に一致する変数部分を含める必要があります。例えば、ファイル名がstore_transactions_2023-12-18.csvの場合、ワイルドカードはstore_transactions_*.csvとなります。これにより、取り込みプロセスは毎日正しいファイルを識別して処理できるようになります。

    その他のオプションは、このシナリオには必要ありません。

    * 古いファイルの削除はAmazon S3バケットの機能であり、Data Cloudの取り込みプロセスではありません。Data Cloudはソースからファイルを削除することはなく、取り込み後にソースファイルを削除する必要もありません。

    * フルリフレッシュは、Data Cloud 内の既存のレコードをすべて削除し、ソースファイルのレコードに置き換えるリフレッシュモードです。このシナリオには適していません。特にソースファイルに過去
    24 時間のトランザクションの概要のみが含まれている場合、データの損失と不整合が発生する可能性があります。参考資料: Amazon S3 からのデータの取り込み、リフレッシュモード'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 45
  question_text: 'Northern Trail Outfitters（NTD）は、統合された顧客について、顧客満足度、頻度、金額（RFM）スコアに関する計算されたインサイトを作成します。そして、これらのスコアに基づいてセグメントを作成し、Marketing
    Cloudのアクティベーションターゲットにアクティベートします。

    アクティベーションを構成するときに必要な 2 つのアクションはどれですか。

    2つの回答を選択してください'
  choices:
    A: 追加の属性を追加します。
    B: セグメントを選択します。
    C: 接触点を選択します。
    D: 計算されたインサイトをアクティベーションに追加します。
  correct_answer: B,C
  japanese_explanation: 'Marketing Cloud のアクティベーションターゲットへのアクティベーションを設定するには、セグメントとコンタクトポイントを選択する必要があります。セグメントを選択すると、アクティベーションする統合された個人を指定できます。

    コンタクトポイントを選択すると、セグメントの属性をMarketing Cloudデータエクステンションのフィールドにマッピングできます。これらの属性や計算済みインサイトは既にセグメント定義に含まれているため、アクティベーションで追加属性や計算済みインサイトを追加する必要はありません。参考資料：Marketing
    Cloudアクティベーションターゲットの作成、データクラウドのデータターゲットの種類'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 46
  question_text: 'Cloud Kicks は、過去 7 日以内に自社の Web サイトにアクセスした顧客のセグメントを構築したいと考えています。

    このユースケースに適したエンゲージメント日フィールドのフィルター演算子はどれですか?'
  choices:
    A: 間にある
    B: 最後の数より大きい
    C: 次の日数
    D: 最後の日数
  correct_answer: D
  japanese_explanation: 'フィルター演算子「過去日数」を使用すると、今日から何日前の日付範囲で、日付フィールドをフィルタリングできます。例えば、この演算子を使用して、過去7日間、過去30日間、または任意の日数以内にウェブサイトにアクセスした顧客をフィルタリングできます。この演算子は、現在の日付に基づいて自動的に更新される動的セグメントを作成するのに役立ちます12。参考：

    相対日付フィルターリファレンス

    フィルタリングされたセグメントを作成する'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 47
  question_text: 毎日評価される誕生日キャンペーンのセグメントを作成するには、コンサルタントはどの演算子を使用する必要がありますか?
  choices:
    A: 今日は
    B: 誕生日です
    C: 〜の間
    D: 記念日です
  correct_answer: D
  japanese_explanation: '毎日評価される誕生日キャンペーンのセグメントを作成するには、「記念日」演算子を使用する必要があります。この演算子は、日付フィールドと現在の日付を比較し、年に関係なく月と日が同じ場合にtrueを返します。例えば、日付フィールドが1990-01-01で、現在の日付が2023-01-01の場合、演算子はtrueを返します。これにより、コンサルタントは、現在の日付と同じ日に誕生日を迎えるすべての顧客を含むセグメントを作成でき、セグメントは毎日新しい誕生日で更新されます。他の演算子は、以下の理由により、この目的には最適ではありません。

    A) 「今日」演算子は、日付フィールドと現在の日付を比較し、年を含め日付が一致する場合にtrueを返します。例えば、日付フィールドが1990-01-01で、現在の日付が2023-01-01の場合、この演算子はfalseを返します。この演算子は、現在の日付と同じ年日に生まれた顧客のみを対象としますが、そのような可能性は非常に低いため、誕生日キャンペーンには適していません。

    B）「誕生日」演算子はData Cloudでは有効な演算子ではありません。セグメントキャンバスや計算インサイトエディターでは、この演算子は使用できません。

    C) Is Between演算子は、日付フィールドと日付範囲を比較し、日付が範囲内（両端を含む）にある場合にtrueを返します。例えば、日付フィールドが1990-01-01で、範囲が2022-12-25から2022-12-25の場合、

    2023-01-05 の場合、演算子は true を返します。この演算子は、誕生日が特定の日付範囲内にある顧客のみを対象とし、セグメントは毎日新しい誕生日で更新されないため、誕生日キャンペーンには適していません。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 48
  question_text: どのソリューションが、Marketing Cloud の加入者プロファイル属性を毎日 Data Cloud に取り込む簡単な方法を提供しますか?
  choices:
    A: Automation Studio およびプロファイル ファイル API
    B: マーケティングクラウド接続 API
    C: Marketing Cloud データ拡張機能のデータストリーム
    D: Email Studio スターター データ バンドル
  correct_answer: C
  japanese_explanation: 'Marketing Cloud の購読者プロファイル属性を Data Cloud に毎日簡単に取り込むことができるソリューションが、Marketing
    Cloud データ拡張機能のデータストリームです。Marketing Cloud データ拡張機能のデータストリームは、Marketing Cloud データ拡張機能から
    Data Cloud データスペースにデータをストリーミングできる機能です。ストリーミングするデータ拡張機能を選択すると、Data Cloud によってデータスペース内の対応するデータモデルオブジェクト
    (DMO) が自動的に作成され、更新されます。また、ユーザーインターフェースまたは API を使用して、データ拡張機能フィールドを DMO 属性にマッピングすることもできます。Marketing
    Cloud データ拡張機能のデータストリームを使用すると、コードを記述したり複雑な統合を設定したりすることなく、Marketing Cloud から Data
    Cloud に購読者プロファイル属性などのデータを取り込むことができます。

    その他のオプションは、Marketing Cloud の購読者プロファイル属性を Data Cloud に日常的に簡単に取り込むことができるソリューションではありません。Automation
    Studio と Profile file API は、Marketing Cloud から外部システムにデータをエクスポートするために使用できるツールですが、スクリプトの作成、ファイル転送の設定、自動化のスケジュール設定など、お客様自身で行う必要があります。Marketing
    Cloud Connect API は、Sales Cloud や Service Cloud などの他の Salesforce ソリューションで Marketing
    Cloud のデータにアクセスするために使用できる API ですが、Data Cloud へのデータのストリーミングはサポートしていません。Email Studio
    Starter Data Bundle は、Email Studio 用のサンプルデータとセグメントを含むデータキットですが、購読者プロファイル属性は含まれておらず、Data
    Cloud へのデータのストリーミングもサポートされていません。

    参考文献:

    マーケティングクラウドデータ拡張データストリーム

    データクラウドデータ取り込み

    [Marketing Cloud データ拡張データストリーム API]

    [マーケティングクラウドコネクトAPI]

    [Email Studio スターター データ バンドル]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 49
  question_text: セグメンテーションまたはアクティベーションを実行する場合、データの公開と更新にはどのタイムゾーンが使用されますか?
  choices:
    A: アクティビティ作成時に指定されたタイムゾーン
    B: アクティビティを作成したユーザーのタイムゾーン
    C: データクラウド管理者ユーザーのタイムゾーン
    D: Salesforce Data Cloud 組織によって設定されたタイムゾーン
  correct_answer: D
  japanese_explanation: セグメンテーションまたはアクティベーションを実行する際にデータの公開と更新に使用されるタイムゾーンはDです。Salesforce
    Data Cloud組織によって設定されたタイムゾーンです。このタイムゾーンは、Data Cloudのプロビジョニング時に組織設定で設定され、Data Cloud内のすべてのユーザーとアクティビティに適用されます。このタイムゾーンによって、セグメントの更新スケジュールとアクティベーションの公開スケジュールが決まります。したがって、セグメンテーションとアクティベーションの戦略を計画する際には、Data
    Cloud組織と対象システムまたはチャネル間のタイムゾーン差を考慮することが重要です。参考資料：Salesforce Data Cloudコンサルタント試験ガイド、セグメンテーション、アクティベーション
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 50
  question_text: '顧客はCRMからData Cloudに取り込むためのマスター顧客テーブルを持っています。このテーブルには、氏名、メインのメールアドレス、その他の個人識別情報（PLL）が含まれています。

    ID 解決をサポートするには、フィールドをどのようにマッピングする必要がありますか?'
  choices:
    A: 入力テーブルに直接一致するフィールドを持つ新しいカスタム オブジェクトを作成します。
    B: すべてのフィールドを Customer オブジェクトにマップします。
    C: 名前を個人オブジェクトにマップし、電子メール アドレスを連絡先電話番号電子メール オブジェクトにマップします。
    D: すべてのフィールドを個人オブジェクトにマップし、電子メール アドレスのカスタム フィールドを追加します。
  correct_answer: C
  japanese_explanation: 'Data Cloud で ID 解決をサポートするには、マスター顧客テーブルのフィールドを、この目的のために設計された標準データモデルオブジェクトにマッピングする必要があります。個人オブジェクトは、顧客の名前やその他の個人識別情報
    (PII) を保存するために使用され、連絡先電話番号メールオブジェクトは、顧客の主要なメールアドレスやその他の連絡先情報を保存するために使用されます。これらのオブジェクトは、連絡先情報が個人に属していることを示すリレーションフィールドによってリンクされています。これらのオブジェクトにフィールドをマッピングすることで、Data
    Cloud は ID 解決ルールを使用して、名前とメールアドレスのフィールドに基づいて、さまざまなソースのプロファイルを照合および調整できます。その他のオプションは、標準データモデルに含まれない新しいカスタムオブジェクトを作成するか、すべてのフィールドを
    ID 解決用ではない顧客オブジェクトにマッピングするか、すべてのフィールドを標準のメールアドレスフィールドを持たない個人オブジェクトにマッピングするため、推奨されません。参考資料:
    ID 解決のためのデータモデリング要件、統合された個人プロファイルの作成'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 51
  question_text: 'Cloud Kicksのマーケティングマネージャーは、自社の取引先の企業電話番号をData Cloudに取り込む予定です。電話番号を保存するには、データを「電話」に設定したカスタムフィールドを使用する予定です。

    電話番号を取り込む際に正しい記述はどれですか?'
  choices:
    A: 電話データ型フィールドへの取り込みにテキスト値を受け入れることができます。
    B: Data Cloud は、取り込み時に電話番号の形式を検証します。
    C: 電話番号フィールドは 10 桁の値のみを受け入れます。
    D: 電話番号フィールドを主キーとして使用する必要があります。
  correct_answer: A
  japanese_explanation: 'Salesforce Data Cloud の Phone データ型のカスタムフィールドに電話番号を取り込む場合、正しくはテキスト値も
    phone データ型のフィールドに取り込める、ということになります。その理由は次のとおりです。

    要件を理解する

    Cloud Kicks のマーケティング マネージャーは、電話データ型のカスタム フィールドを使用して、企業の電話番号を Data Cloud に取り込む予定です。

    電話番号が取り込み時にどのように検証され、保存されるかを理解することが重要です。

    テキスト値が受け入れられる理由

    電話データ型の動作:

    Salesforceの電話データ型は、電話番号が通常文字列として保存されるため、テキスト値を受け入れます（例：

    「+1-800-555-1234」）。

    このフィールドは電話番号用に設計されていますが、取り込み時に厳密な書式設定ルールは適用されません。

    取り込み中の検証:

    Salesforce は、取り込み時に電話番号の形式を検証しません。

    検証は、データがフォーマット規則を適用する下流のシステムまたはアプリケーションで使用される場合にのみ行われます。

    その他のオプションが間違っています:

    B). Data Cloud は取り込み時に電話番号の形式を検証します。これは誤りです。Data Cloud は取り込み時に電話番号の形式を検証しません。

    C) 電話番号フィールドは 10 桁の値のみを受け入れることができます。電話データ型は国際電話番号を含むさまざまな形式をサポートしているため、これは誤りです。

    D) 電話番号フィールドは主キーとして使用する必要があります。電話番号は一意の識別子ではないため、主キーとして使用すべきではないため、これは誤りです。

    電話番号を取得する手順

    ステップ1: カスタムフィールドを作成する

    「オブジェクト マネージャー」>「アカウント」>「フィールドとリレーションシップ」に移動し、電話データ型のカスタム フィールドを作成します。

    ステップ2: データ取り込みを構成する

    ソース データに電話番号がテキスト値として含まれていることを確認します。

    ソースの電話番号フィールドを Data Cloud のカスタム フィールドにマップします。

    ステップ3: データ使用量の検証

    取り込んだデータをテストして、ダウンストリームの要件 (ダイヤル用のフォーマットなど) を満たしていることを確認します。

    結論

    電話番号は文字列として保存され、プロセスの後半で書式の検証が行われるため、テキスト値は電話データ型フィールドに取り込むことができます。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 52
  question_text: 'Northern Trail Outfitters (NTO) は、B2C コマース データを Data Cloud に接続し、2
    年間の取引履歴を Data Cloud に取り込むことを望んでいます。

    これを達成するために NTO は何を使うべきでしょうか?'
  choices:
    A: B2Cコマーススターターバンドル
    B: 直接販売注文エンティティの取り込み
    C: 直接販売製品エンティティの取り込み
    D: B2C コマース スターター バンドルとカスタム抽出
  correct_answer: D
  japanese_explanation: 'B2C Commerceスターターバンドルは、B2C Commerceから注文データと商品データをData Cloudに取り込むための事前定義されたデータストリームです。ただし、スターターバンドルはデフォルトで過去90日間のデータのみを取得します。2年間の取引履歴を取り込むには、NTOはB2C
    Commerceから履歴データを含むカスタム抽出を使用し、そのカスタム抽出をソースとして使用するようにデータストリームを設定する必要があります。他の方法では、以下の理由により、この目的を達成できません。

    * A. B2C Commerce スターター バンドルは、デフォルトでは過去 90 日間のデータのみを取り込みま す。

    * B. 直接販売注文エンティティの取り込みは、B2C Commerceデータの接続方法としてはサポートされていません。

    * Data Cloud を使用。Data Cloud では、B2C Commerce データへの直接アクセス接続は提供されず、データの取り込みのみ提供されます。

    * C. 直接販売商品エンティティの取り込みは、B2C CommerceデータをData Cloudに接続するためのサポートされていない方法です。Data
    CloudはB2C Commerceデータへの直接アクセス接続を提供しておらず、データの取り込みのみを提供しています。参考資料：B2C Commerceデータバンドルの作成
    - Salesforce、B2C Commerceコネクタ - Salesforce、Salesforce B2C Commerceの料金プランと費用'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 53
  question_text: 'コンサルタントは、複数の断片化されたデータ ソースを持つ顧客と Data Cloud の利点について話し合っています。

    顧客データの管理に関してコンサルタントが強調すべき 2 つの機能領域はどれですか?

    2つの回答を選択してください'
  choices:
    A: データの調和
    B: 統合プロファイル
    C: マスターデータ管理
    D: データマーケットプレイス
  correct_answer: A,B
  japanese_explanation: 'データクラウドは、オープンで拡張可能なデータプラットフォームであり、ファーストパーティデータと業界データへの安全なアクセスを実現しながら、よりスマートで効率的なAIを実現します1。コンサルタントが顧客データ管理に関して強調すべき2つの機能領域は次のとおりです。

    * データのハーモナイゼーション：Data Cloudは、複数のソースと形式から取得したデータを共通のスキーマにハーモナイズすることで、顧客データの信頼できる唯一の情報源を実現します1。また、Data
    Cloudはデータ品質ルールと変換を適用し、データの正確性と一貫性を確保します。

    * 統合プロファイル：データクラウドは、メールアドレス、電話番号、Cookie、デバイスID1など、さまざまな識別子にまたがるデータをリンクすることで、顧客と見込み客の統合プロファイルを作成します。統合プロファイルは、チャネルやタッチポイントをまたがる顧客の行動、嗜好、インタラクションを包括的に把握できます。その他の選択肢は、以下の理由により正しくありません。

    * マスターデータ管理：マスターデータ管理（MDM）は、製品、顧客、サプライヤー、位置情報などのマスターデータを、一貫性と信頼性に優れた単一のソースとして作成・管理するプロセスです。Data
    Cloud は MDM 機能を提供していませんが、MDM ソリューションと統合することで顧客データを拡充できます。

    * データマーケットプレイス：データマーケットプレイスは、Data Cloudの機能の一つで、ユーザーはサードパーティプロバイダーから提供される人口統計データ、行動データ、インテントデータなどのデータを発見、アクセス、活用することができます。データマーケットプレイスは、顧客データの管理に関連する機能領域ではなく、顧客データを強化できる外部データソースです。参考資料：

    * Salesforce データクラウド

    * [データクラウドのためのデータハーモナイゼーション]

    * [データクラウドの統合プロファイル]

    * [マスターデータ管理とは]

    * [データクラウドとマスターデータ管理の統合]

    * [データクラウド向けデータマーケットプレイス]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 54
  question_text: 'お客様には2つのData Cloud組織があります。Data Cloud組織の1つで、Amazon S3データストリームとそのマッピングの新しい設定が完了し、テストが完了しました。

    この構成をパッケージ化して顧客の 2 番目の組織に宣伝するには、どのようなことが推奨されますか?'
  choices:
    A: メタデータ API を使用します。
    B: Salesforce CRM コネクタを使用します。
    C: データキットを作成します。
    D: AppExchange アプリケーションとしてパッケージ化します。
  correct_answer: C
  japanese_explanation: '* Data Cloud 構成のプロモーション: 複数の Salesforce Data Cloud 組織にわたって構成を管理する場合は、プロモーション
    プロセスの一貫性と正確性を確保するツールを使用することが重要です。

    * データキット：Salesforce Data Cloud では、データキットを使用して設定をパッケージ化し、プロモートすることができます。これらのキットは、データストリームの定義、マッピング、その他の構成要素をポータブルな形式でカプセル化します。

    * プロセス：

    ソース組織に、Amazon S3 データストリームの構成とマッピングを含むデータキットを作成します。

    ソース組織からデータキットをエクスポートします。

    データ キットをターゲット組織にインポートし、すべての構成が正確に転送されることを確認します。

    * 利点: データ キットを使用すると、移行プロセスが簡素化され、構成エラーのリスクが軽減され、すべての設定とマッピングが新しい組織で一貫して適用されるようになります。

    * 参照：

    Salesforce データクラウド開発者ガイド

    Salesforce データクラウドパッケージ'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 55
  question_text: Data Cloud はデータのプライバシーとセキュリティをどのように確保しますか?
  choices:
    A: 保存時および転送中のデータを暗号化することにより
    B: 同意の参照を強制および制御することにより
    C: オフサイトサーバーにデータを安全に保存することで
    D: データアクセスを承認された管理者に制限することで
  correct_answer: A
  japanese_explanation: '* データクラウドにおけるデータのプライバシーとセキュリティ:

    Salesforce Data Cloud では、データのプライバシーとセキュリティの確保が最も重要です。

    参照：

    * 主なセキュリティ対策:

    保存時および転送中のデータの暗号化:

    データ暗号化により、保存時と送信時の両方で情報が不正アクセスから保護されます。

    同意設定の強制と制御:

    同意管理により、データの使用が顧客の許可と規制要件に準拠していることが保証されます。

    * セキュリティ対策を実施する手順:

    データ暗号化:

    Salesforce Shield を使用して保存データの暗号化を有効にします。

    転送中のデータには TLS/SSL 暗号化が使用されていることを確認します。

    同意管理:

    Data Cloud 内で同意設定を設定して適用します。

    同意記録を定期的に監査し、更新します。

    * 実用的な応用:

    例: 金融機関は暗号化を使用して顧客の財務データを保護し、GDPR に準拠するための同意を管理します。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 56
  question_text: ユーザーが Data Cloud で統合された顧客データを視覚化および分析できるようにするツールはどれですか?
  choices:
    A: Salesforce CLI
    B: ヘロク
    C: タブロー
    D: アインシュタインアナリティクス
  correct_answer: C
  japanese_explanation: 'Salesforce Data Cloud の概要: Salesforce Data Cloud を使用すると、組織は複数のソースからの顧客データを統合して管理し、顧客とのやり取りや行動を包括的に把握できるようになります。

    可視化と分析：Salesforceは、統合されたデータを可視化および分析するために、それぞれ異なる目的を持つ複数のツールを提供しています。特にTableauは、高度な分析機能と可視化機能で知られています。

    Tableau との統合：Tableau は Salesforce と統合されており、ユーザーは詳細かつインタラクティブなビジュアライゼーションを作成できます。Salesforce
    Data Cloud に直接接続し、統合されたデータを取り込んで包括的な分析を行うことができます。

    機能：Tableauは幅広いデータソースとフォーマットをサポートし、ドラッグ＆ドロップ機能で複雑なグラフやダッシュボードを作成できます。そのため、Salesforce
    Data Cloud内で管理される豊富なデータセットを分析するのに最適なツールです。

    参考文献:

    * Salesforce ヘルプ: Tableau 統合

    * Salesforce データクラウドの概要'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 57
  question_text: データ モデル内に矛盾する情報がある場合、アイデンティティ解決では統合された個人の属性をどのように選択するのでしょうか?
  choices:
    A: 追加の接触点を作成する
    B: 調整ルールを活用する
    C: 追加のルールセットを作成する
    D: マッチルールを活用する
  correct_answer: B
  japanese_explanation: アイデンティティ解決とは、異なるソースからのデータを照合および統合することで、個人の統合プロファイルを作成するプロセスです。データモデル内に、同一人物の異なる名前、住所、電話番号など、矛盾する情報が存在する場合、アイデンティティ解決では調整ルールを活用して、統合プロファイルに最も正確で完全な属性を選択します。調整ルールは、最新性、頻度、ソースの優先度、完全性などの基準に基づいて矛盾を解決する方法を定義する設定可能なルールです。例えば、調整ルールでは、統合プロファイルに最も最近使用した名前や最も頻繁に使用される電話番号を選択するように指定できます。調整ルールは、属性レベルまたは連絡先レベルで適用できます。参考：アイデンティティ解決、調整ルール、Salesforce
    Data Cloud 試験問題
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 58
  question_text: 'コンサルタントは、Amazon 53 がアクティブ化したキャンペーンを顧客の送信先システムに統合しています。

    宛先システムがセグメントに関するメタデータを見つけるために、処理用のこの情報は 53 のどのファイルに含まれますか?'
  choices:
    A: .txt ファイル
    B: jsonファイル
    C: .csvファイル
    D: .zipファイル
  correct_answer: B
  japanese_explanation: '処理対象のセグメントに関するメタデータが含まれる Amazon S3 上のファイルは、B. json ファイルです。

    json ファイルは、セグメントが Amazon S3 に対してアクティブ化されたときに csv ファイルとともに生成されるメタデータ ファイルです。

    json ファイルには、セグメント名、セグメント ID、セグメント サイズ、セグメント属性、セグメント フィルター、セグメント スケジュールなどの情報が含まれています。

    宛先システムはこのファイルを使用して、セグメントとそのプロパティを識別し、セグメント データを宛先システム内の対応するフィールドと一致させることができます。

    参考資料: Salesforce Data Cloud Consultant 試験ガイド、Amazon S3 アクティベーション'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 59
  question_text: '顧客は、閲覧放棄行動に基づいてジャーニーをトリガーするための要件を概説しました。コンサルタントは、この要件に基づき、ストリーミングインサイトを使用して、Journey
    Builderへのデータアクションを1時間ごとにトリガーすることを決定しました。

    データアクションが必要な頻度でトリガーされるようにするには、コンサルタントはどのようにソリューションを構成する必要がありますか?'
  choices:
    A: アクティベーションスケジュールを時間ごとに設定します。
    B: データを 1 時間ごとに一括して取り込むように設定します。
    C: 旅程エントリスケジュールを 1 時間ごとに実行するように設定します。
    D: インサイトの集計時間ウィンドウを 1 時間に設定します。
  correct_answer: D
  japanese_explanation: ストリーミングインサイトは、リアルタイムのエンゲージメントイベントから計算され、事前設定されたルールに基づいてデータアクションをトリガーするために使用できます。データアクションは、Data
    CloudからJourney Builderなどの他のシステムにデータを送信するワークフローです。データアクションが1時間ごとにトリガーされるようにするには、コンサルタントはインサイトの集計時間枠を1時間に設定する必要があります。これは、ストリーミングインサイトが過去1時間以内に発生したイベントを評価し、条件が満たされた場合にデータアクションを実行することを意味します。その他のオプションは、ストリーミングインサイトとデータアクションには関係ありません。参考資料：ストリーミングインサイトとデータアクションの制限と動作、ストリーミングインサイト、ストリーミングインサイトとデータアクションのユースケース、Data
    Cloudでのインサイトの使用、最新のMarketing Cloudリリースでキャンペーンを強化できる6つの方法
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 60
  question_text: 'Cumulus Financial のリーダーシップ チームは、過去 5 年間に 25 万ドル以上を預金し、アドバイザリー サービスを利用していない顧客を、来年のすべての新規キャンペーンの中心に据えることを決定しました。

    このユースケースをサポートする機能はどれですか?'
  choices:
    A: 計算された洞察とデータアクション
    B: 計算された洞察とセグメント
    C: ストリーミングの洞察とセグメント
    D: ストリーミングの洞察とデータアクション
  correct_answer: B
  japanese_explanation: 'ユースケースを理解する:

    経営陣は、過去 5 年間に 25 万ドル以上を預け入れており、アドバイザリー サービスを利用していない顧客に重点を置きたいと考えています。

    参考: Salesforce Data Cloud ユースケースドキュメント

    関連する機能:

    計算されたインサイト：この機能は、既存のデータに基づいて指標と値を導き出すのに役立ちます。この例では、過去5年間の預金総額を計算できます。

    セグメント: セグメンテーションにより、総預金額やアドバイザリ サービスの使用状況など、定義された基準に基づいて特定の顧客グループをターゲットにすることができます。

    参考資料: Salesforce 計算インサイトおよびセグメンテーションガイド

    実装手順:

    計算された洞察を作成する:

    Salesforce Data Cloud の Visual Insights Builder に移動します。

    過去 5 年間の各顧客の預金を合計する新しい計算されたインサイトを作成します。

    セグメントを作成する:

    セグメント キャンバスを使用して新しいセグメントを作成します。

    フィルターを適用して、預金額が 250,000 ドルを超える顧客を含め、アドバイザリ サービスを利用している顧客を除外します。

    参考資料: Salesforce Calculated Insights チュートリアルおよびセグメント作成ガイド 実践的な応用:

    例: 追加サービスを利用していない価値の高い顧客を特定し、パーソナライズされたマーケティング キャンペーンでその顧客をターゲットにして、アドバイザリ サービスを促進します。

    参考：Salesforce 高価値顧客セグメンテーションのケーススタディ'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 61
  question_text: '最近、データ クラウドのコンサルタントが、ID 解決プロセスで、電子メール アドレスや電話番号を共有しているが、実際には同一人物ではない個人が照合されていることを発見しました。

    この問題に対処するためにコンサルタントは何をすべきでしょうか?'
  choices:
    A: より厳しい一致基準で既存のルールセットを変更し、ルールセットを実行して更新された結果を確認し、個体が正しく一致するまで必要に応じて調整します。
    B: 一致するルールが少ない新しいルールを作成して実行し、2 つのルールセットを比較して結果を確認して、承認されたら新しいルールセットに移行します。
    C: より厳密な一致基準を持つ新しいルールセットを作成して実行し、2 つのルールセットを比較して結果を確認および検証し、承認されたら新しいルールセットに移行します。
    D: より厳しい一致基準で既存のルールセットを変更し、2 つのルールセットを比較して結果を確認および検証し、承認されたら新しいルールセットに移行します。
  correct_answer: C
  japanese_explanation: 'アイデンティティ解決とは、一致ルールと調整ルールに基づき、異なるデータソースのソースプロファイルを統合された個人プロファイルにリンクするプロセスです。アイデンティティ解決プロセスにおいて、メールアドレスや電話番号を共有しているものの、実際には同一人物ではない個人が一致している場合、一致ルールが緩すぎるため、改善が必要です。この問題に対処する最善の方法は、属性の追加や一致スコアのしきい値の引き上げなど、より厳格な一致基準を持つ新しいルールセットを作成して実行することです。その後、コンサルタントは2つのルールセットを比較して結果を確認し、新しいルールセットによって誤検知が削減され、アイデンティティ解決の精度が向上するかどうかを確認します。新しいルールセットが承認されたら、コンサルタントは新しいルールセットに移行し、古いルールセットを削除できます。既存のルールセットを変更すると、既存の統合プロファイルに影響が及び、データの損失や不整合が発生する可能性があるため、他の選択肢は適切ではありません。一致ルールが少ない新しいルールセットを作成して実行すると、誤検知が増加し、アイデンティティ解決の範囲が狭まる可能性があります。参考資料:
    統合された個人プロファイルの作成、AI ベースの ID 解決: 多様な顧客データのリンク、データ クラウド ID 解決。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 62
  question_text: '高級小売店は、高価値顧客をターゲットとするセグメントを作成し、Marketing Cloud を通じてメールコミュニケーション用に有効化しました。ところが、有効化された顧客数がセグメント数よりも少ないことに気づきました。

    これには何の理由があるのでしょうか?'
  choices:
    A: Marketing Cloud アクティベーションでは頻度上限が適用され、アクティベーションで送信できるレコード数が制限されます。
    B: Data Cloud は、Marketing Cloud のアクティベーションに連絡先の存在を必須とします。個人に関連する連絡先が存在しない場合は、アクティベートされません。
    C: Marketing Cloud のアクティベーションでは、エンゲージメントがなく、過去 6 か月間にメールを開いたりクリックしたりしていない個人が自動的に抑制されます。
    D: Marketing Cloud のアクティベーションでは、Marketing Cloud にすでに存在する個人のみがアクティベートされます。新しいレコードのアクティベーションは許可されません。
  correct_answer: B
  japanese_explanation: Data Cloud では、Marketing Cloud のアクティベーションにコンタクトポイントが必要です。コンタクトポイントとは、個人とメールアドレスを関連付けるレコードです。これにより、個人がメールの受信に同意していること、およびメールアドレスが有効であることが保証されます。個人に関連するコンタクトポイントがない場合、Marketing
    Cloud でアクティベートされません。そのため、アクティベートされた数がセグメント数よりも少なくなる可能性があります。参考：Data Cloud のアクティベーション、Marketing
    Cloud のコンタクトポイント
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 63
  question_text: 'ある組織では、ユーザーがオプションの選択リストからテキスト属性を識別して選択できるようにしたいと考えています。

    このユースケースに役立つ Data Cloud の機能はどれですか?'
  choices:
    A: 値の提案
    B: データの調和
    C: 変換式
    D: グローバル選択リスト
  correct_answer: A
  japanese_explanation: 値の提案は、セグメントフィルターを作成する際にテキストフィールドに入力可能な値を表示して選択できるデータクラウド機能です。値の提案は、データモデルオブジェクト（DMO）レコードホームの各DMOフィールドに対して有効または無効にできます。値の提案により、ユーザーは正確な値を入力したり記憶したりすることなく、選択肢からテキスト属性を特定して選択できます。また、値の提案は、セグメントフィルターの一貫性と有効性を確保することで、エラーを削減し、データ品質を向上させることができます。参考資料：セグメンテーションにおける値の提案の使用、関連属性の選択に関する考慮事項
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 64
  question_text: 'ある顧客では、複数のチームメンバーがセグメントオーディエンスを作成し、それぞれ異なるタイムゾーンで勤務しています。そのうちの1人は、組織のタイムゾーン設定と一致する太平洋標準時タイムゾーンの本社で勤務しています。

    別のチームメンバーは東部標準時でリモート勤務しています。

    セグメントとアクティベーション スケジュール領域で自分のホーム タイム ゾーンが表示されるのはどのユーザーですか?'
  choices:
    A: 太平洋時間帯のチーム メンバー。
    B: 東部標準時のチームメンバー。
    C: どちらのチーム メンバーも、Data Cloud はすべてのスケジュールを GMT で表示します。
    D: チームメンバー両方。データクラウドは、ログインしたユーザーのタイムゾーンに合わせてセグメントとアクティベーションのスケジュールを調整します。
  correct_answer: D
  japanese_explanation: '正解はD（両方のチームメンバー）です。Data Cloudは、セグメントとアクティベーションのスケジュールをログインユーザーのタイムゾーンに合わせて調整します。Data
    Cloudは、ログインユーザーのタイムゾーン設定を使用して、セグメントとアクティベーションのスケジュールを表示します。つまり、組織のタイムゾーン設定や他のチームメンバーの所在地に関係なく、各ユーザーのホームタイムゾーンでスケジュールが表示されます。この機能は、異なるタイムゾーン間でセグメントとアクティベーションをスケジュールする際の混乱やエラーを回避するのに役立ちます。その他の選択肢は、Data
    Cloudのタイムゾーン処理方法を反映していないため、正しくありません。太平洋標準時（Pacific Time Zone）のチームメンバーは、個人のタイムゾーン設定が組織のタイムゾーン設定と一致しない限り、組織のタイムゾーン設定と同じタイムゾーンを表示しません。東部標準時（Eastern
    Time Zone）のチームメンバーは、個人のタイムゾーン設定が組織のタイムゾーン設定と一致しない限り、組織のタイムゾーン設定でスケジュールを表示しません。Data
    CloudはすべてのスケジュールをGMTではなく、ユーザーのローカルタイムゾーンで表示します。参考資料：

    * データクラウドのタイムゾーン

    * ユーザーと組織のデフォルトのタイムゾーンを変更する

    * Salesforce、Google、Outlook のタイムゾーン設定を変更する

    * SalesforceのDateTimeフィールドとタイムゾーン設定'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 65
  question_text: City | Is Equal To | 'San Jose' でフィルタリングしたセグメンテーション基準の結果は何ですか?
  choices:
    A: 「San Jose」、「San Jose」、「san jose」、または「san jose」を含む都市
    B: 「San Jose」または「san jose」のみを含む都市
    C: 「San Jose」または「San Jose」のみを含む都市
    D: 「San Jose」または「san jose」のみを含む都市
  correct_answer: D
  japanese_explanation: 「City | Is Equal To | 'San Jose'」でセグメンテーション条件をフィルタリングした結果は、「San
    Jose」または「san jose」を含む都市のみになります。これは、セグメンテーション条件が大文字と小文字を区別し、アクセント記号も区別するため、フィルターに入力された値と完全に一致する場合にのみ一致します1。したがって、「San
    Jose」、「san jose」、「San Jose」を含む都市は、フィルター値と完全に一致しないため、結果に含まれません。「San Jose」という名前に異なるバリエーションを持つ都市を含めるには、OR演算子を使用して複数のフィルター値を追加する必要があります（例：'San
    Jose' OR 'San Jose' OR 'san jose' OR 'san jose'2）。参考：セグメンテーション条件、セグメンテーション演算子
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 66
  question_text: Data Cloud が CRM データを取り込む方法に関連する考慮事項のうち正しいものはどれですか?
  choices:
    A: CRMデータは手動で更新できず、次回のスケジュールされた同期まで待つ必要があります。
    B: CRM コネクタの同期時間は、最大 15 分間隔にカスタマイズできます。
    C: 数式フィールドは定期的な同期間隔で更新され、次回の完全更新時に更新されます。
    D: CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。
  correct_answer: D
  japanese_explanation: '正解は D です。CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。

    つまり、CRMデータソースの標準フィールドへの変更は、次回のスケジュールされた同期を待たずに、ほぼ瞬時にData Cloudに反映されます。この機能により、Data
    Cloudはセグメンテーションとアクティベーションに必要な最新かつ正確なCRMデータを保持できます1。

    その他のオプションは、次の理由により正しくありません。

    A) CRMデータは、データストリーム詳細ページ2の「更新」ボタンをクリックすることで、いつでも手動で更新できます。このオプションは無効です。

    B). CRMコネクタの同期時間は、15分間隔ではなく、最大60分間隔までカスタマイズできます3。このオプションは無効です。

    C) 数式フィールドは定期的な同期間隔ではなく、次回の完全更新時のみ更新されます4。完全更新とは、24時間ごと、または手動でトリガーされたときに実行される完全なデータ取り込みプロセスです。このオプションは無効です。

    1: Salesforce ヘルプの「Data Cloud でデータを接続して取り込む」の記事

    2: Trailhead の Data Cloud ユニットのデータソース

    3: Trailheadの管理者向けデータクラウドモジュール

    4: Trailheadの[Data Cloudの数式項目]ユニット

    Trailhead の [Data Cloud のデータストリーム] ユニット'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 67
  question_text: 'Cumulus Financial は、2 つ以上の投資信託に投資した個人を含む「Multiple Investments」というセグメントを作成しました。

    同社は、このセグメントに新しい投資信託の提供に関する電子メールを送信する予定であり、各顧客の現在の投資信託投資に関する情報を電子メールの内容に反映させたいと考えています。

    Data Cloud コンサルタントはこのアクティベーションをどのように構成すればよいでしょうか?'
  choices:
    A: 関連属性として「投資信託」に等しいファンドタイプを追加します。追加属性なしで、新しいセグメントに基づいてアクティベーションを設定します。
    B: 複数の投資セグメントを選択し、電子メール連絡先ポイントを選択し、関連属性ファンド名を追加し、ファンド タイプが「投資信託」に等しい関連属性フィルターを追加します。
    C: 複数の投資セグメントを選択し、電子メール連絡先を選択して、関連属性ファンド タイプを追加します。
    D: ターゲット システムでの後処理のために、ファンド名とファンド タイプをデフォルトで含めます。
  correct_answer: B
  japanese_explanation: '各顧客の現在の投資信託に関する情報をメールのコンテンツに反映させるには、データクラウドのコンサルタントがアクティベーションに関連属性を追加する必要があります。関連属性とは、パーソナライズや分析のためにセグメントと共にターゲットシステムに送信できる追加のデータフィールドです。この場合、コンサルタントは顧客が投資している投資信託の名前を含む「ファンド名」属性を追加し、「ファンドタイプ」が「投資信託」に等しいフィルターを適用して、関連データのみが送信されるようにする必要があります。その他のオプションは、以下の理由により正しくありません。

    * A. 「投資信託」に等しいファンドタイプを関連属性として追加するだけでは、メールの内容をパーソナライズするには不十分です。コンサルタントは、顧客が投資している投資信託の具体的な名称を含むファンド名属性も追加する必要があります。

    * C. 関連属性「ファンドタイプ」を追加するだけでは、メールの内容をパーソナライズするには不十分です。コンサルタントは、顧客が投資している投資信託の具体的な名称を含む「ファンド名」属性も追加し、「ファンドタイプ」が「投資信託」に一致するフィルターを適用することで、関連データのみが送信されるようにする必要があります。

    * D. ターゲットシステムでの後処理のために、ファンド名とファンドタイプをデフォルトで含めることは有効なオプションではありません。コンサルタントは、データがターゲットシステムに送信された後ではなく、Data
    Cloudでのアクティベーション設定時に関連属性とフィルターを追加する必要があります。参考資料：アクティベーションへの関連属性の追加 - Salesforce、アクティベーションにおける関連属性
    - Salesforce、Salesforce Data Cloudコンサルタント資格取得の準備'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 68
  question_text: 'コンサルタントはトランザクションデータでデータストリームを設定しています。

    コンサルタントは、どのフィールドタイプを選択すべきでしょうか？

    注文番号のゼロは保持されますか?'
  choices:
    A: テキスト
    B: 数値
    C: 10進数
    D: シリアル
  correct_answer: A
  japanese_explanation: '発注番号の先頭のゼロが保持されるようにするには、フィールド タイプとしてテキストを選択する必要があります。

    これは、テキストフィールドでは英数字が文字列として保存され、先頭や末尾の文字は削除されないためです。一方、数値、小数点、シリアル値フィールドでは数値が数値として保存され、データの表示またはエクスポート時に先頭のゼロが自動的に削除されます123。そのため、テキストフィールドは、発注書番号、郵便番号、電話番号など、元の形式を維持する必要があるデータの保存に適しています。参考資料：

    * フィールドの先頭のゼロは、データエクスポートでは省略されているように見えます

    * CSVファイルをインポートするときに最初の「0」を保持する

    * ゼロで始まる、またはプラス記号を含む住所フィールドをインポートおよびエクスポートします'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 69
  question_text: 'コンサルタントはトランザクションデータでデータストリームを設定しています。

    コンサルタントは、どのフィールドタイプを選択すべきでしょうか？

    注文番号のゼロは保持されますか?'
  choices:
    A: テキスト
    B: 数値
    C: 10進数
    D: シリアル
  correct_answer: A
  japanese_explanation: '発注書番号の先頭のゼロを保持するには、フィールドタイプとして「テキスト」を選択する必要があります。これは、テキストフィールドは英数字を文字列として保存し、先頭または末尾の文字を削除しないためです。一方、数値、小数点、シリアル値フィールドは数値を数値として保存し、データの表示またはエクスポート時に先頭のゼロを自動的に削除します123。したがって、発注書番号、郵便番号、電話番号など、元の形式を維持する必要があるデータの保存には、テキストフィールドの方が適しています。参考：

    データエクスポートではフィールドの先頭のゼロが省略されているように見える

    CSV ファイルをインポートするときに最初の ''0'' を保持する

    ゼロで始まる、またはプラス記号を含む住所フィールドをインポートおよびエクスポートします'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 70
  question_text: 'Cumulus Financialは、複数のセグメントの同時公開に遅延が発生しています。同社は、現在と同じセグメントを維持しながら、セグメントの公開頻度の低下を避けたいと考えています。

    この問題を緩和するためにコンサルタントはどのような行動を取るべきでしょうか?'
  choices:
    A: 生成時間を短縮するために、すべてのセグメントへの迅速なセグメント公開を有効にします。
    B: 公開するセグメントの数を減らします。
    C: Data Cloud セグメンテーションの同時実行制限を増やします。
    D: プロセスの重複を防ぐために、各セグメントの公開スケジュールの開始時刻を調整します。
  correct_answer: C
  japanese_explanation: 'Cumulus Financialは、複数のセグメントを同時に公開する際に遅延が発生しており、同じセグメントを維持しながらセグメントの公開頻度を下げたくないと考えています。最善の解決策は、Data
    Cloudのセグメンテーション同時実行制限を増やすことです。その理由は次のとおりです。

    問題を理解する

    同社は複数のセグメントを同時に公開しているため、遅延が発生しています。

    セグメントの頻度や数を減らすことはビジネスクリティカルな要件であるため、選択肢にはありません。

    セグメンテーションの同時実行制限を増やす理由は何ですか?

    セグメンテーション同時実行制限:

    Salesforce Data Cloud には、同時に処理できるセグメントの数にデフォルトの制限があります。

    複数のセグメントを同時に公開する場合、この制限を超えると遅延が発生する可能性があります。

    ソリューションアプローチ：

    セグメンテーションの同時実行制限を増やすと、より多くのセグメントを遅延なく同時に処理できるようになります。

    これにより、頻度を減らしたり既存のセグメントを削除したりすることなく、すべてのセグメントが時間どおりに公開されることが保証されます。

    問題を解決するための手順

    ステップ1: 現在の同時実行制限を確認する

    [セットアップ] > [データ クラウド設定] に移動して、現在のセグメンテーションの同時実行制限を確認します。

    ステップ2：増額を申請する

    セグメンテーションの同時実行制限の増加をリクエストするには、Salesforce サポートまたは Salesforce アカウントエグゼクティブにお問い合わせください。

    ステップ3: パフォーマンスを監視する

    制限を増やした後、セグメントの公開を監視して、遅延が解決されていることを確認します。

    他の選択肢はないのでしょうか?

    A). すべてのセグメントに対して高速セグメント公開を有効にして、生成時間を短縮します。高速セグメント公開は、生成を高速化するように設計されていますが、複数のセグメントが同時に公開される場合の同時実行の問題には対処していません。

    B). 公開されるセグメントの数を減らす: これは、同じセグメントを保持して頻度の低下を回避するという要件に反します。

    D). 重複プロセスを防ぐために各セグメントの公開スケジュールの開始時間を調整します。スケジュールをずらすことは役立つかもしれませんが、同時実行制限によって発生する遅延の問題を完全に解決するわけではありません。

    結論

    Data Cloud のセグメンテーション同時実行制限を増やすことで、Cumulus Financial はビジネス要件を満たしながら、複数のセグメントを同時に公開する際の遅延を軽減できます。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 71
  question_text: どのソリューションが、Marketing Cloud の加入者プロファイル属性を毎日 Data Cloud に取り込む簡単な方法を提供しますか?
  choices:
    A: Automation Studio およびプロファイル ファイル API
    B: マーケティングクラウド接続 API
    C: Marketing Cloud データ拡張機能のデータストリーム
    D: Email Studio スターター データ バンドル
  correct_answer: C
  japanese_explanation: 'Marketing Cloud の購読者プロファイル属性を Data Cloud に毎日簡単に取り込むことができるソリューションが、Marketing
    Cloud データ拡張機能のデータストリームです。Marketing Cloud データ拡張機能のデータストリームは、Marketing Cloud データ拡張機能から
    Data Cloud データスペースにデータをストリーミングできる機能です。ストリーミングするデータ拡張機能を選択すると、Data Cloud によってデータスペース内の対応するデータモデルオブジェクト
    (DMO) が自動的に作成され、更新されます。また、ユーザーインターフェースまたは API を使用して、データ拡張機能フィールドを DMO 属性にマッピングすることもできます。Marketing
    Cloud データ拡張機能のデータストリームを使用すると、コードを記述したり複雑な統合を設定したりすることなく、Marketing Cloud から Data
    Cloud に購読者プロファイル属性などのデータを取り込むことができます。

    その他のオプションは、Marketing Cloud の購読者プロファイル属性を Data Cloud に日常的に簡単に取り込むことができるソリューションではありません。Automation
    Studio と Profile file API は、Marketing Cloud から外部システムにデータをエクスポートするために使用できるツールですが、スクリプトの作成、ファイル転送の設定、自動化のスケジュール設定など、お客様自身で行う必要があります。Marketing
    Cloud Connect API は、Sales Cloud や Service Cloud などの他の Salesforce ソリューションで Marketing
    Cloud のデータにアクセスするために使用できる API ですが、Data Cloud へのデータのストリーミングはサポートしていません。Email Studio
    Starter Data Bundle は、Email Studio 用のサンプルデータとセグメントを含むデータキットですが、購読者プロファイル属性は含まれておらず、Data
    Cloud へのデータのストリーミングもサポートされていません。

    参照：

    マーケティングクラウドデータ拡張データストリーム

    データクラウドデータ取り込み

    [Marketing Cloud データ拡張データストリーム API]

    [マーケティングクラウドコネクトAPI]

    [Email Studio スターター データ バンドル]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 72
  question_text: 'ある企業は顧客データを Marketing Cloud に保存し、Marketing Cloud Connector を使用してデータを
    Data Cloud に取り込みます。

    データ削除または忘れられる権利の要求はどこに提出すればよいですか?'
  choices:
    A: データクラウド設定
    B: マーケティングクラウドの設定
    C: データクラウドの個々のデータプロファイルについて
    D: Consent API 経由
  correct_answer: D
  japanese_explanation: ''
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 73
  question_text: データ クラウドにおける人工知能 (AI) の役割は何ですか?
  choices:
    A: データ検証の自動化
    B: 動的なデータ駆動型管理ダッシュボードの作成
    C: 洞察と予測を通じて顧客とのインタラクションを強化する
    D: ユースケース用のメールテンプレートの生成
  correct_answer: C
  japanese_explanation: '* データクラウドにおける AI の役割: 人工知能 (AI) は、データを活用して顧客とのやり取りを強化する洞察と予測を生成することで、Salesforce
    データクラウドで重要な役割を果たします。

    * 洞察と予測:

    AI アルゴリズム: 機械学習アルゴリズムを使用して、膨大な量の顧客データを分析します。

    予測分析: 顧客の行動傾向、好み、将来の潜在的な行動などの予測的な洞察を提供します。

    * 顧客とのインタラクションの強化:

    パーソナライゼーション: AI は顧客のニーズと好みを予測することで、パーソナライズされたエクスペリエンスの作成に役立ちます。

    効率性: 顧客が問い合わせる前に問題を予測し、解決策を提案することで、プロアクティブな顧客サービスを実現します。

    マーケティング: ターゲティングとセグメンテーションを改善し、マーケティング活動が最も有望なリードと顧客に向けられるようにします。

    * ユースケース:

    推奨エンジン: 過去の行動や好みに基づいて製品やサービスを提案します。

    離脱予測: 離脱のリスクがある顧客を特定し、顧客維持戦略で関与させます。

    * 参照：

    Salesforce データクラウド AI 機能

    顧客インタラクションのためのSalesforce AI'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 74
  question_text: 'コンサルタントは顧客の Data Cloud 組織で作業しており、既存の ID 解決ルールセットを削除するように求められています。

    このアクションの結果としてコンサルタントが伝える必要がある 2 つの影響はどれですか?

    2つの回答を選択してください'
  choices:
    A: 個々のデータはすべて削除されます。
    B: このルールセットに関連付けられた統合顧客データは削除されます。
    C: データ モデル オブジェクトへの依存関係が削除されます。
    D: すべてのソースプロファイルデータが削除されます
  correct_answer: B,C
  japanese_explanation: ID解決ルールセットを削除すると、コンサルタントが顧客に伝える必要がある2つの大きな影響があります。1つ目は、ルールセットによって作成されたすべての統合顧客データが完全に削除されるため、統合プロファイルとその属性はData
    Cloud1で利用できなくなります。2つ目は、ルールセットで使用されていたデータモデルオブジェクトへの依存関係がなくなるため、ルールセット1に影響を与えずにデータモデルオブジェクトを変更または削除できるようになります。これらの影響は、顧客のデータ品質、セグメンテーション、アクティベーション、および分析に重大な影響を及ぼす可能性があるため、コンサルタントは、ルールセットの削除を進める前に、その影響を慎重に検討するよう顧客にアドバイスする必要があります。その他の選択肢は、ルールセットの削除による影響ではないため、正しくありません。選択肢Aは、ルールセットを削除してもすべての個別データではなく、統合顧客データのみが削除されるため、正しくありません。ソースシステムの個別データは、引き続きData
    Cloud1で利用できます。選択肢Dは、ルールセットを削除してもすべてのソースプロファイルデータではなく、統合顧客データのみが削除されるため、正しくありません。データストリームからのソースプロファイルデータは、引き続きData
    Cloud1で利用できます。参考：アイデンティティ解決ルールセットの削除
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 75
  question_text: '実装プロジェクト中に、コンサルタントが顧客のすべてのデータ ストリームの取り込みを完了しました。

    データをセグメント化して操作する前に、どのような追加構成が必要ですか?'
  choices:
    A: データのアクティベーション
    B: 計算された洞察
    C: データマッピング
    D: アイデンティティ解決
  correct_answer: D
  japanese_explanation: 'さまざまなソースから Data Cloud にデータを取り込んだ後、そのデータをセグメント化して操作する前に必要な追加の設定は、Identity
    Resolution です。Identity Resolution とは、さまざまなデータソースのソースプロファイルを照合および調整し、単一の個人またはエンティティを表す統合プロファイルを作成するプロセスです1。Identity
    Resolution を使用すると、顧客と見込み客の 360 度ビューを作成し、属性と行動に基づいてセグメント化してアクティブ化できます2。Identity
    Resolution を設定するには、データの一致ルールと調整ルールを定義するルールセットを作成して展開する必要があります3。その他のオプションは、データをセグメント化して操作する前には必要ないため、正しくありません。Data
    Activation とは、マーケティング、営業、またはサービスを目的として、Data Cloud から他の Salesforce クラウドまたは外部の送信先にデータを送信するプロセスです4。計算されたインサイトは、生涯価値、解約リスク、製品アフィニティなど、ソースデータまたは統合データに基づいて計算される派生属性です5。Data
    Mapping とは、ソース属性をデータモデル内の統合属性にマッピングするプロセスです。これらの設定は、データのセグメント化と処理を行った後、またはIdentity
    Resolutionと並行して行うことができますが、Identity Resolutionの前提条件ではありません。参考資料：Identity Resolutionの概要、データクラウドでのデータのセグメント化とアクティベーション、Identity
    Resolutionルールセットの設定、データアクティベーションの概要、Calculated Insightsの概要

    [データマッピングの概要]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 76
  question_text: 'Data Cloud で対応できる一般的なユースケースを 2 つ挙げてください。

    2つの回答を選択してください'
  choices:
    A: 顧客データを理解し、それに基づいて行動することで、より関連性の高いエクスペリエンスを実現します。
    B: 一元化された一連のポリシーとプロセスを通じて、エンタープライズ データのライフサイクルを管理します。
    C: 標準化され拡張可能なデータ モデルを使用して、複数のソースからのデータを調整します。
    D: バックアップと災害復旧のための集中システムとして機能することで、重要なビジネス データを保護します。
  correct_answer: A,C
  japanese_explanation: 'Data Cloudは、Salesforceや外部の様々なソースにまたがるデータの接続、準備、ハーモナイズ、統合、クエリ、分析、そしてそれらに基づいたアクションの実行を支援するデータプラットフォームです。Data
    Cloudで対応できる一般的なユースケースには、以下のようなものがあります。

    * 顧客データを理解し、それに基づいて行動することで、より関連性の高いエクスペリエンスを提供できます。Data Cloudは、さまざまなソースからのデータを統合し、チャネルをまたいでIDを解決することで、お客様が顧客を360度ビューで把握できるよう支援します。また、オーディエンスのセグメント化、パーソナライズされたエクスペリエンスの創出、インサイトとAIを活用したあらゆるチャネルでのデータの活用も支援します。

    * 標準化され拡張可能なデータモデルを用いて、複数のソースからデータを統合します。Data Cloudは、お客様がデータを使用する前に変換・クレンジングし、拡張・カスタマイズ可能な共通データモデルにマッピングするお手伝いをします。また、Data
    Cloudは、お客様が計算されたインサイトや関連属性を作成することで、データを拡充し、ID解決を最適化するお手伝いもします。

    他の2つのオプションは、Data Cloudの一般的なユースケースではありません。Data Cloudはデータガバナンスやバックアップ、ディザスタリカバリ機能を提供していません。これらの機能は通常、他のSalesforceソリューションや外部ソリューションによって処理されます。

    参考文献:

    * データクラウドの仕組みを学ぶ

    * Salesforce Data Cloudについて

    * プラットフォームのユースケースを発見する

    * 一般的なデータ分析のユースケースを理解する'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 77
  question_text: 'Northern Trail Outfitters には、Data Cloud に取り込んでセグメンテーションに使用する次の顧客データがあります。

    1. 購入意欲

    2. アクティブな会員である

    3. 仕事用メールアドレス

    このデータを取り込むときにコンサルタントはどのデータ型を使用する必要がありますか?'
  choices:
    A: 数値、テキスト、URL
    B: パーセント、ブール値、メール
    C: 数値、ブール値、テキスト
    D: パーセント、数値、メール
  correct_answer: B
  japanese_explanation: '顧客データをData Cloudに取り込む際には、適切なセグメンテーションと活用を実現するために、適切なデータタイプを使用することが重要です。コンサルタントは、提供されたデータポイントをどのように処理すべきでしょうか。

    購入傾向:

    これは可能性または確率の値を表し、通常はパーセンテージ（例: 75%）で表されます。

    このフィールドに適したデータ型はパーセントであり、これにより簡単に解釈してセグメンテーションで使用することができます。

    アクティブなメンバーシップ:

    これは、顧客がアクティブなメンバーシップを持っているかどうかを示すバイナリ値です (例: 「はい」または「いいえ」)。

    このフィールドの正しいデータ型は、true/false 値をサポートする Boolean です。

    勤務先メールアドレス:

    これは標準の電子メール アドレス フィールドです。

    適切なデータ型は Email であり、これにより適切な検証と書式設定が保証されます。

    他の選択肢はないのでしょうか?

    A. 数値、テキスト、URL: これらのデータタイプは正しくありません。「購入傾向」は一般的な数値ではなくパーセンテージで表すべきです。同様に、「勤務先メールアドレス」はURLではなくメールアドレスで表すべきです。

    C . 数値、ブール値、テキスト: 「数値」は傾向スコアには適していますが、パーセンテージのような意味的意味を欠いています。また、「テキスト」はメールアドレスには適していません。

    D . パーセント、数値、電子メール: 「アクティブなメンバーシップがある」に「数値」を使用するのは、数値ではなくバイナリ値であるため、正しくありません。

    コンサルタントは、パーセント、ブール値、電子メールを選択することで、データが正しくフォーマットされ、セグメンテーションと分析の準備ができていることを確認できます。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 78
  question_text: 'データ ソースを切断する前に削除する必要がある 2 つの依存関係はどれですか。

    2つの回答を選択してください'
  choices:
    A: 活性化対象
    B: セグメント
    C: アクティベーション
    D: データストリーム
  correct_answer: B,D
  japanese_explanation: 'データクラウドの依存関係:

    * データ ソースを切断する前に、データの整合性の問題を防ぐためにすべての依存関係を削除する必要があります。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 79
  question_text: '顧客が個人データの削除を要求します。

    Data Cloud でこのリクエストに対応するために、コンサルタントはどのようなアクションを実行する必要がありますか?'
  choices:
    A: ストリーミング API 呼び出しを使用して顧客の情報を削除します。
    B: Profile Explorer を使用して、Data Cloud から顧客データを削除します。
    C: Consent API を使用して顧客情報の削除をリクエストします。
    D: データ権利主体要求ツールを使用して、顧客情報の削除を要求します。
  correct_answer: C
  japanese_explanation: データ権利主体リクエストツールは、データクラウドユーザーがデータへのアクセス、削除、またはポータビリティに関する顧客のリクエストを管理できる機能です。このツールは、データ権利リクエストの作成、追跡、および対応のためのユーザーインターフェースとAPIを提供します。また、顧客の個人データとリクエストへの対応状況を含むレポートも生成します。コンサルタントは、このツールを使用して、データクラウドにおける顧客のデータ削除リクエストに対応する必要があります。参考資料：データ権利主体リクエストツール、データ権利主体リクエストの作成
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 80
  question_text: 'Cumulus Financialは、法人向けローンと個人向けローンの両方を提供しています。個人顧客は法人向けローンと個人向けローンの両方を利用される場合があるため、連絡先DLOの記録は両方のグループにとって有用です。ただし、法的理由により、2つのグループは区別して管理する必要があります。

    Cumulus Financial はこのビジネス要件をどのように解決すべきでしょうか?'
  choices:
    A: 個別 DM0 を複製します。
    B: 連絡先 DLO を複製します。
    C: 同じデータ スペースに 2 つの ID 解決ルールを作成します。
    D: 2 つのデータ スペースを使用します。
  correct_answer: D
  japanese_explanation: 'Cumulus Financialは、法的な理由から事業用ローンと個人用ローンの記録を分けて管理しながら、同じContact
    DLOを活用しなければならないというビジネス要件に対応しています。最適なソリューションは、2つのデータスペースを使用することです。その理由と仕組みは以下のとおりです。

    Salesforce Data Cloud のデータスペースについて：データスペースは、Salesforce Data Cloud 内の論理コンテナであり、組織は特定のビジネスニーズ、コンプライアンス要件、またはプライバシー規制に基づいてデータをセグメント化できます。これにより、データ処理と
    ID 解決ルールを分離しながら、連絡先 DLO などの共有データオブジェクトへのアクセスが可能になります。

    なぜ 2 つのデータ スペースが必要なのでしょうか?

    2 つのデータ スペース (たとえば、ビジネス ローン用と個人ローン用) を作成することにより、Cumulus Financial は 2 つのグループ間の分離を維持し、法令遵守を維持できます。

    両方のデータ スペースは同じ連絡先 DLO を参照できるため、個々の顧客データは重複されず、両方のコンテキストでアクセス可能になります。

    ID 解決ルールは各データ スペース内で個別に構成できるため、セグメンテーションが法的要件に準拠していることを確認できます。

    このソリューションを実装する手順:

    ステップ 1: Salesforce Data Cloud の「データ スペース」セクションに移動します。

    ステップ 2: 2 つの新しいデータ スペースを作成します。1 つは「ビジネス ローン」用、もう 1 つは「個人ローン」用です。ステップ 3: 適切なセグメンテーションを確保するために、各データ
    スペースに対して ID 解決ルールを個別に構成します。

    ステップ4：既存の連絡先DLOを両方のデータスペースにリンクします。これにより、両方のコンテキストで同じ連絡先データが重複なく利用できるようになります。

    ステップ 5: あるデータ スペースのデータが他のデータ スペースと誤って混在しないように、アクティベーション ルールとアクセス許可を設定します。

    他の選択肢はないのでしょうか?

    A) 個々のDMOを複製する：これはデータの不要な重複につながり、ストレージコストの増加につながります。また、重複したレコード間の一貫性を維持するのが複雑になります。

    B). 連絡先 DLO を複製する: DMO を複製する場合と同様に、このアプローチでは、法的分離という根本的な問題を解決せずに、ストレージとメンテナンスのオーバーヘッドが増加します。

    C). 同じデータ スペースに 2 つの ID 解決ルールを作成する: これは実行可能なオプションのように見えますが、両方のグループが同じデータ スペース内に存在するため、必要な法的分離は提供されません。

    Cumulus Financial は 2 つのデータ スペースを使用することで、効率性を維持し、データの冗長性を回避しながら、必要な法的分離を実現します。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 81
  question_text: Data Cloud は個人の忘れられる権利をどのように扱いますか?
  choices:
    A: すべてのデータソースオブジェクトからレコードを削除し、下流のデータモデルオブジェクトは次回のスケジュールされた取り込み時に更新されます。
    B: 指定された個別レコードとその統合個別リンクレコードを削除します。
    C: 指定された個人とレコードを、Individual データ モデル オブジェクトにマップされたすべてのデータ ソース オブジェクトから削除します。
    D: 指定された個人と、その個人に関連するすべてのデータ モデル オブジェクト/データ レイク オブジェクトからレコードを削除します。
  correct_answer: D
  japanese_explanation: 'Data Cloud は、指定された個人と、その個人に関連するすべてのデータモデルオブジェクト/データレイクオブジェクトからレコードを削除することで、個人の「忘れられる権利」を処理します。つまり、Data
    Cloud は、ソースオブジェクト、統合された個人プロファイル、および関連オブジェクトのデータを含む、個人に関連付けられたすべてのデータをデータスペースから削除します。また、個人とソースレコードをリンクする統合個人リンクレコードも削除します。Data
    Cloud は、Consent API を使用して「忘れられる権利」リクエストを処理します。これらのリクエストは、完全な削除を確実にするために、30 日、60
    日、90 日ごとに再処理されます。

    その他のオプションは、データクラウドが個人の忘れられる権利をどのように処理するかについて正しく説明していません。データクラウドは、ソースシステムのデータの整合性と可用性に影響を与えるため、すべてのデータソースオブジェクトからレコードを削除することはありません。また、データクラウドは、指定された個人レコードとその統合個人リンクレコードのみを削除することもありません。そうすると、ソースレコードと関連レコードがそのまま残ってしまうためです。さらに、データクラウドは、指定された個人と、その個人データモデルオブジェクトにマッピングされたデータソースオブジェクトからのレコードのみを削除することもありません。そうすると、関連レコードがそのまま残ってしまうためです。

    参照：

    データ削除または忘れられる権利の要求

    データクラウドのデータ削除

    Data Cloud で Consent API を使用する

    データクラウドにおけるデータとアイデンティティ'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 82
  question_text: 'ある企業は顧客データを Marketing Cloud に保存し、Marketing Cloud Connector を使用してデータを
    Data Cloud に取り込みます。

    データ削除または忘れられる権利の要求はどこに提出すればよいですか?'
  choices:
    A: データクラウド設定
    B: データクラウドの個々のデータプロファイルについて
    C: マーケティングクラウドの設定
    D: Consent API 経由
  correct_answer: C
  japanese_explanation: '* データ削除リクエスト: Salesforce Marketing Cloud および Data Cloud を使用している企業にとって、データのプライバシーと削除リクエストの管理は不可欠です。

    * Marketing Cloud コネクタ: このコネクタは Marketing Cloud と Data Cloud 間のデータ統合を容易にしますが、データ削除リクエストは特定の手順に従う必要があります。

    * Marketing Cloud での削除リクエスト:

    データ管理: データの削除または忘れられる権利のリクエストは、顧客データが元々保存および管理されている Marketing Cloud 設定を通じて送信されます。

    伝播: リクエストが Marketing Cloud で処理されると、変更はコネクタを通じて Data Cloud に伝播されます。

    * 参照：

    Salesforce Marketing Cloud ドキュメント: データ管理

    Salesforce データクラウドコネクタガイド'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 83
  question_text: 毎日評価される誕生日キャンペーンのセグメントを作成するには、コンサルタントはどの演算子を使用する必要がありますか?
  choices:
    A: 今日は
    B: 誕生日です
    C: 〜の間
    D: 記念日です
  correct_answer: D
  japanese_explanation: '毎日評価される誕生日キャンペーンのセグメントを作成するには、「記念日」演算子を使用する必要があります。この演算子は、日付フィールドと現在の日付を比較し、年に関係なく月と日が同じ場合にtrueを返します。例えば、日付フィールドが1990-01-01で、現在の日付が2023-01-01の場合、演算子はtrueを返します。これにより、コンサルタントは、現在の日付と同じ日に誕生日を迎えるすべての顧客を含むセグメントを作成でき、セグメントは毎日新しい誕生日で更新されます。他の演算子は、以下の理由により、この目的には最適ではありません。

    A. Is Today演算子は、日付フィールドと現在の日付を比較し、年を含め日付が一致する場合にtrueを返します。例えば、日付フィールドが1990-01-01で、現在の日付が2023-01-01の場合、この演算子はfalseを返します。この演算子は、現在の日付と同じ年日に生まれた顧客のみを対象としますが、そのような可能性は非常に低いため、誕生日キャンペーンには適していません。

    B. 「誕生日」演算子はData Cloudでは有効な演算子ではありません。セグメントキャンバスや計算インサイトエディターでは、この演算子は使用できません。

    C . Is Between演算子は、日付フィールドと日付範囲を比較し、日付が範囲内（エンドポイントを含む）にある場合にtrueを返します。例えば、日付フィールドが1990年1月1日で、範囲が2022年12月25日から2023年1月5日の場合、演算子はtrueを返します。この演算子は、誕生日が固定された日付範囲内にある顧客のみを対象とし、セグメントは毎日新しい誕生日で更新されないため、誕生日キャンペーンには適していません。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 84
  question_text: データクラウドの主な目的は何ですか?
  choices:
    A: 顧客のゴールデンレコードの提供
    B: 販売サイクルと商談の管理
    C: マーケティングデータの結果の分析
    D: 顧客データの統合と統一
  correct_answer: D
  japanese_explanation: '* データクラウドの主な目的:

    Salesforce Data Cloud の主な機能は、さまざまなソースからの顧客データを統合および統一し、各顧客の単一の包括的なビューを作成することです。

    参照：

    * データ統合と統一のメリット:

    ゴールデンレコード: 顧客に関する統一された正確なビューを提供します。

    強化された分析: 包括的なデータを通じて、より優れた洞察と分析を可能にします。

    顧客エンゲージメントの向上: チャネル全体でパーソナライズされた一貫性のある顧客エクスペリエンスを促進します。

    * データ統合の手順:

    複数のソース (CRM、マーケティング、サービス プラットフォーム) からデータを取り込みます。

    データの調和と調整のプロセスを使用して、データを単一のプロファイルに統合します。

    * 実用的な応用:

    例: 小売企業は、オンライン購入、店舗での取引、顧客サービスのやり取りからの顧客データを統合して、統一された顧客プロファイルを作成します。

    この統合データにより、パーソナライズされたマーケティング キャンペーンと顧客サービスの向上が可能になります。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 85
  question_text: '高級小売店は、高価値顧客をターゲットとするセグメントを作成し、Marketing Cloud を通じてメールコミュニケーション用に有効化しました。ところが、有効化された顧客数がセグメント数よりも少ないことに気づきました。

    これには何の理由があるのでしょうか?'
  choices:
    A: Data Cloud は、Marketing Cloud のアクティベーションに連絡先の存在を必須とします。個人に関連する連絡先が存在しない場合は、アクティベートされません。
    B: Marketing Cloud のアクティベーションでは、エンゲージメントがなく、過去 6 か月間にメールを開いたりクリックしたりしていない個人が自動的に抑制されます。
    C: Marketing Cloud のアクティベーションでは、Marketing Cloud にすでに存在するユーザーのみがアクティベートされます。新しいレコードのアクティブ化は許可されません。
    D: Marketing Cloud アクティベーションでは頻度上限が適用され、アクティベーションで送信できるレコード数が制限されます。
  correct_answer: A
  japanese_explanation: 'アクティブ化された数がセグメント数より少ない理由は、A. Data Cloud では Marketing Cloud
    のアクティベーションに連絡先の存在が必須です。個人が関連する連絡先を持っていない場合、その個人はアクティベートされません。連絡先とは、電子メール、電話、ソーシャルメディアなど、個人とのコミュニケーションチャネルまたは方法を表すデータモデルオブジェクトです。Marketing
    Cloud のアクティベーションでは、Data Cloud では、有効なメールアドレスを含む、メールタイプの関連する連絡先が個人に必要です。個人がそのような連絡先を持っていない場合、または連絡先が見つからないか無効な場合、その個人はアクティベートされず、メールによるコミュニケーションも受信されません。したがって、セグメント内で有効なメール連絡先を持つ個人の数によっては、アクティブ化された数がセグメント数より少なくなる場合があります。参考資料:
    Salesforce Data Cloud コンサルタント試験ガイド、連絡先、Marketing Cloud アクティベーション'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 86
  question_text: 'Data Cloud は、前日のすべての電子商取引トランザクションのファイルを夜間に受信します。

    いくつかのセグメントとアクティベーションは、顧客のスケジュールされたキャンペーン メッセージの正確性を維持するために、更新されたデータから計算された洞察に依存します。

    スケジュールされたアクティベーションごとに電子商取引データが使用可能であることを確認するために、コンサルタントは何をする必要がありますか?'
  choices:
    A: アクティベーションの実行がスケジュールされる前に、Flow を使用して e コマース データの変更データ イベントをトリガーし、計算されたインサイトとセグメントを更新します。
    B: 計算された分析情報が 1 時間ごとに更新されるスケジュールを設定します。
    C: アクティベーションが増分アクティベーションに設定され、1 時間ごとに自動的に公開されることを確認します。
    D: セグメントが Rapid Publish に設定され、1 時間ごとに更新されるように設定されていることを確認します。
  correct_answer: A
  japanese_explanation: 'コンサルタントが、スケジュールされた各アクティベーションで e コマース データが使用可能であることを確認するために実行する必要がある最善のオプションは、A
    です。フローを使用して、e コマース データの変更データ イベントをトリガーし、アクティベーションの実行がスケジュールされる前に、計算されたインサイトとセグメントを更新します。このオプションにより、コンサルタントは
    Data Cloud のフロー機能を使用できます。これにより、イベントまたはスケジュールに基づいてデータ処理タスクの自動化とオーケストレーションが可能になります。フローを使用して、e
    コマース データの変更データ イベントをトリガーできます。これは、データが更新または変更されたことを示すイベント タイプです。その後、このイベントにより、e
    コマース データに依存する計算されたインサイトとセグメントの更新がトリガーされ、最新のデータが反映されます。計算されたインサイトとセグメントの更新は、アクティベーションの実行がスケジュールされる前に完了できるため、顧客のスケジュールされたキャンペーン
    メッセージが正確で関連性のあるものになります。

    他のオプションはオプション A ほど効果的ではありません。オプション B は不正解です。計算されたインサイトの更新スケジュールを 1 時間ごとに設定しても、十分または効率的ではない可能性があります。更新スケジュールがアクティベーション
    スケジュールと一致しない場合があり、その結果、データが古くなったり、一貫性がなくなったりする可能性があります。また、e コマース データは毎時間変更されない可能性があるため、更新スケジュールによって必要以上のリソースと時間が消費される可能性があります。オプション
    C は不正解です。アクティベーションを増分アクティベーションに設定し、1 時間ごとに自動的に公開しても、問題が解決しない可能性があります。増分アクティベーションは、セグメント内の新規または変更されたレコードのみをアクティベートできる機能であり、アクティベーションの時間とサイズを削減します。ただし、この機能では、セグメント
    データが e コマース データに基づいて更新またはリフレッシュされることが保証されません。アクティベーション スケジュールが e コマース データの更新スケジュールと一致しない場合もあり、その結果、キャンペーン
    メッセージが不正確または無関係になる可能性があります。オプション D は不正解です。セグメントを高速公開に設定し、1 時間ごとに更新するように設定しても、最適または効果的ではない可能性があります。
    Rapid Publishは、重複レコードや無効な値のチェックなど、一部の検証手順を省略することで、セグメントをより迅速に公開できる機能です。ただし、この機能はセグメントデータの品質や精度を損なう可能性があり、すべてのユースケースに適しているとは限りません。また、更新スケジュールもオプションBと同様の問題が発生する可能性があります。更新スケジュールは、eコマースデータの更新スケジュールやアクティベーションスケジュールと同期せず、データが古くなったり、一貫性が失われたりする可能性があります。参考資料：Salesforce
    Data Cloud Consultant試験ガイド、フロー、変更データイベント、計算されたインサイト、セグメント、[アクティベーション]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 87
  question_text: 顧客がエージェントと連携しているときに、顧客サポートのやり取りを改善するために Data Cloud が提供する機能はどれですか?
  choices:
    A: 予測的なトラブルシューティング
    B: 強化されたレポートツール
    C: リアルタイムデータ統合
    D: 自動カスタマーサービス返信
  correct_answer: C
  japanese_explanation: 'Salesforce Data Cloud の顧客サポート: Salesforce Data Cloud の主な利点の
    1 つは、包括的かつリアルタイムの顧客データを提供することで顧客サポートを強化できることです。

    リアルタイム データ統合: この機能により、顧客サポート エージェントは最新の顧客情報にアクセスできるようになり、顧客からの問い合わせや問題に効果的に対応する能力が向上します。

    顧客サポートのメリット:

    * 即時アクセス: エージェントは顧客とのやり取りやデータにリアルタイムでアクセスできるため、正確でタイムリーなサポートを提供できます。

    * コンテキスト情報: 統合されたデータにより、顧客の履歴と好みの全体像が提供され、よりパーソナライズされたサポートのやり取りが可能になります。

    ユースケース: 顧客がサポートに連絡すると、エージェントは最近の購入、やり取り、進行中の問題に関する更新情報をリアルタイムで確認できるため、問い合わせを迅速かつ効率的に解決できます。

    参考文献:

    * 顧客サポートのためのSalesforce Data Cloud

    * Salesforceでのリアルタイムデータ統合'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 88
  question_text: Data Cloud は個人の忘れられる権利をどのように扱いますか?
  choices:
    A: すべてのデータソースオブジェクトからレコードを削除し、下流のデータモデルオブジェクトは次回のスケジュールされた取り込み時に更新されます。
    B: 指定された個別レコードとその統合個別リンクレコードを削除します。
    C: 指定された個人とレコードを、Individual データ モデル オブジェクトにマップされたすべてのデータ ソース オブジェクトから削除します。
    D: 指定された個人と、その個人に関連するすべてのデータ モデル オブジェクト/データ レイク オブジェクトからレコードを削除します。
  correct_answer: D
  japanese_explanation: 'Data Cloud は、指定された個人と、その個人に関連するすべてのデータモデルオブジェクト/データレイクオブジェクトからレコードを削除することで、個人の「忘れられる権利」を処理します。つまり、Data
    Cloud は、ソースオブジェクト、統合された個人プロファイル、および関連オブジェクトのデータを含む、個人に関連付けられたすべてのデータをデータスペースから削除します。また、個人とソースレコードをリンクする統合個人リンクレコードも削除します。Data
    Cloud は、Consent API を使用して「忘れられる権利」リクエストを処理します。これらのリクエストは、完全な削除を確実にするために、30 日、60
    日、90 日ごとに再処理されます。

    その他のオプションは、データクラウドが個人の忘れられる権利をどのように処理するかについて正しく説明していません。データクラウドは、ソースシステムのデータの整合性と可用性に影響を与えるため、すべてのデータソースオブジェクトからレコードを削除することはありません。また、データクラウドは、指定された個人レコードとその統合個人リンクレコードのみを削除することもありません。そうすると、ソースレコードと関連レコードがそのまま残ってしまうためです。さらに、データクラウドは、指定された個人と、その個人データモデルオブジェクトにマッピングされたデータソースオブジェクトからのレコードのみを削除することもありません。そうすると、関連レコードがそのまま残ってしまうためです。

    参考文献:

    * データ削除または忘れられる権利の要求

    * データクラウドのデータ削除

    * Data Cloud で Consent API を使用する

    * データクラウドにおけるデータとアイデンティティ'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 89
  question_text: 'コンサルタントは、複数の断片化されたデータ ソースを持つ顧客と Data Cloud の利点について話し合っています。

    顧客データの管理に関してコンサルタントが強調すべき 2 つの機能領域はどれですか?

    2つの回答を選択してください'
  choices:
    A: データの調和
    B: 統合プロファイル
    C: マスターデータ管理
    D: データマーケットプレイス
  correct_answer: A,B
  japanese_explanation: 'データクラウドは、オープンで拡張可能なデータプラットフォームであり、ファーストパーティデータと業界データへの安全なアクセスを実現しながら、よりスマートで効率的なAIを実現します1。コンサルタントが顧客データ管理に関して強調すべき2つの機能領域は次のとおりです。

    データのハーモナイゼーション：Data Cloudは、複数のソースと形式から取得したデータを共通のスキーマにハーモナイズすることで、顧客データの信頼できる唯一の情報源を実現します1。また、Data
    Cloudはデータ品質ルールと変換を適用し、データの正確性と一貫性を確保します。

    統合プロファイル：データクラウドは、メールアドレス、電話番号、Cookie、デバイスID1など、さまざまな識別子にまたがるデータをリンクすることで、顧客と見込み客の統合プロファイルを作成します。統合プロファイルは、チャネルやタッチポイントをまたがる顧客の行動、嗜好、インタラクションを包括的に把握できます。その他の選択肢は、以下の理由により正しくありません。

    マスター データ管理: マスター データ管理 (MDM) は、製品、顧客、サプライヤー、場所データなどのマスター データの単一の一貫性のある信頼できるソースを作成および維持するプロセスです。

    Data Cloud は MDM 機能を提供しませんが、MDM ソリューションと統合して顧客データを充実させることができます。

    データマーケットプレイス：データマーケットプレイスは、Data Cloudの機能の一つで、ユーザーはサードパーティプロバイダーから提供されるデータ（人口統計データ、行動データ、インテントデータなど）を発見、アクセス、活用することができます。データマーケットプレイスは、顧客データの管理に関連する機能領域ではなく、顧客データを強化できる外部データのソースです。参考資料：

    Salesforce データクラウド

    [データクラウドのためのデータハーモナイゼーション]

    [データクラウドの統合プロファイル]

    【マスターデータ管理とは？】

    [データクラウドとマスターデータ管理の統合]

    [データクラウド向けデータマーケットプレイス]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 90
  question_text: 'ある企業は、さまざまなターゲット層を対象にマーケティング キャンペーンをテストしたいと考えています。

    異なる母集団を取得するには、コンサルタントはセグメント キャンバス インターフェイスで何を調整する必要がありますか?'
  choices:
    A: 直接属性、関連属性、人口フィルター
    B: セグメンテーションフィルタ、直接的な帰属、データソース
    C: 直接属性と関連属性
    D: 人口フィルターと直接属性
  correct_answer: A
  japanese_explanation: 'Salesforce Data Cloud のセグメンテーション:

    セグメント キャンバス インターフェイスは、マーケティング キャンペーンの対象グループを定義および調整するために使用されます。

    参考: Salesforce セグメント キャンバス ドキュメント

    対象集団を調整するための要素:

    直接属性: ターゲット エンティティに直接関連する特定の属性です (例: 顧客の年齢、場所)。

    関連属性: これらは、ターゲット エンティティに接続された他のエンティティに関連する属性です (例: 購入履歴)。

    人口フィルター: セグメント人口 (アクティブ顧客など) を定義および絞り込むために適用されるフィルター。

    参考: Salesforce セグメンテーションガイド

    セグメント キャンバスで人口を調整する手順:

    直接属性: 対象集団を直接説明する属性を選択します。

    関連属性: 関連エンティティからの属性を組み込んで、セグメント基準を強化します。

    人口フィルター: フィルターを適用して、人口の特定のサブセットを絞り込み、ターゲットにします。

    例: 「25〜35 歳のアクティブ顧客」というセグメントを作成するには、年齢を直接属性として使用し、購入アクティビティを関連属性として使用し、アクティビティ
    ステータスと年齢範囲に人口フィルターを適用します。

    参考: Salesforce セグメント キャンバス チュートリアル

    実用例:

    セグメント キャンバスに移動します。

    キャンペーンの目標に基づいて、直接属性と関連属性を調整します。

    人口フィルターを適用して、ターゲット ユーザーを微調整します。

    参考: Salesforce Marketing Cloud セグメンテーションのベストプラクティス'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 91
  question_text: DMO を作成するときに、セグメンテーションの属性の値の提案はどこで有効になりますか?
  choices:
    A: データマッピング
    B: データ変換
    C: セグメント設定
    D: データストリームのセットアップ
  correct_answer: C
  japanese_explanation: セグメンテーションにおける属性の値の提案は、セグメントフィルターを作成する際にテキスト項目の可能な値を表示して選択できる機能です。この機能は、データモデルオブジェクト（DMO）レコードホームの各DMO項目に対して有効または無効にできます。値の提案は、組織全体で最大500個の属性に対して有効にできます。提案された値が表示されるまで最大24時間かかる場合があります。セグメントフィルターの作成時に値の提案を使用するには、属性をキャンバスにドラッグし、属性の「値」項目に入力を開始する必要があります。一部の演算子では複数の値を選択することもできます。値の提案は、255文字を超える属性、または1対多（1:N）の関係では利用できません。参考資料：セグメンテーションにおける値の提案の使用、関連属性の選択に関する考慮事項
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 92
  question_text: 'コンサルタントは、データ クラウドで新しいオーディエンスを構築したいと考えています。

    セグメントを構築する際、コンサルタントが含めることができる 3 つの基準はどれですか?

    3つの回答を選択してください'
  choices:
    A: 直接属性
    B: データストリーム属性
    C: 計算された洞察
    D: 関連属性
    E: ストリーミングインサイト
  correct_answer: A,C,D
  japanese_explanation: 'セグメントとは、属性と行動に基づいて特定の基準を満たす個人のサブセットです。コンサルタントは、Data Cloud
    でセグメントを構築する際に、以下のような様々な基準を使用できます。

    直接属性: 名前、電子メール、性別、年齢など、個人の特性を表す属性です。これらの属性はプロファイル データ モデル オブジェクト (DMO) に保存され、プロファイル
    データに基づいて個人をフィルター処理するために使用できます。

    計算されたインサイト：データスペース内のデータに対して計算を実行し、その結果をデータ拡張機能に保存するインサイトです。これらのインサイトは、顧客生涯価値、解約リスク、ロイヤルティレベルなど、データから得られた指標やスコアに基づいて個人をセグメント化するために使用できます。

    関連属性: これらは、電子メール、エンゲージメント、注文、製品など、個人と他の DMO との関係を記述する属性です。これらの属性は、電子メールの開封、クリック、購入など、さまざまなエンティティとのやり取りやトランザクションに基づいて個人をセグメント化するために使用できます。

    他の2つのオプションは、Data Cloudでセグメントを構築するための有効な基準ではありません。データストリーム属性は、Marketing Cloud、Commerce
    Cloud、Service CloudなどのさまざまなソースからData Cloudに取り込まれるストリーミングデータを記述する属性です。これらの属性はセグメンテーションに直接使用することはできませんが、ストリーミングデータ変換を使用して変換し、データ拡張機能に保存することができます。

    ストリーミングインサイトは、ストリーミングデータをリアルタイムで分析し、事前定義された条件に基づいてアクションをトリガーするインサイトです。これらのインサイトはセグメンテーションではなく、アクティベーションとパーソナライゼーションに使用されます。参考資料：データクラウドでのセグメントの作成、データクラウドでのインサイトの使用、データクラウドのデータモデル'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 93
  question_text: 'Data Cloud の新規ユーザーは、取り込んだデータの個々の行を確認し、リンクされたデータモデルオブジェクトに正常にモデル化されていることを検証するだけで済みます。必要に応じて変更を加えることもできます。

    このユースケースに対応するために必要な最小限の権限セットは何ですか?'
  choices:
    A: マーケティングスペシャリスト向けデータクラウド
    B: データクラウド管理者
    C: データクラウドユーザー
    D: マーケティングデータアウェアスペシャリストのためのデータクラウド
  correct_answer: C
  japanese_explanation: 'Data Cloud ユーザー権限セットは、このユースケースに対応するために必要な最小限の権限セットです。

    Data Cloud ユーザー権限セットは、Data Explorer 機能へのアクセス権を付与します。これにより、ユーザーは取り込んだデータの個々の行を確認し、リンクされたデータ
    モデル オブジェクトに正常にモデル化されていることを検証できます。また、データ モデル オブジェクト フィールドへの変更 (フィールドの追加または削除、フィールド
    タイプの変更、数式フィールドの作成など) も可能です。Data Cloud ユーザー権限セットでは、データ ストリームの作成、セグメントの作成、アクティベーションの作成、ユーザーの管理など、他の
    Data Cloud 機能やタスクへのアクセス権は付与されません。他の権限セットは、このユース ケースに対して制限が厳しすぎるか、権限が厳しすぎます。Data
    Cloud for Marketing Specialist 権限セットは、セグメンテーション機能とアクティベーション機能へのアクセスのみを付与し、Data
    Explorer 機能へのアクセスは付与しません。Data Cloud 管理者権限セットは、Data Explorer 機能を含むすべての Data Cloud
    機能とタスクへのアクセスを付与しますが、ユーザーの必要以上の権限です。Data Cloud for Marketing Data Aware Specialist
    権限セットは、Data Explorer 機能へのアクセスに加えて、このユース ケースでは必要ありませんが、セグメンテーション機能とアクティベーション機能へのアクセスも付与します。参考資料:
    Data Cloud 標準権限セット、データエクスプローラ、Data Cloud ユニットの設定'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 94
  question_text: 'ユーザーはData Cloudでセグメントを作成し、アクティベーションを作成中です。関連属性を選択する際に、個人に関連するとわかっている属性セットが見つかりません。

    これらの属性が利用できない理由を説明する記述はどれですか?'
  choices:
    A: セグメントはプロファイル データでセグメント化されていません。
    B: 属性は別のアクティベーションで使用されています。
    C: 必要な属性は異なる関連パスに存在します。
    D: アクティベーションには 1 対 1 の属性のみを含めることができます。
  correct_answer: C
  japanese_explanation: '正解はCです。必要な属性は異なる関連パスに存在します。Data Cloudでアクティベーションを作成する際に、セグメントエンティティにリンクされているデータモデルオブジェクトから関連属性を選択できます。

    ただし、すべての関連属性がすべてのアクティベーションで使用できるわけではありません。関連属性の可用性は、コンテナパス（セグメントエンティティを関連エンティティに接続するデータモデルオブジェクトのシーケンス）によって異なります。たとえば、Unified
    Individual エンティティでセグメント化する場合、Order Product エンティティから関連属性を選択できますが、コンテナパスが Unified
    Individual > Order > Order Product の場合のみです。コンテナパスが Unified Individual > Order
    Line Item > Order Product の場合、Order Product の関連属性はアクティベーションに使用できません。これは、Data Cloud
    が関連属性に対して 1 対多の関係のみをサポートし、Order Line Item が Order と Order Product 間の多対多のジャンクションオブジェクトであるためです。したがって、必要な属性がセグメントエンティティと同じ関連パスに存在し、そのパスに多対多のジャンクションオブジェクトが含まれていないことを確認する必要があります。その他のオプションは、関連属性が使用できない理由を説明していないため、正しくありません。セグメントエンティティは、プロファイルデータだけでなく、任意のデータモデルオブジェクトにすることができます。属性は、別のアクティベーションで使用されていることで制限されることはありません。アクティベーションには、1対1の属性だけでなく、1対多の属性も含めることができます。参考資料:

    * アクティベーションにおける関連属性

    * 関連属性を選択する際の考慮事項

    * Salesforceがデータクラウドコンサルタント認定を開始

    * データクラウドでセグメントを作成する'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 95
  question_text: '実装プロジェクト中に、コンサルタントが顧客のすべてのデータ ストリームの取り込みを完了しました。

    データをセグメント化して操作する前に、どのような追加構成が必要ですか?'
  choices:
    A: データのアクティベーション
    B: 計算された洞察
    C: データマッピング
    D: アイデンティティ解決
  correct_answer: D
  japanese_explanation: 'さまざまなソースから Data Cloud にデータを取り込んだ後、そのデータをセグメント化して操作する前に必要な追加の設定は、Identity
    Resolution です。Identity Resolution とは、さまざまなデータソースのソースプロファイルを照合および調整し、単一の個人またはエンティティを表す統合プロファイルを作成するプロセスです1。Identity
    Resolution を使用すると、顧客と見込み客の 360 度ビューを作成し、属性と行動に基づいてセグメント化してアクティブ化できます2。Identity
    Resolution を設定するには、データの一致ルールと調整ルールを定義するルールセットを作成して展開する必要があります3。その他のオプションは、データをセグメント化して操作する前には必要ないため、正しくありません。Data
    Activation とは、マーケティング、営業、またはサービスを目的として、Data Cloud から他の Salesforce クラウドまたは外部の送信先にデータを送信するプロセスです4。計算されたインサイトは、生涯価値、解約リスク、製品アフィニティなど、ソースデータまたは統合データに基づいて計算される派生属性です5。Data
    Mapping とは、ソース属性をデータモデル内の統合属性にマッピングするプロセスです。これらの設定は、データのセグメント化と処理を行った後、またはIdentity
    Resolutionと並行して行うことができますが、Identity Resolutionの前提条件ではありません。参考資料：Identity Resolutionの概要、データクラウドでのデータのセグメント化とアクティベーション、Identity
    Resolutionルールセットの設定、データアクティベーションの概要、Calculated Insightsの概要

    [データマッピングの概要]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 96
  question_text: Data Cloud は個人の忘れられる権利をどのように扱いますか?
  choices:
    A: すべてのデータソースオブジェクトからレコードを削除し、下流のデータモデルオブジェクトは次回のスケジュールされた取り込み時に更新されます。
    B: 指定された個別レコードとその統合個別リンクレコードを削除します。
    C: 指定された個人とレコードを、Individual データ モデル オブジェクトにマップされたすべてのデータ ソース オブジェクトから削除します。
    D: 指定された個人と、その個人に関連するすべてのデータ モデル オブジェクト/データ レイク オブジェクトからレコードを削除します。
  correct_answer: D
  japanese_explanation: 'Data Cloud は、指定された個人と、その個人に関連するすべてのデータモデルオブジェクト/データレイクオブジェクトからレコードを削除することで、個人の「忘れられる権利」を処理します。つまり、Data
    Cloud は、ソースオブジェクト、統合された個人プロファイル、および関連オブジェクトのデータを含む、個人に関連付けられたすべてのデータをデータスペースから削除します。また、個人とソースレコードをリンクする統合個人リンクレコードも削除します。Data
    Cloud は、Consent API を使用して「忘れられる権利」リクエストを処理します。これらのリクエストは、完全な削除を確実にするために、30 日、60
    日、90 日ごとに再処理されます。

    その他のオプションは、データクラウドが個人の忘れられる権利をどのように処理するかについて正しく説明していません。データクラウドは、ソースシステムのデータの整合性と可用性に影響を与えるため、すべてのデータソースオブジェクトからレコードを削除することはありません。また、データクラウドは、指定された個人レコードとその統合個人リンクレコードのみを削除することもありません。そうすると、ソースレコードと関連レコードがそのまま残ってしまうためです。さらに、データクラウドは、指定された個人と、その個人データモデルオブジェクトにマッピングされたデータソースオブジェクトからのレコードのみを削除することもありません。そうすると、関連レコードがそのまま残ってしまうためです。

    参考文献:

    * データ削除または忘れられる権利の要求

    * データクラウドのデータ削除

    * Data Cloud で Consent API を使用する

    * データクラウドにおけるデータとアイデンティティ'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 97
  question_text: '顧客は、データ ウェアハウスのトランザクション データを Data Cloud で使用したいと考えています。

    データのエクスポートは SFTP サイト経由でのみ可能です。

    ファイルを Data Cloud に取り込むにはどうすればよいでしょうか?'
  choices:
    A: SFTP コネクタを使用してファイルを取り込みます。
    B: Cloud Storage Connector を介してファイルを取り込みます。
    C: データ インポート ウィザードを使用してファイルを手動でインポートします。
    D: Salesforce の Dataloader アプリケーションを使用して、デスクトップから一括アップロードを実行します。
  correct_answer: A
  japanese_explanation: 'SFTP コネクタは、Data Cloud が SFTP サーバーからデータを取り込むことを可能にするデータ ソース
    コネクタです。

    お客様はSFTPコネクタを使用してエクスポートしたファイルからデータストリームを作成し、それをデータレイクオブジェクトとしてData Cloudに取り込むことができます。他の方法は、以下の理由から、ファイルをData
    Cloudに取り込む最適な方法ではありません。

    * B. Cloud Storage Connectorは、Data CloudがAmazon S3、Azure Storage、Google Cloud
    Storageなどのクラウドストレージサービスからデータを取り込むことを可能にするデータソースコネクタです。お客様のデータはこれらのサービスには保存されておらず、SFTPサイトにのみ保存されています。

    * C. データインポートウィザードは、取引先、取引先責任者、リード、ソリューション、キャンペーンメンバーなど、多くの標準Salesforceオブジェクトのデータをインポートできるツールです。SFTPサイトからのデータのインポートや、Data
    Cloud内のカスタムオブジェクトのインポートには対応していません。

    * D. データローダーは、Salesforceレコードの挿入、更新、削除、エクスポートを可能にするアプリケーションです。SFTPサイトやData Cloudからデータを取り込むためのものではありません。参考資料：SFTPコネクタ
    - Salesforce、Data CloudでSFTPコネクタを使用してデータストリームを作成する - Salesforce、データインポートウィザード
    - Salesforce、Salesforceデータローダー'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 98
  question_text: 'Northern Trail Outfittersは、過去24時間以内に商品を購入した顧客をセグメント化したいと考えています。セグメントデータは可能な限り最新のものにする必要があります。

    セグメントを作成するときにコンサルタントは何を実装する必要がありますか?'
  choices:
    A: ストリーミング インサイトを使用して、ほぼリアルタイムのセグメンテーション結果を取得します。
    B: Einstein セグメンテーション最適化を使用して、過去 24 時間のデータを収集します。
    C: 公開間隔が 1 時間の高速セグメントを使用します。
    D: 公開間隔が 30 分の標準セグメントを使用します。
  correct_answer: A
  japanese_explanation: 'Northern Trail Outfitters の要件である、過去 24 時間以内に購入した顧客でセグメントを作成し、かつデータを可能な限り最新の状態に保つには、ストリーミングインサイトが最適なソリューションです。その理由は次のとおりです。

    ストリーミングインサイトの理解:

    Salesforce Data Cloud は、ほぼリアルタイムのデータ処理とセグメンテーションを可能にする Streaming Insights を提供します。この機能により、企業は顧客とのやり取りや取引をほぼ瞬時に把握し、それに応じた対応をとることができるため、最近の購入者の特定など、時間的制約が厳しいユースケースに最適です。

    他の選択肢はないのでしょうか?

    オプションB（Einstein Segmentation Optimization）：Einstein Segmentation Optimizationは、AIを用いたセグメントパフォーマンスの向上に重点を置いていますが、本質的にはほぼリアルタイムのデータ更新を提供するものではありません。低レイテンシのデータ可用性の確保よりも、既存のセグメントの改良に重点を置いています。

    オプションC（公開間隔が1時間の高速セグメント）：高速セグメントは標準セグメントよりも高速ですが、公開間隔による遅延が発生します。1時間の間隔では「可能な限り最新の情報」という要件を満たしません。

    オプションD（公開間隔30分の標準セグメント）：標準セグメントは処理頻度が低く、通常は遅延が長くなります。30分間隔であっても、このオプションではストリーミングインサイトのほぼリアルタイム機能には匹敵しません。

    ストリーミングインサイトの仕組み:

    Streaming Insights は、接続されたソース (CRM、外部システムなど) からのデータをほぼリアルタイムで処理します。

    顧客が購入すると、トランザクション データが Data Cloud に取り込まれ、すぐにセグメンテーションに利用できるようになります。

    コンサルタントは、購入タイムスタンプが過去 24 時間以内に該当する顧客のみを含めるようにセグメント ルールを設定できます。

    Salesforce ドキュメントリファレンス:

    Salesforceの公式Data Cloudドキュメントによると、Streaming Insightsは、タイムリーなデータが不可欠なシナリオ向けに設計されています。これにより、セグメントは大幅な遅延なく最新の顧客行動を反映することができ、Northern
    Trail Outfittersのニーズに完全に合致しています。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 99
  question_text: '顧客には、Salesforce CRM の標準の連絡先オブジェクトに関連するカスタムの顧客電子メール c オブジェクトがあります。

    このカスタムオブジェクト

    アクティベーションに使用する連絡先の電子メール アドレスを保存します。

    どのデータ エンティティがマップされていますか?'
  choices:
    A: 連絡先
    B: 連絡先メールアドレス
    C: カスタム顧客 Email__c オブジェクト
    D: 個人
  correct_answer: B
  japanese_explanation: 'Contact Point_Email オブジェクトは、Data Cloud 内の個人に関連付けられたメールアドレスを表すデータエンティティです。これは、顧客データの共通エンティティとリレーションシップを定義する標準化されたデータモデルである
    Customer 360 データモデルの一部です。Contact Point_Email オブジェクトは、Salesforce CRM 内のメールアドレスを格納する任意のカスタムオブジェクトまたは標準オブジェクト（カスタム
    Customer Email__c オブジェクトなど）にマッピングできます。その他のオプションは、以下の理由により、マッピングする適切なデータエンティティではありません。

    * A. 連絡先オブジェクトは、Salesforce CRM の顧客、パートナー、または競合他社の取引先に関連付けられた個人を表すデータエンティティです。Data
    Cloud のメールアドレスを表すデータエンティティではありません。

    * C. カスタム Customer Email__c オブジェクトは、Data Cloud のデータエンティティではなく、Salesforce CRM のカスタムオブジェクトです。Contact
    Point_Email オブジェクトなどの Data Cloud のデータエンティティにマッピングできますが、それ自体はデータエンティティではありません。

    * D. 個人オブジェクトは、Data Cloud において固有の個人を表すデータエンティティです。同意とプライバシー設定を管理するための中核エンティティであり、メールアドレス、電話番号、ソーシャルメディアのハンドルなど、1
    つ以上のコンタクトポイントに関連付けることができます。Data Cloud においてメールアドレスを表すデータエンティティではありません。参考資料：Customer
    360 データモデル：個人とコンタクトポイント - Salesforce、Contact Point_Email | Salesforce Platform
    のオブジェクトリファレンス | Salesforce Developers、

    [連絡先 | Salesforce プラットフォームのオブジェクトリファレンス | Salesforce 開発者]、[個人 | Salesforce プラットフォームのオブジェクトリファレンス
    | Salesforce 開発者]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 100
  question_text: 'コンサルタントは、携帯電話番号を含むプロフィール情報を持つデータ ストリームの取り込みを計画しています。

    今後のSMSキャンペーンで電話番号を確実に使用できるようにするには、電話番号フィールドが適切なE164電話番号形式であることを確認する必要があります。しかし、ファイル内の電話番号の形式は様々であるようです。

    さまざまな電話番号の形式が標準化されていることを保証する最も効率的な方法は何ですか?'
  choices:
    A: 形式を標準化するための数式フィールドを作成します。
    B: Data Cloud に送信する前に、ソース システムでデータを編集および更新します。
    C: データ ストリームを作成するときに、PhoneNumber フィールド タイプを割り当てます。
    D: 取り込み後に計算されたインサイトを作成します。
  correct_answer: C
  japanese_explanation: さまざまな電話番号形式を標準化するための最も効率的な方法は、データストリームの作成時にPhoneNumberフィールドタイプを割り当てることです。PhoneNumberフィールドタイプは、電話番号を国際標準の電話番号であるE164形式に自動変換する特別なフィールドタイプです。E164形式は、プラス記号（+）、国番号、国内番号で構成されます。例えば、+1-202-555-1234は米国の電話番号のE164形式です。PhoneNumberフィールドタイプを使用することで、コンサルタントは電話番号の一貫性を確保し、将来のSMSキャンペーンに使用できるようにすることができます。他のオプションは、時間がかかり、手動による介入が必要になり、フォーマットの問題に対処できません。参考資料：データストリームのフィールドタイプ、E164電話番号形式、Salesforce
    Data Cloud試験問題
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 101
  question_text: '個人にセグメントを作成するときに、以下に示すように AND でリンクされた 2 つの個別のコンテナーを使用すると、どのような結果になりますか?

    商品 | 個数 | 最小 | 1

    色 | 等しい | 赤

    そして

    商品 | 個数 | 最小 | 1

    PrimaryProductCategory | 等しい | 靴'
  choices:
    A: 少なくとも1つの「赤色」製品を購入し、さらに少なくとも1足の「靴」を購入した個人
    B: 購入時に単一の品目として「赤い靴」を少なくとも1つ購入した個人
    C: 少なくとも1つの「赤い靴」を購入した個人。他には何も購入していない。
    D: 少なくとも1つの「赤い」製品を購入した、または少なくとも1足の「靴」を購入した個人
  correct_answer: A
  japanese_explanation: '個人にセグメントを作成する際に、AND でリンクされた 2 つの別々のコンテナを使用する場合、その個人はコンテナ内の両方の条件を満たす必要があります。この場合、個人は色属性が「赤」である商品を少なくとも
    1 つ、主要商品カテゴリ属性が「靴」である商品を少なくとも 1 つ購入している必要があります。これらの商品は同一である必要はなく、同じ取引で購入される必要もありません。したがって、正解は
    A です。

    その他のオプションは、異なる論理演算子または条件を意味しているため、正しくありません。オプション B は、色属性が「赤」で、主要製品カテゴリ属性が「靴」である製品を
    1 つだけ購入した必要があることを意味します。オプション C は、色属性が「赤」で、主要製品カテゴリ属性が「靴」である製品を 1 つだけ購入し、他の製品は購入していない必要があることを意味します。オプション
    D は、色属性が「赤」である製品を 1 つ、または主要製品カテゴリ属性が「靴」である製品を 1 つ、あるいはその両方を購入した必要があることを意味します。これは、AND
    演算子ではなく OR 演算子を使用するのと同じです。

    参照：

    セグメンテーション用のコンテナを作成する

    データクラウドでセグメントを作成する

    データクラウドセグメンテーションをナビゲート'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 102
  question_text: City | Is Equal To | 'San Jose' でフィルタリングしたセグメンテーション基準の結果は何ですか?
  choices:
    A: 「San Jose」、「San Jose」、「san jose」、または「san jose」を含む都市
    B: 「San Jose」または「san jose」のみを含む都市
    C: 「San Jose」または「San Jose」のみを含む都市
    D: 「San Jose」または「san jose」のみを含む都市
  correct_answer: D
  japanese_explanation: 「City | Is Equal To | 'San Jose'」でセグメンテーション条件をフィルタリングした結果は、「San
    Jose」または「san jose」を含む都市のみになります。これは、セグメンテーション条件が大文字と小文字を区別し、アクセント記号も区別するため、フィルターに入力された値と完全に一致する場合にのみ一致します1。したがって、「San
    Jose」、「san jose」、「San Jose」を含む都市は、フィルター値と完全に一致しないため、結果に含まれません。「San Jose」という名前に異なるバリエーションを持つ都市を含めるには、OR演算子を使用して複数のフィルター値を追加する必要があります（例：'San
    Jose' OR 'San Jose' OR 'san jose' OR 'san jose'2）。参考：セグメンテーション条件、セグメンテーション演算子
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 103
  question_text: 'Visual Insights Builder を使用して計算されたインサイトを作成するときに必要な 2 つの最小要件は何ですか?

    2つの回答を選択してください'
  choices:
    A: 少なくとも1つの小節
    B: 少なくとも1つの次元
    C: 結合するオブジェクトが少なくとも2つ
    D: WHERE句
  correct_answer: A,B
  japanese_explanation: '* Visual Insights Builder の紹介:

    Salesforce Data Cloud の Visual Insights Builder は、既存のデータから派生したカスタム メトリックである計算されたインサイトを作成するために使用されるツールです。

    参照：

    * 計算された洞察を作成するための要件:

    メジャー: メジャーとは、収益、購入数、プラットフォームで費やされた合計時間など、分析する定量的な値です。

    ディメンション: ディメンションは、日付、地域、顧客セグメントなどのメジャーを分類またはフィルタリングするために使用する質的属性です。

    * 計算された洞察を作成する手順:

    Salesforce Data Cloud 内の Visual Insights Builder に移動します。

    「新しいインサイトを作成」を選択し、データセットを選択します。

    少なくとも 1 つのメジャーを追加します。これは、「総売上高」など、分析したい任意の指標になります。少なくとも 1 つのディメンションを追加します。これは、「地域別売上高」など、メジャーを細分化するのに役立ちます。

    * 実用的な応用:

    例: 「地域別の平均購入額」に関するインサイトを作成するには、次のものが必要です。

    測定基準: 合計購入額。

    ディメンション: 顧客地域。

    これにより、パフォーマンスの高い地域を特定するなど、実用的な洞察が得られます。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 104
  question_text: どのソリューションが、Marketing Cloud の加入者プロファイル属性を毎日 Data Cloud に取り込む簡単な方法を提供しますか?
  choices:
    A: Automation Studio およびプロファイル ファイル API
    B: マーケティングクラウド接続 API
    C: Marketing Cloud データ拡張機能のデータストリーム
    D: Email Studio スターター データ バンドル
  correct_answer: C
  japanese_explanation: '説明​

    Marketing Cloud の購読者プロファイル属性を Data Cloud に日々簡単に取り込むソリューションが、Marketing Cloud データ拡張機能「データストリーム」です。Marketing
    Cloud データ拡張機能「データストリーム」は、Marketing Cloud データ拡張機能から Data Cloud データスペースにデータをストリーミングできる機能です。ストリーミングするデータ拡張機能を選択すると、Data
    Cloud がデータスペース内に対応するデータモデルオブジェクト (DMO) を自動的に作成し、更新します。

    お客様は、ユーザーインターフェースまたはAPIを使用して、データ拡張フィールドをDMO属性にマッピングすることもできます。Marketing Cloudデータ拡張のデータストリームを使用すると、コードを記述したり複雑な統合を設定したりすることなく、Marketing
    CloudからData Cloudにサブスクライバープロファイル属性などのデータを取り込むことができます。

    その他のオプションは、Marketing Cloud の購読者プロファイル属性を Data Cloud に日常的に簡単に取り込むことができるソリューションではありません。Automation
    Studio と Profile file API は、Marketing Cloud から外部システムにデータをエクスポートするために使用できるツールですが、スクリプトの作成、ファイル転送の設定、自動化のスケジュール設定など、お客様自身で行う必要があります。Marketing
    Cloud Connect API は、Sales Cloud や Service Cloud などの他の Salesforce ソリューションで Marketing
    Cloud のデータにアクセスするために使用できる API ですが、Data Cloud へのデータのストリーミングはサポートしていません。Email Studio
    Starter Data Bundle は、Email Studio 用のサンプルデータとセグメントを含むデータキットですが、購読者プロファイル属性は含まれておらず、Data
    Cloud へのデータのストリーミングもサポートされていません。

    参考文献:

    * マーケティングクラウドデータ拡張データストリーム

    * データクラウドデータ取り込み

    * [Marketing Cloud データ拡張データストリーム API]

    * [マーケティングクラウドコネクトAPI]

    * [Email Studio スターター データ バンドル]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 105
  question_text: '顧客はCRMからData Cloudに取り込むためのマスター顧客テーブルを持っています。このテーブルには、氏名、メインのメールアドレス、その他の個人識別情報（PLL）が含まれています。

    ID 解決をサポートするには、フィールドをどのようにマッピングする必要がありますか?'
  choices:
    A: 入力テーブルに直接一致するフィールドを持つ新しいカスタム オブジェクトを作成します。
    B: すべてのフィールドを Customer オブジェクトにマップします。
    C: 名前を個人オブジェクトにマップし、電子メール アドレスを連絡先電話番号電子メール オブジェクトにマップします。
    D: すべてのフィールドを個人オブジェクトにマップし、電子メール アドレスのカスタム フィールドを追加します。
  correct_answer: C
  japanese_explanation: 'Data Cloud で ID 解決をサポートするには、マスター顧客テーブルのフィールドを、この目的のために設計された標準データモデルオブジェクトにマッピングする必要があります。個人オブジェクトは、顧客の名前やその他の個人識別情報
    (PII) を保存するために使用され、連絡先電話番号メールオブジェクトは、顧客の主要なメールアドレスやその他の連絡先情報を保存するために使用されます。これらのオブジェクトは、連絡先情報が個人に属していることを示すリレーションフィールドによってリンクされています。これらのオブジェクトにフィールドをマッピングすることで、Data
    Cloud は ID 解決ルールを使用して、名前とメールアドレスのフィールドに基づいて、さまざまなソースのプロファイルを照合および調整できます。その他のオプションは、標準データモデルに含まれない新しいカスタムオブジェクトを作成するか、すべてのフィールドを
    ID 解決用ではない顧客オブジェクトにマッピングするか、すべてのフィールドを標準のメールアドレスフィールドを持たない個人オブジェクトにマッピングするため、推奨されません。参考資料:
    ID 解決のためのデータモデリング要件、統合された個人プロファイルの作成'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 106
  question_text: 'コンサルタントは、先ほど設定したID解決を確認したいと考えています。統合プロファイルのデータを検証するために、コンサルタントが使用できる2つの機能はどれですか？

    2つの回答を選択してください'
  choices:
    A: アイデンティティ解決
    B: データアクション
    C: データエクスプローラー
    D: クエリAPI
  correct_answer: C,D
  japanese_explanation: 'ID解決の設定後、統合プロファイル上のデータを検証するために、コンサルタントはデータエクスプローラーとクエリAPIを使用できます。その理由は次のとおりです。

    アイデンティティ解決検証について

    ID 解決では、複数のソースからのデータを統合されたプロファイルに結合します。

    統合プロファイルを検証することで、解決プロセスが正しく機能していること、およびデータが正確であることが保証されます。

    データ エクスプローラーとクエリ API を使用する理由

    データエクスプローラー:

    Data Explorer は、Salesforce Data Cloud に組み込まれているツールで、ユーザーは統合されたプロファイルを表示および分析できます。

    解決された ID や関連属性など、個々のプロファイルの詳細なビューを提供します。

    クエリAPI:

    クエリ API を使用すると、統合プロファイルおよび関連データへのプログラムによるアクセスが可能になります。

    コンサルタントは API を使用して特定のプロファイルを照会し、ID 解決の結果をプログラムで検証できます。

    その他のオプションはあまり適していません:

    A. アイデンティティ解決: これは検証のためのツールではなく、プロセスそのものを指します。

    B. データアクション: データアクションは、統合プロファイルの検証ではなく、ワークフローまたは統合をトリガーするために使用されます。

    統合プロファイルを検証する手順

    データエクスプローラーの使用:

    [データ クラウド] > [データ エクスプローラー] に移動します。

    特定のプロファイルを検索し、解決された ID と属性を確認します。

    データが ID 解決ルールに基づいて期待どおりに一致していることを確認します。

    クエリ API の使用:

    クエリ API を使用して、統合プロファイルをプログラムで取得します。

    結果を予想される結果と比較して、正確性を確認します。

    結論

    コンサルタントは、データ エクスプローラーとクエリ API を使用して統合プロファイルのデータを検証し、ID 解決が意図したとおりに機能していることを確認する必要があります。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 107
  question_text: 'Northern Trail Outfitters は、Data Cloud インスタンスで個人を統合します。

    統合プロファイル上のデータを検証するためにコンサルタントが使用できる 3 つの機能はどれですか?

    3つの回答を選択してください'
  choices:
    A: アイデンティティ解決
    B: APL をクエリする
    C: データエクスプローラー
    D: プロファイルエクスプローラー
    E: データアクション
  correct_answer: A,C,D
  japanese_explanation: '統合プロファイル上のデータを検証するために、コンサルタントは次の機能を使用できます。

    アイデンティティ解決: この機能により、コンサルタントは、さまざまなデータ ソースから個人を統合する方法を決定するアイデンティティ解決ルール セットを表示および編集できます1。

    データ エクスプローラー: この機能により、コンサルタントは統合プロファイルを参照およびフィルタリングし、その属性、セグメント、アクティビティを表示できます2。

    プロファイルエクスプローラー：この機能により、コンサルタントは特定の統合プロファイルをドリルダウンし、ソースレコード、アイデンティティグラフ、計算されたインサイト、データアクションなどの詳細を表示できます3。参考：

    1: データクラウドにおけるID解決

    2: データクラウドのデータエクスプローラー

    3: データクラウドのプロファイルエクスプローラー'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 108
  question_text: 'Cumulus Financialは現在、Data Cloudを活用し、S3コネクタを介してバックエンドシステムから取引データをアップサートモードで取り込みています。6ヶ月前の初期設定時に、同社はData
    Cloudにカスタム分類を作成するための数式フィールドを作成しました。現在、より多くの分類に対応するために、この数式を更新する必要があります。

    S3 コネクタを使用する場合、コンサルタントは数式フィールドの更新に関してどのような点に留意する必要がありますか?'
  choices:
    A: Data Cloud は $3 からデータの完全更新を開始し、すべてのレコードの数式を更新します。
    B: Data Cloud は、新しいレコードに対してのみ、今後数式を更新します。
    C: Data Cloud は、upsert タイプのデータ ストリームの数式フィールドの更新をサポートしていません。
    D: Data Cloud は、次回の増分アップサート更新時にすべてのレコードの数式を更新します。
  correct_answer: D
  japanese_explanation: '数式フィールドとは、他のフィールドまたは定数に基づいて値を計算するフィールドです。S3 コネクタを使用して Amazon
    S3 バケットからデータを取り込む場合、Data Cloud は、S3 ソースのデータを格納するデータレイクオブジェクト (DLO) 上の数式フィールドの作成と更新をサポートします。ただし、数式フィールドの更新はすぐには適用されず、データストリームの次回の増分アップサート更新時に適用されます。増分アップサート更新とは、主キーフィールドに基づいて、S3
    ソースから DLO に新しいレコードを追加し、既存のレコードを更新するプロセスです。したがって、コンサルタントは、数式フィールドの更新は新しいレコードと既存のレコードの両方に影響しますが、データストリームの次回の増分アップサート更新後にのみ適用されることを念頭に置く必要があります。Data
    Cloud は S3 からのデータの完全更新を開始せず、新しいレコードに対してのみ数式を更新せず、アップサートタイプのデータストリームに対する数式フィールドの更新をサポートしているため、他のオプションは正しくありません。参考資料:
    数式フィールドの作成、Amazon S3 接続、Data Lake オブジェクト'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 109
  question_text: '正常に構成された Amazon S3 データストリームが「ファイルが見つかりません」というエラーメッセージで更新に失敗した場合、コンサルタントが実行する必要がある
    2 つの手順はどれですか?

    2つの回答を選択してください'
  choices:
    A: Data Cloud ユーザーに正しい権限が設定されているかどうかを確認します。
    B: Data Cloud セットアップで Amazon S3 データ ソースが有効になっているかどうかを確認します。
    C: 指定されたバケットの場所にファイルが存在するかどうかを確認します。
    D: S3 ユーザーに正しい権限が設定されているかどうかを確認します。
  correct_answer: A,C
  japanese_explanation: '「ファイルが見つかりません」というエラーメッセージは、Data Cloud が Amazon S3 ソースのファイルにアクセスできない、またはファイルを見つけられないことを示します。このエラーには
    2 つの原因が考えられ、コンサルタントがトラブルシューティングを行うために実行する必要がある 2 つの手順があります。

    Data Cloud ユーザーに、Amazon S3 バケットからファイルを読み取るための適切な権限がありません。これは、ユーザーの権限セットまたはプロファイルに
    Data Cloud データストリームの読み取り権限が含まれていない場合、またはユーザーの Amazon S3 認証情報が無効または期限切れの場合に発生する可能性があります。この問題を解決するには、コンサルタントが
    Data Cloud と Amazon S3 でそれぞれユーザーの権限と認証情報を確認し、更新する必要があります。

    指定されたバケットの場所にファイルが存在しません。ファイル名またはパスが変更された場合、またはファイルがAmazon S3バケットから削除または移動された場合に発生する可能性があります。この問題を解決するには、コンサルタントはAmazon
    S3バケット内のファイル名とパスを確認し、それに応じてData Cloudのデータストリーム設定を更新する必要があります。参考資料：Data CloudでAmazon
    S3データストリームを作成する、Data CloudでAmazon S3ストレージコネクタを使用する方法、Amazon S3接続'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 110
  question_text: セグメンテーションまたはアクティベーションを実行する場合、データの公開と更新にはどのタイムゾーンが使用されますか?
  choices:
    A: アクティビティ作成時に指定されたタイムゾーン
    B: アクティビティを作成したユーザーのタイムゾーン
    C: データクラウド管理者ユーザーのタイムゾーン
    D: Salesforce Data Cloud 組織によって設定されたタイムゾーン
  correct_answer: D
  japanese_explanation: セグメンテーションまたはアクティベーションを実行する際にデータの公開と更新に使用されるタイムゾーンはDです。Salesforce
    Data Cloud組織によって設定されるタイムゾーンです。このタイムゾーンは、Data Cloudのプロビジョニング時に組織設定で設定されるもので、Data
    Cloud内のすべてのユーザーとアクティビティに適用されます。このタイムゾーンによって、セグメントの更新スケジュールとアクティベーションの公開スケジュールが決まります。したがって、セグメンテーションとアクティベーションの戦略を計画する際には、Data
    Cloud組織と対象システムまたはチャネル間のタイムゾーン差を考慮することが重要です。参考：Salesforce Data Cloudコンサルタント試験ガイド、セグメンテーション、アクティベーション
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 111
  question_text: 'Northern Trail Outfitters (NTO) は、あいまい名と正規化された電子メールに基づいて ID 解決ルール
    セットを構成しています。

    最適な電子メール アドレスが確実にアクティブ化されるようにするには、NTO は何をすべきでしょうか?'
  choices:
    A: 連絡先メール オブジェクトの Is Active フィールドを一致ルールとして含めます。
    B: アクティベーションでソースの優先順位を使用して、目的のソースからのコンタクト ポイントがアクティベーション ターゲットに配信されるようにします。
    C: ソース優先度調整ルールで、Marketing Cloud が最初のデータ ソースとして優先されていることを確認します。
    D: デフォルトの調整ルールを「最終更新日」に設定します。
  correct_answer: B
  japanese_explanation: NTOは、あいまい名前と正規化されたメールアドレスを一致ルールとして使用し、異なるソースからのデータを統合された個人プロファイルにリンクしています。しかし、複数のソースから同じメールアドレスが取得される場合があり、NTOはアクティベーションに使用するアドレスを決定する必要があります。例えば、レイチェルがService
    CloudとMarketing Cloudに同じメールアドレスを持っているものの、NTOからの連絡をMarketing Cloud経由で受信することを希望している場合、NTOはMarketing
    Cloudのメールアドレスがアクティベーションされるようにする必要があります。そのために、NTOはアクティベーションにおいてソースの優先順位を使用できます。これにより、アクティベーションの優先順位に従ってデータソースをランク付けできます。Marketing
    CloudをService Cloudよりも高いソース優先順位に設定することで、NTOはMarketing Cloudのメールアドレスがメールキャンペーンやジャーニーなどのアクティベーション対象に確実に配信されるようにすることができます。これにより、NTOはレイチェルの希望を尊重し、より良いカスタマーエクスペリエンスを提供できます。参考資料：アクティベーションの設定、アクティベーションにおけるソースの優先順位の使用
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 112
  question_text: Amazon S3 にアクティブ化するときに .csv ファイルで提供される情報はどれですか?
  choices:
    A: セグメントをアクティブ化したユーザーとアクティブ化した日時を示す監査ログ
    B: アクティブ化されたデータペイロード
    C: セグメント定義に関するメタデータ
    D: Data Cloud 内のオリジンソースのマニフェスト
  correct_answer: B
  japanese_explanation: Amazon S3 にアクティブ化する場合、.csv ファイルで提供される情報は、アクティブ化データペイロードです。アクティブ化データペイロードは、Data
    Cloud からアクティブ化ターゲット (この場合は Amazon S3 バケット) に送信されるデータです1。アクティブ化データペイロードには、アクティブ化されるセグメントに含まれる個人またはエンティティの属性と値が含まれます2。アクティブ化データペイロードは、マーケティング、営業、サービス、分析など、さまざまな目的に使用できます3。その他のオプションは、Amazon
    S3 にアクティブ化するときに .csv ファイルで提供されないため、正しくありません。オプション A は、監査ログが .csv ファイルで提供されないため、正しくありませんが、Data
    Cloud UI の [アクティベーション履歴] タブで表示できます4。オプション C は、セグメント定義に関するメタデータが .csv ファイルで提供されないため、正しくありませんが、Data
    Cloud UI の [セグメンテーション] タブで表示できるため、正しくありません5。選択肢Dは不正解です。データクラウド内のオリジンソースのマニフェストは.csvファイルでは提供されていませんが、データクラウドUIの「データソース」タブで確認できます。参考資料：データアクティベーションの概要、データクラウドでのセグメントの作成とアクティベーション、データアクティベーションのユースケース、アクティベーション履歴の表示、セグメンテーションの概要、[データソースの概要]
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 113
  question_text: 'Cumulus Financialの採用チームは、過去24時間以内にウェブサイトの求人ページを2回以上閲覧した候補者を特定したいと考えています。これらの候補者に関する情報をData
    Cloudでセグメンテーションに利用し、採用システムに追加したいと考えています。

    この目標を達成するためにコンサルタントはどの機能を推奨すべきでしょうか?'
  choices:
    A: ストリーミングデータ変換
    B: ストリーミングの洞察
    C: 計算された洞察力
    D: バッチバタ変換
  correct_answer: B
  japanese_explanation: 'ストリーミングインサイトは、ウェブやモバイルイベントなどのストリーミングデータソースからリアルタイムのメトリクスを作成・監視できる機能です。また、ストリーミングインサイトは、メトリクスの値と条件に基づいて、通知の送信、レコードの作成、フィールドの更新といったデータアクションをトリガーすることもできます。したがって、ストリーミングインサイトは、過去24時間以内にウェブサイトの求人ページを2回以上閲覧した候補者を特定し、採用システムに追加するという目標を達成するのに最適な機能です。その他の選択肢は、以下の理由により誤りです。

    * ストリーミングデータ変換は、SQL式を使用してストリーミングデータを変換・拡充できる機能です。フィルタリング、結合、集計、値の計算などが可能です。ただし、ストリーミングデータ変換では、メトリクスを監視したり、条件に基づいてデータアクションをトリガーしたりすることはできません。

    * 計算インサイトとは、SQL式を用いてLTV、CSAT、平均注文額といった多次元指標をデータから定義・計算できる機能です。ただし、計算インサイトはスケジュールに基づいて実行され、データソースをサポートしていないため、リアルタイムデータ分析には適していません。

    * アクション。

    * バッチ データ変換は、データの結合、集計、フィルタリング、追加など、ビジュアル エディターを使用して複雑なデータ変換を作成およびスケジュールできる機能です。

    ただし、バッチ データ変換はスケジュールに基づいて実行され、データアクションをサポートしていないため、リアルタイムのデータ分析には適していません。参考資料:
    ストリーミング インサイト、ストリーミング インサイトの作成、データクラウドでのインサイトの使用、データクラウド インサイトの学習、SQL を使用したデータクラウド
    インサイト、ストリーミング データ変換、データクラウドでのバッチ データ変換の開始、バッチ データ変換の変換、データクラウドでのバッチ データ変換: クイック
    ルック、Salesforce データクラウド: AI CDP。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 114
  question_text: 'Northern Trail Outfitters（NTO）は、過去6ヶ月以内に商品を購入した顧客を対象にプロモーションキャンペーンを実施したいと考えています。コンサルタントはこの要件を満たすセグメントを作成しました。

    現在、NTO は過去 1 週間以内に購入した顧客を抑制するための追加要件を導入しています。

    コンサルタントは最近の顧客を削除するために何を使用すべきでしょうか?'
  choices:
    A: バッチ変換
    B: セグメンテーション除外ルール
    C: 関連属性
    D: ストリーミングの洞察
  correct_answer: B
  japanese_explanation: 'コンサルタントは、B. セグメンテーション除外ルールを使用して最近の顧客を除外する必要があります。セグメンテーション除外ルールは、特定の条件を満たすレコードを除外するためにセグメントに適用できるフィルターです。コンサルタントは、セグメンテーション除外ルールを使用して、過去6ヶ月以内に購入した顧客を含むセグメントから、過去1週間以内に購入した顧客を除外することができます。これにより、セグメントにはプロモーションキャンペーンの対象となる顧客のみが含まれます。

    その他の選択肢は正しくありません。選択肢Aは不正解です。バッチ変換は、データストリームまたはデータレイクオブジェクトに適用してデータを変更または拡充できるデータ処理タスクです。バッチ変換はセグメンテーションやアクティベーションには使用されません。選択肢Cは不正解です。関連属性は、データモデルオブジェクト間の関係から派生する属性です。関連属性は、セグメントからレコードを除外するために使用されません。選択肢Dは不正解です。ストリーミングインサイトは、データ取り込み時に計算される派生属性です。ストリーミングインサイトは、セグメントからレコードを除外するために使用されません。参考資料：Salesforce
    Data Cloud Consultant 試験ガイド、セグメンテーション、セグメンテーション除外ルール'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 115
  question_text: 'Northern Trail Outfitters は、Data Cloud に取り込まれる新しい顧客データを毎日 Amazon
    S3 バケットにアップロードします。

    新しくインポートされたデータがどのセグメントでも使用可能であることを確認するには、各プロセスをどのような順序で実行する必要がありますか?'
  choices:
    A: 計算されたインサイト > データストリームの更新 > ID解決
    B: データストリームの更新 > 計算された洞察 > ID解決
    C: アイデンティティ解決 > データストリームの更新 > 計算された洞察
    D: データストリームの更新 > アイデンティティ解決 > 計算された洞察
  correct_answer: D
  japanese_explanation: 'Amazon S3 バケットから新しくインポートされたデータが準備完了し、どのセグメントでも使用できるようにするには、次のプロセスをこの順序で実行する必要があります。

    データストリームの更新：このプロセスは、ソースシステムからの最新データでデータクラウド内のデータレイクオブジェクトを更新します。データストリーム設定1に応じて、自動または手動で実行するように設定できます。データストリームを更新することで、Amazon
    S3バケットからの最新かつ正確なデータがデータクラウドに確実に提供されます。

    アイデンティティ照合：このプロセスは、アイデンティティ照合ルールセットに基づいて、異なるデータストリームからのソースプロファイルを照合・統合することで、統合された個人プロファイルを作成します。デフォルトでは毎日実行されますが、手動で実行することも可能です2。アイデンティティ照合により、Data
    Cloudは異なるデータソースにまたがる各顧客の単一ビューを確保します。

    計算されたインサイト：このプロセスは、データレイクオブジェクトまたはCRMデータに対して計算を実行し、結果を新しいデータオブジェクトとして返します。セグメンテーションや分析のための指標や指標の作成に使用できます3。計算されたインサイトにより、パーソナライゼーションやアクティベーションに使用できる派生データがData
    Cloudに確実に提供されます。

    参照：

    1: データストリームの更新と頻度を設定する - Salesforce

    2: アイデンティティ解決ルールセットの処理結果 - Salesforce

    3: 計算された洞察 - Salesforce'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 116
  question_text: '顧客は、閲覧放棄行動に基づいてジャーニーをトリガーするための要件を概説しました。コンサルタントは、この要件に基づき、ストリーミングインサイトを使用して、Journey
    Builderへのデータアクションを1時間ごとにトリガーすることを決定しました。

    データアクションが必要な頻度でトリガーされるようにするには、コンサルタントはどのようにソリューションを構成する必要がありますか?'
  choices:
    A: アクティベーションスケジュールを時間ごとに設定します。
    B: データを 1 時間ごとに一括して取り込むように設定します。
    C: 旅程エントリスケジュールを 1 時間ごとに実行するように設定します。
    D: インサイトの集計時間ウィンドウを 1 時間に設定します。
  correct_answer: C
  japanese_explanation: 'Explanation:'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 117
  question_text: 'コンサルタントは、Amazon 53 がアクティブ化したキャンペーンを顧客の送信先システムに統合しています。

    宛先システムがセグメントに関するメタデータを見つけるために、処理用のこの情報は 53 のどのファイルに含まれますか?'
  choices:
    A: .txt ファイル
    B: jsonファイル
    C: .csvファイル
    D: .zipファイル
  correct_answer: B
  japanese_explanation: 'Amazon S3 上のファイルで、処理対象となるセグメントのメタデータが含まれるファイルは B. json ファイルです。json
    ファイルは、セグメントが Amazon S3 でアクティベートされた際に csv ファイルと共に生成されるメタデータファイルです。json ファイルには、セグメント名、セグメント
    ID、セグメントサイズ、セグメント属性、セグメントフィルタ、セグメントスケジュールなどの情報が含まれています。宛先システムはこのファイルを使用して、セグメントとそのプロパティを識別し、セグメントデータを宛先システムの対応するフィールドと照合することができます。参考資料:
    Salesforce Data Cloud Consultant 試験ガイド、Amazon S3 アクティベーション'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 118
  question_text: データ ストリームを取り込むときに数式を作成する理由は何ですか?
  choices:
    A: ファイルを連結して正しい順序で取り込まれるようにする
    B: 既存のルールセットに一意の外部識別子を追加する
    C: データマッピングで使用するために、日付時刻フィールドをデールフィールドに変換します。
    D: データストリームから重複するデータ行を削除します
  correct_answer: C
  japanese_explanation: 'データストリームの取り込み中に数式を作成するのは、多くの場合、特定の要件を満たすためにデータフィールドを操作または変換するためです。この場合、最も一般的な理由は、データマッピングで使用するために日時フィールドを日付フィールドに変換することです。その理由は次のとおりです。

    要件を理解する

    Salesforce Data Cloud にデータを取り込む場合、ターゲット データ モデルに合わせて特定のフィールドを変換する必要がある場合があります。

    たとえば、適切なマッピングと分析を行うには、日時フィールド (例: 「2023-10-05T14:30:00Z」) を日付フィールド (例: 「2023-10-05」)
    に変換する必要がある場合があります。

    日時フィールドを日付フィールドに変換する理由は何ですか?

    データマッピングの互換性:

    一部のデータ モデルまたは下流システムでは、日付フィールド (時間コンポーネントなし) のみが受け入れられる場合があります。

    フィールドを変換すると互換性が確保され、取り込み時またはアクティベーション時のエラーを回避できます。

    簡略化された分析：

    時間コンポーネントを削除すると、特に日次傾向や集計を扱う場合に、分析とレポートが簡素化されます。

    標準化：

    日付/時刻フィールドを一貫した日付形式に変換すると、データセット全体の一貫性が確保されます。

    このソリューションを実装する手順

    ステップ1: 日時フィールドを特定する

    データ ストリームのセットアップ中に、日時値 (例: 「Order_Date_Time」) を含むフィールドを識別します。

    ステップ2: 数式フィールドを作成する

    新しいフィールドを作成するには、データ ストリーム構成の「数式フィールド」オプションを使用します。

    変換関数 (DATE() または同等のもの) を適用して、日付時刻フィールドから日付部分を抽出します。

    ステップ3: 変換されたフィールドをマップする

    新しく作成された日付フィールドを、ターゲット データ モデル (統合プロファイルやデータ レイク オブジェクトなど) 内の対応するフィールドにマップします。

    ステップ4: 変換を検証する

    データ ストリームをテストして、変換が正しく機能し、日付フィールドが適切に取り込まれていることを確認します。

    他の選択肢はないのでしょうか?

    A . ファイルを連結して正しい順序で取り込まれるようにするには:

    連結は、取り込み時に数式を使用する典型的なケースではありません。ファイルの順序付けは通常、数式ではなく、ファイル取り込みレベルで処理されます。

    B. 既存のルールセットに一意の外部識別子を追加するには:

    一意の識別子の追加は、通常、取り込み時の数式を通じてではなく、データの準備中または ID 解決中に行われます。

    D. データストリームから重複するデータ行を削除するには:

    重複の削除は、数式ではなく、重複排除ルールまたは変換を通じて処理する方が適切です。

    結論

    データストリームを取り込む際に数式を作成する主な理由は、データマッピングで使用するために、日時フィールドを日付フィールドに変換することです。これにより、互換性が確保され、分析が簡素化され、下流での使用に向けてデータが標準化されます。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 119
  question_text: 'Northern Trail Outfitters のマーケティング マネージャーは、データ クラウド セグメント インテリジェンスからの分析情報を活用して、マーケティングの投資収益率
    (ROI) を向上したいと考えています。

    これを設定するには、ユーザーはどの権限セットが必要ですか?'
  choices:
    A: クラウドマーケティングマネージャー
    B: データクラウド データアウェア スペシャリスト
    C: データクラウド管理者
    D: データクラウドユーザー
  correct_answer: C
  japanese_explanation: ''
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 120
  question_text: セグメンテーションと計算されたインサイトでの時間ベースの操作にデータを使用するには、どのデータ ストリーム カテゴリを割り当てる必要がありますか?
  choices:
    A: 個人
    B: トランザクション
    C: 販売注文
    D: エンゲージメント
  correct_answer: B
  japanese_explanation: 'データストリームとは、Data Cloud に取り込まれ、データモデルにマッピングされるデータのソースです。データストリームには様々なカテゴリがあり、Data
    Cloud におけるデータの処理方法と使用方法を決定します。

    トランザクションデータストリームは、日付範囲によるフィルタリング、期間による集計、イベント発生までの時間指標の計算など、セグメンテーションや計算によるインサイトにおける時間ベースの操作に使用されます。トランザクションデータストリームは通常、購入、クリック、訪問など、タイムスタンプと値が関連付けられたイベントデータに使用されます。参考資料：データストリーム、データストリームのカテゴリ'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 121
  question_text: 'コンサルタントは、複数のDLOに基づいてデータグラフを作成する必要があります。

    これを実現するためにコンサルタントはどのようなステップを踏むべきでしょうか?'
  choices:
    A: データアクションを使用して、DLOデータでデータグラフを更新します。
    B: DLOS を DMOS にマップし、これをデータ グラフで使用します。
    C: DLO をデータ グラフに直接マップします。
    D: DLO を複数の DMO にバッチ変換し、データ グラフでアクティブ化します。
  correct_answer: B
  japanese_explanation: '複数のデータレイクオブジェクト（DLO）に基づくデータグラフを作成するには、コンサルタントはDLOをデータモデルオブジェクト（DMO）にマッピングし、データグラフで使用する必要があります。その理由は次のとおりです。

    データグラフを理解する

    Salesforce Data Cloud のデータ グラフは、エンティティ (顧客、アカウント、注文など) とその属性間の関係を表します。

    これは、統合されたプロファイルと関連データに標準化された構造を提供するデータ モデル オブジェクト (DMO) を使用して構築されます。

    DLO を DMO にマッピングする理由は何ですか?

    DLOとDMOの役割：

    DLO は、Data Cloud に取り込まれた生のデータ ソースです。

    DMO は、ID 解決と統合プロファイルに使用される標準化されたオブジェクトです。

    DLO を DMO にマッピングすると、生のデータがデータ グラフに適した構造化された形式に変換されます。

    データグラフの構築:

    DLO が DMO にマップされると、コンサルタントは DMO を使用して関係を定義し、データ グラフを構築できます。

    このアプローチにより、統一されたデータ モデルとの一貫性と整合性が確保されます。

    その他のオプションはあまり適していません:

    A . データ アクションを使用して、DLO データでデータ グラフを更新します。データ アクションは、データ グラフの構築ではなく、ワークフローのトリガーに使用されます。

    C . DLO をデータ グラフに直接マップする: DLO はデータ グラフに直接マップできないため、最初に DMO に変換する必要があります。

    D. DLO を複数の DMO にバッチ変換し、データ グラフでアクティブ化します。これは、DLO を DMO にマッピングするだけで十分な場合は、過度に複雑で不要です。

    データグラフを作成する手順

    ステップ1: DLOをDMOにマッピングする

    「データ クラウド」>「データ ストリーム」に移動し、DLO の関連フィールドを対応する DMO にマップします。

    ステップ2: 関係を定義する

    データ モデル タブを使用して、DMO 間の関係 (個人とアカウントのリンクなど) を定義します。

    ステップ3: データグラフを構築する

    マップされた DMO を使用してデータ グラフを作成し、ノード (エンティティ) とエッジ (リレーションシップ) を定義します。

    ステップ4: グラフを検証する

    データ グラフをテストして、目的の関係とデータ フローが正確に表現されていることを確認します。

    結論

    コンサルタントは、DLO を DMO にマッピングし、それをデータ グラフで使用して、エンティティ間の関係を構築するための構造化された一貫性のあるアプローチを確保する必要があります。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 122
  question_text: 'あるクライアントは、Salesforce CRMのカスタムオブジェクトからロイヤルティデータをインポートしたいと考えています。このオブジェクトには、ホテルポイントと航空会社ポイントのポイント残高が同一レコード内に格納されています。クライアントは、これらのポイントシステムを2つの別々のレコードに分割することで、追跡と処理を効率化したいと考えています。

    このシナリオではコンサルタントは何を推奨すべきでしょうか?'
  choices:
    A: データ ソース オブジェクトを複製します。
    B: バッチ変換を使用して 2 番目のデータ レイク オブジェクトを作成します。
    C: Salesforce CRM でジャンクション オブジェクトを作成し、取り込み戦略を変更します。
    D: データレイク オブジェクトからデータキットを作成し、同じ Data Cloud 組織にデプロイします。
  correct_answer: B
  japanese_explanation: バッチ変換は、既存のデータレイクオブジェクトに基づいて新しいデータレイクオブジェクトを作成し、それらに変換を適用できる機能です。これは、データモデルやビジネス要件に合わせてデータを分割、結合、または再形成する場合に役立ちます。この場合、コンサルタントはバッチ変換を使用して、元のロイヤルティデータオブジェクトから航空会社のポイントのみを含む2つ目のデータレイクオブジェクトを作成できます。元のオブジェクトは、ホテルのポイントのみを含むように変更できます。これにより、クライアントはポイントシステムごとに2つの個別のレコードを作成し、それらを適切に追跡および処理できます。参考資料：バッチ変換、バッチ変換の作成
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 123
  question_text: セグメントを再度使用する目的でセグメントのアクティベーションを一時停止するには、ユーザーは何をすればよいですか?
  choices:
    A: セグメントを非アクティブ化します。
    B: セグメントを削除します。
    C: アクティベーションをスキップします。
    D: 公開スケジュールを停止します。
  correct_answer: A
  japanese_explanation: '正解はAです。セグメントを非アクティブ化します。不要になったセグメントは、Data Cloudから非アクティブ化でき、選択したすべてのターゲットに適用されます。非アクティブ化されたセグメントはパブリッシュされなくなりますが、いつでも再アクティブ化できます1。このオプションを使用すると、ユーザーはセグメントのアクティブ化を一時停止し、そのセグメントを再度使用できるようになります。

    その他のオプションは、次の理由により正しくありません。

    B. セグメントを削除します。このオプションを選択すると、セグメントはData Cloudから完全に削除され、元に戻すことはできません。このオプションを選択した場合、ユーザーはセグメントを再度使用できなくなります。

    C . アクティベーションをスキップします。このオプションは、セグメントの現在のアクティベーションサイクルをスキップしますが、将来のアクティベーションサイクルには影響しません3。このオプションは、セグメントのアクティベーションを無期限に停止するものではありません。

    D . 公開スケジュールを停止します。このオプションは、選択したターゲットへのセグメントの公開を停止しますが、セグメントを非アクティブ化しません。このオプションは、セグメントのアクティブ化を完全に一時停止するものではありません。

    参照：

    1: Salesforceヘルプの「セグメントの無効化」の記事

    2: Salesforceヘルプのセグメント記事を削除する

    3: Salesforceヘルプのアクティベーション記事をスキップする

    4: Salesforceヘルプの公開スケジュール記事を停止する'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 124
  question_text: 'アウトドアライフスタイル衣料ブランドのNorthern Trail Outfitters（NTO）は、最近、新たな事業を開始しました。この新事業は、グルメキャンプフードを専門としています。ビジネス上の理由とセキュリティ上の理由から、NTOはすべてのデータクラウドデータをブランドごとに分離して管理することが重要だと考えています。

    ブランドごとにデータを分離するという NTO の要望を最もよくサポートする機能はどれですか?'
  choices:
    A: 各ブランドのデータストリーム
    B: 各ブランドのデータモデルオブジェクト
    C: ブランドごとのデータスペース
    D: 各ブランドのデータソース
  correct_answer: C
  japanese_explanation: 'データスペースは、ブランド、地域、製品、事業部門など、さまざまな基準でデータを分離・整理できる論理コンテナです1。データスペースは、データアクセス、セキュリティ、ガバナンスの管理、そしてクラウド間のデータ統合とアクティベーションに役立ちます2。NTOの場合、データスペースはブランドごとにデータを分離したいという要望をサポートし、アウトドアライフスタイル衣料とグルメキャンプフード事業それぞれに異なるデータモデル、ルール、インサイトを提供できます2。また、データスペースは、NTOがさまざまなブランドに適用される可能性のあるデータプライバシーおよびセキュリティ規制を遵守するのにも役立ちます3。他の選択肢は、データスペースと同じレベルのデータ分離と整理を提供しないため、正しくありません。データストリームは、さまざまなソースからデータクラウドにデータを取り込むために使用されますが、ブランドごとにデータを分離するものではありません4。データモデルオブジェクトは、データの構造と属性を定義するために使用されますが、ブランドごとにデータを分離するものではありません5。データソースは、データの出所と種類を識別するために使用されますが、ブランドごとにデータを分割するものではありません。参考資料:
    データ スペースの概要、データ スペースの作成、データ クラウドにおけるデータのプライバシーとセキュリティ、データ ストリームの概要、データ モデル オブジェクトの概要、[データ
    ソースの概要]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 125
  question_text: 'ある顧客では、複数のチームメンバーがセグメントオーディエンスを作成しており、それぞれが異なるタイムゾーンで勤務しています。そのうちの1人は、組織のタイムゾーン設定と一致する太平洋標準時の本社で勤務しています。

    別のチームメンバーは東部標準時でリモート勤務しています。

    セグメントとアクティベーション スケジュール領域で自分のホーム タイム ゾーンが表示されるのはどのユーザーですか?'
  choices:
    A: 太平洋時間帯のチーム メンバー。
    B: 東部標準時のチームメンバー。
    C: どちらのチーム メンバーも、Data Cloud ではすべてのスケジュールが GMT で表示されます。
    D: チームメンバー両方。データクラウドは、ログインしたユーザーのタイムゾーンに合わせてセグメントとアクティベーションのスケジュールを調整します。
  correct_answer: D
  japanese_explanation: '正解はD（両方のチームメンバー）です。Data Cloudは、セグメントとアクティベーションのスケジュールをログインユーザーのタイムゾーンに合わせて調整します。Data
    Cloudは、ログインユーザーのタイムゾーン設定を使用して、セグメントとアクティベーションのスケジュールを表示します。つまり、組織のタイムゾーン設定や他のチームメンバーの所在地に関係なく、各ユーザーのホームタイムゾーンでスケジュールが表示されます。この機能は、異なるタイムゾーン間でセグメントとアクティベーションをスケジュールする際の混乱やエラーを回避するのに役立ちます。その他の選択肢は、Data
    Cloudのタイムゾーン処理方法を反映していないため、正しくありません。太平洋標準時（Pacific Time Zone）のチームメンバーは、個人のタイムゾーン設定が組織のタイムゾーン設定と一致しない限り、組織のタイムゾーン設定と同じタイムゾーンを表示しません。東部標準時（Eastern
    Time Zone）のチームメンバーは、個人のタイムゾーン設定が組織のタイムゾーン設定と一致しない限り、組織のタイムゾーン設定でスケジュールを表示しません。Data
    CloudはすべてのスケジュールをGMTではなく、ユーザーのローカルタイムゾーンで表示します。参考資料：

    * データクラウドのタイムゾーン

    * ユーザーと組織のデフォルトのタイムゾーンを変更する

    * Salesforce、Google、Outlook のタイムゾーン設定を変更する

    * SalesforceのDateTimeフィールドとタイムゾーン設定'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 126
  question_text: 'Cloud Kicks は顧客から忘れ去られるリクエストを受け取りました。

    この要求に応えるために、コンサルタントは Data Cloud をどのように使用すべきですか 2 つの方法のうちどれですか?

    2つの回答を選択してください'
  choices:
    A: 受信データ ストリームからデータを削除し、完全更新を実行します。
    B: ヘッダーなしファイルに個人 ID を追加し、ファイルからの削除機能を使用します。
    C: データ エクスプローラーを使用して、個人を特定し、手動で削除します。
    D: Consent API を使用して処理を抑制し、個人および関連レコードをソース データ ストリームから削除します。
  correct_answer: B,D
  japanese_explanation: '顧客からの忘れられるリクエストに応えるために、コンサルタントは Data Cloud を次の 2 つの方法で使用する必要があります。

    * ヘッダーなしファイルに個人IDを追加し、ファイルから削除する機能を使用します。このオプションを使用すると、コンサルタントはIDを記載したCSVファイルをアップロードすることで、複数の個人をData
    Cloudから削除できます1。削除プロセスは非同期で行われ、完了するまでに最大24時間かかる場合があります1。

    * Consent API を使用して処理を抑制し、個人および関連レコードをソースデータストリームから削除します。このオプションを使用すると、コンサルタントは
    Consent API2 を使用して Data Cloud 内の個人プロファイルのデータ削除リクエストを送信できます。データ削除リクエストは、指定された個人エンティティと、そのエンティティの識別属性と個人
    ID 属性2 の間に関係が定義されているすべてのエンティティを削除します。削除プロセスは、完全な削除を確実にするために、30 日、60 日、90 日ごとに再処理されます2。その他のオプションは、以下の理由により正しくありません。

    * 受信データ ストリームからデータを削除し、完全更新を実行しても、Data Cloud 内の既存のデータは削除されず、ソース システム 3 からの新しいデータのみが削除されます。

    * データエクスプローラーを使用して個人を特定し、手動で削除しても、ソースデータストリームから関連レコードは削除されず、データクラウド内の個人エンティティのみが削除されることに注意してください。参考資料：

    * データクラウドから個人を削除する

    * データ削除または忘れられる権利の要求

    * データクラウドのデータ更新

    * [データエクスプローラー]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 127
  question_text: 'データ ソースを切断する前に削除する必要がある 2 つの依存関係はどれですか。

    2つの回答を選択してください'
  choices:
    A: 活性化対象
    B: セグメント
    C: アクティベーション
    D: データストリーム
  correct_answer: B,D
  japanese_explanation: '* データクラウドの依存関係:

    データ ソースを切断する前に、データの整合性の問題を防ぐためにすべての依存関係を削除する必要があります。

    参照：

    * 依存関係の特定:

    セグメント: ソースのデータを使用しているセグメントは削除するか、再割り当てする必要があります。

    データ ストリーム: データ ストリームはデータ ソースに直接依存するため、切断されている必要があります。

    * 依存関係を削除する手順:

    セグメントを削除:

    Salesforce Data Cloud のセグメンテーション インターフェースに移動します。

    データ ソースに依存するセグメントを識別して削除します。

    データ ストリームを切断します:

    データ ストリームの設定に移動します。

    ソースに関連付けられたデータ ストリームを見つけて切断します。

    * 実用的な応用:

    例: 従来の CRM システムを切断する準備をするときは、そのデータを使用しているすべてのセグメントとデータ ストリームが適切に削除または移行されていることを確認します。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
- question_id: 128
  question_text: データ モデル内に矛盾する情報がある場合、アイデンティティ解決では統合された個人の属性をどのように選択するのでしょうか?
  choices:
    A: 追加の接触点を作成する
    B: 調整ルールを活用する
    C: 追加のルールセットを作成する
    D: マッチルールを活用する
  correct_answer: B
  japanese_explanation: アイデンティティ解決とは、異なるソースからのデータを照合および統合することで、個人の統合プロファイルを作成するプロセスです。データモデル内に、同一人物の異なる名前、住所、電話番号など、矛盾する情報が存在する場合、アイデンティティ解決では調整ルールを活用して、統合プロファイルに最も正確で完全な属性を選択します。調整ルールは、最新性、頻度、ソースの優先度、完全性などの基準に基づいて矛盾を解決する方法を定義する設定可能なルールです。例えば、調整ルールでは、統合プロファイルに最も最近使用した名前や最も頻繁に使用される電話番号を選択するように指定できます。調整ルールは、属性レベルまたは連絡先レベルで適用できます。参考資料：アイデンティティ解決、調整ルール、Salesforce
    Data Cloud 試験問題
  ai_analysis:
    related_docs: []
    ai_verification:
      status: エラー
      justification: 'AI処理中にエラーが発生しました: Expecting value: line 1 column 1 (char 0)'
