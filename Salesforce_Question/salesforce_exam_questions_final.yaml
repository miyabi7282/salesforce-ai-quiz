- question_id: 1
  question_text: '顧客には、Data Cloud 組織内で各セグメントが最後に公開された日時を表示できるという要件があります。

    この要件に最もよく対応するためにコンサルタントが推奨すべき 2 つの機能はどれですか?

    2つの回答を選択してください'
  choices:
    A: プロファイルエクスプローラー
    B: 計算された洞察力
    C: ダッシュボード
    D: レポート
  correct_answer: C,D
  japanese_explanation: 'Data Cloud 組織内で各セグメントが最後に公開された日時を確認したいお客様は、ダッシュボードとレポート機能を使用してこの要件を満たすことができます。ダッシュボードは、主要な指標、傾向、比較を表示できるデータの視覚的な表現です。レポートは、詳細、要約、計算を表示できる表形式またはマトリックス形式のデータビューです。ダッシュボードとレポートの両方の機能により、ユーザーはニーズや好みに応じてデータビューを作成、カスタマイズ、共有できます。各セグメントが最後に公開された日時を確認するには、セグメントオブジェクトのセグメント名、公開日、公開ステータスフィールドを表示するダッシュボードまたはレポートを作成できます。また、これらのフィールドでデータをフィルタリング、並べ替え、グループ化、またはグラフ化して、より多くの洞察と分析を得ることもできます。必要に応じて、ダッシュボードまたはレポートデータをスケジュール、更新、またはエクスポートすることもできます。参考資料:
    ダッシュボード、レポート'
  ai_analysis:
    related_docs:
    - title: Data Cloud アーキテクチャ戦略
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud_architecture_strategy.htm&language=ja&type=5
      reason: このドキュメントには、「レポートを生成したりするときに処理されます」という記述があり、Data Cloudのコンテキストでレポート機能が利用されることを示唆しています。問題の要件である「セグメントの最終公開日時」といった特定の情報を表示するためには、Salesforceの標準機能であるレポートと、それを視覚化するダッシュボードが最も一般的な解決策です。このドキュメントは、その解決策の構成要素である「レポート」の存在を間接的に裏付けています。
      supporting_text: データは、ユーザーがレコードを表示および更新したり、組織間で共有されるオブジェクトを作成したり、レポートを生成したりするときに処理されます。組織を標準
        CRM 組織または Data Cloud One コンパニオン接続に接続すると、データが処理される場所が変更され、法的に影響する可能性があります。
    ai_verification:
      status: 判断不能
      justification: 問題は、Data Cloudのセグメントに関する特定の情報（最終公開日時）を表示するための機能を問うています。正答は「ダッシュボード」と「レポート」ですが、これはSalesforceプラットフォームの標準的なデータ可視化機能に関する一般知識に基づいています。提供された公式ドキュメントには、Data
        Cloudのセグメントオブジェクトをデータソースとしてレポートやダッシュボードを作成し、最終公開日時といったメタデータを表示する具体的な方法について直接的な記述が見つかりません。そのため、提供されたドキュメントのみを根拠として正答を導き出すことは困難です。
- question_id: 2
  question_text: 'Cumulus Financial は、Data Cloud ユーザー向けに Salesforce CRM アカウント データを国別に分離したいと考えています。

    これを達成するためにコンサルタントは何をすべきでしょうか?'
  choices:
    A: ストリーミング変換を使用して、国に基づいてアカウント データをフィルター処理し、それに応じて個別のデータ モデル オブジェクトにマップします。
    B: データ スペース機能を使用し、国に基づいてアカウント データ レイク オブジェクトにフィルターを適用します。
    C: アカウント オブジェクトで Salesforce 共有ルールを使用して、国に基づいてレコードをフィルタリングおよび分離します。
    D: アカウントの国フィールドに基づいて数式フィールドを使用して、受信レコードをフィルタリングします。
  correct_answer: B
  japanese_explanation: データスペースは、データクラウドユーザーがフィルターと権限に基づいてデータのサブセットを作成できる機能です。データスペースは、地域、事業部門、製品ラインなどのさまざまな基準に基づいてデータを分離するために使用できます。この場合、コンサルタントはデータスペース機能を使用して、アカウントデータレイクオブジェクトに国に基づいてフィルタリングを適用できます。これにより、データクラウドユーザーはそれぞれの国に属するアカウントデータのみにアクセスできるようになります。参考資料：データスペース、データスペースの作成
  ai_analysis:
    related_docs:
    - title: Cumulus によるデータ基盤要件の確立
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_cumulus_req.htm&language=ja&type=5
      reason: 問題文のシナリオの登場企業であるCumulus社が多国籍（10か国）で事業を展開していることが記載されており、データを国別に分離する必要があるという背景を補強するため。
      supporting_text: Cumulus Bank and Financial Services は、10 か国、5 つの業務ユニットで共有される完全な利用者
        (約 1000 万の連絡先) を持つ国際的な企業です。
    ai_verification:
      status: 判断不能
      justification: 問題はData Cloud内でデータを論理的に分離する方法を問うています。正答とされている「データスペース」機能は、ブランドや地域（国など）ごとにデータを分離し、アクセスや処理を制御するための最適な機能です。しかし、提供された公式ドキュメント候補は、主にData
        CloudとMarketing Cloud Engagementの連携やセグメンテーション、有効化に関する内容に終始しており、「データスペース」機能に関する直接的な説明が含まれていません。したがって、提供された情報だけでは正答Bが正しいと断定することはできません。
- question_id: 3
  question_text: 'Salesforce CRMのキャンペーンにキャンペーンメンバーをインポートするには、セグメントをAmazon S3にエクスポートする必要があります。エクスポートしたファイルの名前には、Salesforce
    CRMのキャンペーンIDを含める必要があります。

    この結果を達成するための 2 つの方法は何ですか?

    2つの回答を選択してください'
  choices:
    A: アクティベーション名にキャンペーン識別子を含めます。
    B: キャンペーンアクティベーションでキャンペーン識別子を新しい属性としてハードコードします。
    C: ファイル名の指定にキャンペーン識別子を含めます。
    D: セグメント名にキャンペーン識別子を含めます。
  correct_answer: A,C
  japanese_explanation: 'この結果を実現するには、AとCの2つの方法があります。アクティベーション名にキャンペーン識別子を含める方法と、ファイル名の指定にキャンペーン識別子を含める方法です。これらの2つのオプションにより、ユーザーはAmazon
    S3にエクスポートされるファイル名にSalesforce CRMキャンペーンIDを指定できます。アクティベーション名とファイル名の指定はどちらもアクティベーションウィザードで設定可能で、ユーザーはキャンペーン識別子をテキストまたは変数として入力できます。アクティベーション名はファイル名のプレフィックスとして使用され、ファイル名の指定はファイル名のサフィックスとして使用されます。例えば、アクティベーション名が

    「Campaign_123」でファイル名の指定が「{segmentName}_{date}」の場合、結果のファイル名は次のようになります。

    「Campaign_123_SegmentA_2023-12-18.csv」。これにより、ユーザーはキャンペーンに対応するファイルを簡単に識別し、Salesforce
    CRMにインポートできます。

    その他の選択肢は正しくありません。選択肢Bは、キャンペーンIDをキャンペーンアクティベーションの新しい属性としてハードコーディングできないため、正しくありません。キャンペーンアクティベーションには属性はなく、設定のみがあります。選択肢Dは、セグメント名にキャンペーンIDを含めるだけでは不十分であるため、正しくありません。

    セグメント名は、ファイル名の指定で指定されない限り、エクスポートされたファイルのファイル名には使用されません。そのため、ユーザーはファイル名に含まれるキャンペーン識別子を確認できません。'
  ai_analysis:
    related_docs:
    - title: ファイル名の例 (SFTP、GCS、Azure)
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_file_name_examples.htm&language=ja&type=5
      reason: このドキュメントは、エクスポートされるファイル名が「セグメント名」と「有効化名（アクティベーション名）」から構成されることを明確に示しています。これにより、有効化名にキャンペーンIDを含める方法（選択肢A）が正しいと判断できます。また、「カスタムファイル名」の記述から、ファイル名を直接指定する方法（選択肢C）も可能であることがわかります。
      supporting_text: "このファイル名は、セグメント名と有効化名に基づいて事前に決定されます。\n\nTeenagersInNewyork\
        \ - セグメント名\nEmailCampaign - 有効化名\n\n...\n\nWinterOffersForMobileAudience_2023-07-30-17-55-45_00000.json\t\
        カスタムファイル名。有効化対象に対するすべての有効化には、同じカスタムファイル名が使用され..."
    - title: ファイルストレージプラットフォームでのセグメントの検索
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_find_segments_in_cloud_file_storage.htm&language=ja&type=5
      reason: このドキュメントでは、各種クラウドストレージにおけるファイル名の形式が示されています。「セグメントファイルは /FileName_DateTimeSuffix_Part#.FileFormat.CompressionFormat
        の形式で作成されます。」という記述は、ファイル名を指定できること（選択肢C）を裏付けています。また、ファイル名の例に「有効化名」が含まれており、選択肢Aの妥当性も補強します。
      supporting_text: 'セグメントファイルは /FileName_DateTimeSuffix_Part#.FileFormat.CompressionFormat
        の形式で作成されます。


        ファイル名の例: /TeenagersInNewyork_EmailCampaign_2023-07-30-17-55-45-216_00000.csv.gz'
    ai_verification:
      status: 一致
      justification: 公式ドキュメント「ファイル名の例 (SFTP、GCS、Azure)」によると、Data Cloudからエクスポートされるファイルの命名規則は、デフォルトで『セグメント名』と『有効化名』を組み合わせたものになります。したがって、「アクティベーション名（有効化名）にキャンペーン識別子を含める」（選択肢A）ことで、ファイル名にIDを反映させることができます。また、同ドキュメントでは「カスタムファイル名」を指定できることにも言及しており、「ファイル名の指定にキャンペーン識別子を含める」（選択肢C）も有効な方法です。これらの点から、正答AとCはドキュメントの内容と一致します。
- question_id: 4
  question_text: '顧客は最近、統合率が上昇していることに気づき、コンサルタントに連絡してその理由を尋ねました。

    この増加の理由として考えられる 2 つのことは何でしょうか?

    2つの回答を選択してください'
  choices:
    A: 既存のプロファイルと大部分が重複する新しいデータ ソースが Data Cloud に追加されました。
    B: ソース システム データ ストリームから重複が削除されました。
    C: 一致するプロファイルの数を減らすために、ID 解決ルールが削除されました。
    D: 一致するプロファイルの数を増やすために、ルールセットに ID 解決ルールが追加されました。
  correct_answer: A,D
  japanese_explanation: '統合率は、Data Cloud で統合プロファイルを作成するためにソースプロファイルが統合される量を測定する指標であり、1
    - (統合プロファイルの数 / ソースプロファイルの数) で計算されます。統合率が高いほど、より多くのソースプロファイルが一致して統合プロファイルに統合され、統合プロファイルの数が少なくなることを意味します。一方、統合率が低いほど、一致するソースプロファイルが少なくなり、統合プロファイルの数が増えることを意味します。最近、お客様の統合率が上昇した理由としては、以下の2つが考えられます。

    Data Cloud には、既存のプロファイルと大部分が重複する新しいデータソースが追加されました。つまり、新しいデータソースには、既存のデータソースのプロファイルと類似または同一のプロファイルが多数含まれることになります。例えば、お客様が新しい
    CRM システムを追加し、そのシステムが古い CRM システムと同じ顧客レコードを持っている場合、新しいデータソースは既存のデータソースと重複することになります。Data
    Cloud は新しいデータソースを取り込む際に、ID 解決ルールセットを使用して重複するプロファイルを照合し、統合されたプロファイルに統合します。これにより、統合率が向上します。

    一致するプロファイルの数を増やすため、ルールセットにアイデンティティ解決ルールが追加されました。これは、お客様がアイデンティティ解決ルールセットを変更し、より多くの一致ルールまたは一致基準を追加することで、より多くのプロファイルを同一個人に属するものとして識別できるようにすることを意味します。例えば、お客様がメールアドレスだけでなく、メールアドレスと電話番号に基づいてプロファイルを一致させる一致ルールを追加した場合、ルールセットは同じメールアドレスと電話番号を持つより多くのプロファイルを一致させることができるため、統合率が向上します。

    アイデンティティ解決の計算された洞察: 統合プロファイルの統合率、アイデンティティ解決ルールセットの構成'
  ai_analysis:
    related_docs:
    - title: ID 解決一致ルール
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_match_rules.htm&language=ja&type=5
      reason: 選択肢Dは、一致するプロファイルを増やすためにルールを追加することが統合率の上昇につながるとしています。このドキュメントでは「複数の一致ルールを作成して、一致オプションを拡張します。いずれか
        1 つの一致ルールが有効化されると、統合プロファイルが作成されます。」と説明しており、一致ルールを追加することで統合されるプロファイルが増えること、つまり統合率が上昇することを直接的に裏付けています。
      supporting_text: 複数の一致ルールを作成して、一致オプションを拡張します。いずれか 1 つの一致ルールが有効化されると、統合プロファイルが作成されます。
    - title: ID 解決ルールセット
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_ruleset.htm&language=ja&type=5
      reason: 選択肢Aは、重複するデータソースの追加が統合率の上昇につながるとしています。このドキュメントでは、ID解決ルールセットの目的が「複数のデータソースを統合プロファイルにリンクする」ことであると定義しています。既存データと重複する新しいデータソースが追加されれば、ID解決プロセスによってそれらが統合され、結果として統合率が上昇することは、この定義から論理的に導き出せます。
      supporting_text: ルールセットには、複数のデータソースを統合プロファイルにリンクする方法を Customer Data Platform
        に指示する一致ルールと調整ルールが含まれます。
    ai_verification:
      status: 一致
      justification: '問題はData Cloudの「統合率」が上昇する原因を問うています。統合率の上昇は、より多くのソースプロファイルが少数の統合プロファイルにまとめられることを意味します。


        選択肢A「既存のプロファイルと大部分が重複する新しいデータ ソースが Data Cloud に追加されました。」：重複データを含む新しいソースが追加されると、ID解決によってそれらのプロファイルが一致・統合され、1つの統合プロファイルに含まれるソースプロファイルの数が増えるため、統合率は上昇します。


        選択肢D「一致するプロファイルの数を増やすために、ルールセットに ID 解決ルールが追加されました。」：『ID 解決一致ルール』のドキュメントにある通り、一致ルールを追加すると一致オプションが拡張され、これまで別々と見なされていたプロファイルが統合されるようになります。これにより統合プロファイルの総数が減り、統合率が上昇します。


        他の選択肢は逆の効果をもたらします。B（ソースでの重複削除）は統合対象を減らし、C（ルール削除）は一致する可能性を低くするため、いずれも統合率を低下させる要因となります。したがって、正答AとDは論理的に正しく、公式ドキュメントの概念とも一致します。'
- question_id: 5
  question_text: 'Northern Trail Outfittersは、毎日新しい顧客データをAmazon S3バケットにアップロードし、Data
    Cloudに取り込みます。このデータに基づいて、過去30日間の顧客あたりの総支出を示すインサイトが生成されます。

    新しくインポートされたデータがどのセグメントでも使用可能であることを確認するには、各プロセスをどの順序で実行する必要がありますか?'
  choices:
    A: データストリームの更新 > アイデンティティ解決 > 計算された洞察
    B: データストリームの更新 > 計算された洞察 > ID解決
    C: 計算された洞察 > データストリームの更新 > ID解決
    D: アイデンティティ解決 > データストリームの更新 > 計算された洞察
  correct_answer: A
  japanese_explanation: '新しくインポートしたデータがどのセグメントでも使用可能であることを確認するには、以下の順序でプロセスを実行する必要があります：データストリームの更新
    > Identity Resolution > Calculated Insight。その理由は次のとおりです。

    要件を理解する

    Northern Trail Outfitters は、毎日新しい顧客データを Amazon S3 バケットにアップロードし、それが Data Cloud
    に取り込まれます。

    過去 30 日間の顧客あたりの総支出を表示するために計算されたインサイトが作成されます。

    目標は、データがセグメントで使用される前に適切に更新、解決、および処理されるようにすることです。

    なぜこのシーケンスなのでしょうか?

    ステップ1: データストリームを更新する

    処理を実行する前に、データストリームを更新して、Amazon S3 バケットから最新のデータを取り込む必要があります。

    これにより、最新の顧客データが Data Cloud で利用できるようになります。

    ステップ2: アイデンティティ解決

    データ ストリームを更新した後、関連するレコードを統合プロファイルにマージするために ID 解決を実行する必要があります。

    このステップにより、顧客データが統合され、分析の準備が整います。

    ステップ3：計算された洞察

    ID 解決が完了すると、計算された洞察が生成され、過去 30 日間の顧客あたりの総支出を計算できるようになります。

    これにより、洞察は最新かつ最も正確なデータに基づくものになります。

    その他のオプションが間違っています:

    B. データ ストリームの更新 > 計算されたインサイト > ID 解決: 計算されたインサイトは統合プロファイルに依存しているため、ID 解決の前に生成することはできません。

    C . 計算されたインサイト > データ ストリームの更新 > ID 解決: 計算されたインサイトには最新のデータと解決済みの ID の両方が必要なので、このシーケンスは無効です。

    D . ID 解決 > データ ストリームの更新 > 計算された洞察: 最初にデータ ストリームを更新して最新のデータを取り込まなければ、ID 解決は実行できません。

    結論

    正しい順序は、「データ ストリームの更新」>「アイデンティティ解決」>「計算されたインサイト」であり、セグメントで使用される前にデータが適切に更新、解決、および処理されることが保証されます。'
  ai_analysis:
    related_docs:
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: このドキュメントには、「統合プロファイルの計算済みインサイトを作成する場合にこのオブジェクトが必要になります」と明記されており、ID解決によって統合プロファイルが作成された後に、計算済みインサイトが実行されるというプロセスの順序を直接的に裏付けているため。
      supporting_text: 統合リンクオブジェクトはソースデータと統合オブジェクト間のリンクとして機能します。統合リンクオブジェクトでは、各統合プロファイルのソースデータを参照できます。統合プロファイルの計算済みインサイトを作成する場合にこのオブジェクトが必要になります。
    - title: ID 解決の最適化
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_optimize.htm&language=ja&type=5
      reason: このドキュメントでは、ID解決の結果をトラブルシューティング（調査）する手段として計算済みインサイトを作成することが記載されています。これは、ID解決が計算済みインサイトの前に実行されるプロセスであることを示唆しています。
      supporting_text: '計算済みインサイトを使用した ID 解決の結果のトラブルシューティング

        計算済みインサイトを作成して、統合プロファイルデータの品質とプロファイル統合率を調査します。'
    ai_verification:
      status: 一致
      justification: 問題は、Data Cloudでデータを取り込んでからセグメントで利用可能にするまでの一連のプロセスの順序を問うています。論理的な順序は以下の通りです。まず、外部ソースから「データストリームの更新」によってデータを取り込みます。次に、そのデータを既存のプロファイルと統合するために「アイデンティティ解決」を実行します。最後に、統合されたプロファイルに基づいて集計を行う「計算された洞察」を実行します。この順序が完了して初めて、最新のデータとインサイトがセグメントで利用可能になります。参照ドキュメント「ソースプロファイルの統合」は、計算済みインサイトがID解決によって作成されるオブジェクトに依存することを示しており、「ID解決
        -> 計算された洞察」の順序を裏付けています。したがって、正答である「A. データストリームの更新 > アイデンティティ解決 > 計算された洞察」は正しいです。
- question_id: 6
  question_text: '個人にセグメントを作成するときに、以下に示すように AND でリンクされた 2 つの個別のコンテナーを使用すると、どのような結果になりますか?

    商品 | 個数 | 最小 | 1

    色 | 等しい | 赤

    そして

    商品 | 個数 | 最小 | 1

    PrimaryProductCategory | 等しい | 靴'
  choices:
    A: 少なくとも1つの「赤色」製品を購入し、さらに少なくとも1足の「靴」を購入した個人
    B: 購入時に単一の品目として「赤い靴」を少なくとも1つ購入した個人
    C: 少なくとも1つの「赤い靴」を購入した個人。他には何も購入していない。
    D: 少なくとも1つの「赤」製品を購入した、または少なくとも1組の'靴'
  correct_answer: A
  japanese_explanation: '個人にセグメントを作成する際に、AND でリンクされた 2 つの別々のコンテナを使用する場合、その個人はコンテナ内の両方の条件を満たす必要があります。この場合、個人は色属性が「赤」である商品を少なくとも
    1 つ、主要商品カテゴリ属性が「靴」である商品を少なくとも 1 つ購入している必要があります。これらの商品は同一である必要はなく、同じ取引で購入される必要もありません。したがって、正解は
    A です。

    その他のオプションは、異なる論理演算子または条件を意味しているため、正しくありません。オプション B は、色属性が「赤」で、主要製品カテゴリ属性が「靴」である製品を
    1 つだけ購入した必要があることを意味します。オプション C は、色属性が「赤」で、主要製品カテゴリ属性が「靴」である製品を 1 つだけ購入し、他の製品は購入していない必要があることを意味します。オプション
    D は、色属性が「赤」である製品を 1 つ、または主要製品カテゴリ属性が「靴」である製品を 1 つ、あるいはその両方を購入した必要があることを意味します。これは、AND
    演算子ではなく OR 演算子を使用するのと同じです。

    参考文献:

    * セグメンテーション用のコンテナを作成する

    * データクラウドでセグメントを作成する

    * データクラウドセグメンテーションをナビゲート'
  ai_analysis:
    related_docs:
    - title: 購入検索条件
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_purchases_filters.htm&language=ja&type=5
      reason: 'このドキュメントは、複数の購入条件コンテナを`AND`で結合する具体的な例（例: カヤックを購入し、かつ安全ベストを購入していない）を複数提示しています。問題のシナリオと同様に、異なる商品の購入条件を持つコンテナを`AND`でリンクした場合、両方の条件を満たす必要があることを明確に示しており、正答の根拠として最も適切です。'
      supporting_text: 'ある商品を購入し、別の商品を購入していない


        この検索条件では、一定の期間内にカヤックを購入し、安全ベストを購入しなかった顧客を検索します。


        例

        販売注文商品 | 件数 | 以上 | 1

        商品名 | 次の値と等しい | カヤック

        および

        注文開始日 | 次の範囲内にある | 2020-05-01 AND 2020-06-01


        および


        販売注文商品 | 件数 | 次の値と等しい | 0

        Product Name | Is Equal To | Safety Vests (商品名 | 次の値と等しい | 安全ベスト)'
    - title: データの整理
      url: basics.pdf
      reason: このドキュメントでは、フィルターロジックにおける`AND`演算子の基本的な定義が「両方の値と一致するレコードを検索します」と簡潔に説明されています。これは、問題で提示された2つの条件コンテナの両方を満たす必要があるという解釈を直接的に裏付けます。
      supporting_text: '定義

        オペランド

        両方の値と一致するレコードを検索します。

        1 AND 2

        AND'
    - title: 検索条件ノード
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_batch_transform_filter.htm&language=ja&type=5
      reason: このドキュメントは、データ変換において複数の検索条件を組み合わせる際のロジックについて説明しています。デフォルトが`AND`ロジックであること、そして`AND`、`OR`、`NOT`といったBoolean演算子を使ってロジックを構築することが述べられており、問題の`AND`でのリンクが標準的な条件結合の方法であることを示しています。
      supporting_text: '現在の標準検索条件ロジックを表示するには、  および [標準の検索条件ロジックを追加] をクリックします。

        デフォルトの AND ロジックが表示され、各検索条件コンポーネントには番号が割り当てられています。

        ロジックを編集するには、鉛筆アイコン () をクリックします。

        括弧と AND、OR、および NOT Boolean 演算子を使用して、検索条件ロジックを構築します。'
    ai_verification:
      status: 一致
      justification: 問題は、2つの個別の条件コンテナを`AND`演算子で結合した結果を問うています。コンテナ1は「少なくとも1つの赤色製品の購入」、コンテナ2は「少なくとも1足の靴の購入」です。`AND`演算子は、結合された両方の条件を満たす場合にのみ真となります。したがって、セグメントの対象となるのは「少なくとも1つの赤色製品を購入」し、**かつ**「少なくとも1足の靴を購入」した個人です。これは選択肢Aの内容と完全に一致します。ドキュメント「購入検索条件」や「データの整理」にも示されている通り、`AND`は複数の条件をすべて満たすレコードを抽出するため、正答はAで間違いありません。
- question_id: 7
  question_text: DMO を作成するときに、セグメンテーションの属性の値の提案はどこで有効になりますか?
  choices:
    A: データマッピング
    B: データ変換
    C: セグメント設定
    D: データストリームのセットアップ
  correct_answer: C
  japanese_explanation: セグメンテーションにおける属性の値の提案は、セグメントフィルターを作成する際にテキスト項目の可能な値を表示して選択できる機能です。この機能は、データモデルオブジェクト（DMO）レコードホームの各DMO項目に対して有効または無効にできます。値の提案は、組織全体で最大500個の属性に対して有効にできます。提案された値が表示されるまで最大24時間かかる場合があります。セグメントフィルターの作成時に値の提案を使用するには、属性をキャンバスにドラッグし、属性の「値」項目に入力を開始する必要があります。一部の演算子では複数の値を選択することもできます。値の提案は、255文字を超える属性、または1対多（1:N）の関係では利用できません。参考：セグメンテーションにおける値の提案の使用、関連属性の選択に関する考慮事項
  ai_analysis:
    related_docs:
    - title: セグメンテーションでの値の提案の使用
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_suggested_values_in_segments.htm&language=ja&type=5
      reason: 問題で問われている「セグメンテーションの属性の値の提案」を「どこで有効にするか」について、具体的な設定場所を直接説明しているため。
      supporting_text: データ型が [テキスト] の場合、データモデルオブジェクト (DMO) 項目の値の提案を有効にできます。DMO レコードホームでこの機能を有効化または無効化します。値の提案は組織全体で最大
        500 個の属性に対して有効にできます。
    ai_verification:
      status: 矛盾の可能性あり
      justification: 公式ドキュメント「セグメンテーションでの値の提案の使用」には、値の提案機能は『DMO レコードホームでこの機能を有効化または無効化します』と明確に記載されています。これはDMOオブジェクト自体の設定画面を指しており、選択肢「C.
        セグメント設定」とは異なります。選択肢の中にDMOの設定に直接関連するものがなく、提示された正答とドキュメントの記述が一致しないため、問題または正答が不正確である可能性があります。
- question_id: 8
  question_text: Data Cloud が CRM データを取り込む方法に関連する考慮事項のうち正しいものはどれですか?
  choices:
    A: CRMデータは手動で更新できず、次回のスケジュールされた同期まで待つ必要があります。
    B: CRM コネクタの同期時間は、最大 15 分間隔にカスタマイズできます。
    C: 数式フィールドは定期的な同期間隔で更新され、次回の完全更新時に更新されます。
    D: CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。
  correct_answer: D
  japanese_explanation: '正解は D です。CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。

    つまり、CRMデータソースの標準フィールドへの変更は、次回のスケジュールされた同期を待たずに、ほぼ瞬時にData Cloudに反映されます。この機能により、Data
    Cloudはセグメンテーションとアクティベーションに必要な最新かつ正確なCRMデータを保持できます1。

    その他のオプションは、次の理由により正しくありません。

    * A. CRMデータは、データストリーム詳細ページ2の「更新」ボタンをクリックすることで、いつでも手動で更新できます。このオプションは無効です。

    * B. CRMコネクタの同期時間は、最大60分間隔までカスタマイズできます。

    15分間隔3。このオプションは無効です。

    * C. 数式フィールドは定期的な同期間隔ではなく、次回の完全更新時のみ更新されます4。完全更新とは、24時間ごと、または手動でトリガーされたときに実行される完全なデータ取り込みプロセスです。

    このオプションは偽です。

    参考文献:

    * 1: Salesforceヘルプの「Data Cloudでのデータの接続と取り込み」の記事

    * 2: Trailheadのデータクラウドユニットのデータソース

    * 3: Trailheadの管理者向けデータクラウドモジュール

    * 4: Trailheadの[データクラウドの数式フィールド]ユニット

    * : Trailhead の [Data Cloud のデータストリーム] ユニット'
  ai_analysis:
    related_docs:
    - title: Data Cloud を使用した次のステップ
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_summary_dc4sales.htm&language=ja&type=5
      reason: 問題はData CloudへのCRMデータ取り込み方法に関する考慮事項を問うています。このドキュメントには、Data Cloudで「ほぼリアルタイム」にデータを活用するユースケースが記載されており、これが正答Dの「リアルタイムでData
        Cloudにストリーミングできる」という内容を間接的に支持する唯一の記述であるため選択しました。
      supporting_text: たとえば、複数の取引先に属する統合取引先責任者をクリーンアップする ToDo を作成したり、優先度の高い取引先の商談をほぼリアルタイムで特定して収益を増やしたり、リレーションを改善したりできます。
    ai_verification:
      status: 判断不能
      justification: 提示されたドキュメントには、正答D「CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます」を直接的かつ明確に裏付ける記述が存在しません。「Data
        Cloud を使用した次のステップ」ドキュメントに「ほぼリアルタイムで特定」という関連性の高い記述がありますが、これがCRMコネクタによる標準フィールドのデータストリーミングを指していると断定するには情報が不足しています。また、他の選択肢（A,
        B, C）を明確に否定する情報も提供されたドキュメント内には見つからないため、厳密な正誤判断は不可能です。
- question_id: 9
  question_text: 'コンサルタントは、携帯電話番号を含むプロフィール情報を持つデータ ストリームの取り込みを計画しています。

    今後のSMSキャンペーンで電話番号を確実に使用できるようにするには、電話番号フィールドが適切なE164電話番号形式であることを確認する必要があります。しかし、ファイル内の電話番号の形式は様々であるようです。

    さまざまな電話番号の形式が標準化されていることを保証する最も効率的な方法は何ですか?'
  choices:
    A: 形式を標準化するための数式フィールドを作成します。
    B: Data Cloud に送信する前に、ソース システムでデータを編集および更新します。
    C: データ ストリームを作成するときに、PhoneNumber フィールド タイプを割り当てます。
    D: 取り込み後に計算されたインサイトを作成します。
  correct_answer: C
  japanese_explanation: '様々な電話番号形式を標準化するための最も効率的な方法は、データストリームを作成する際にPhoneNumberフィールド型を指定することです。PhoneNumberフィールド型は、電話番号を国際標準の電話番号であるE164形式に自動的に変換する特別なフィールド型です。E164形式は、プラス記号（+）、国番号、国内番号で構成されます。例えば、

    +1-202-555-1234 は、米国の電話番号の E164 形式です。PhoneNumber フィールドタイプを使用することで、コンサルタントは電話番号の一貫性を確保し、将来の
    SMS キャンペーンで使用できるようにすることができます。他のオプションは、より時間がかかり、手動による介入が必要になり、フォーマットの問題を解決できません。参考資料：データストリームのフィールドタイプ、E164
    電話番号形式、Salesforce Data Cloud 試験問題'
  ai_analysis:
    related_docs:
    - title: '[あいまい] および [完全] 照合方法'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_match_rules_criteria_fuzzy_normalized.htm&language=ja&type=5
      reason: このドキュメントは、「Formatted E164 Phone Number」フィールドにマッピングされた電話番号が、Googleのライブラリを使用して自動的に解析、書式設定、検証される「標準化プロセス」を経ることを明確に説明しています。これにより、様々な形式の電話番号がE.164形式に標準化されるため、正答Cの裏付けとして最も直接的です。
      supporting_text: "連絡先電話\tFormatted E164 Phone Number (書式設定された E164 電話番号)\n\n\
        電話番号から空白を削除する\n* や () などの英数字以外の文字を電話番号から削除する\n国際電話番号を解析、書式設定、および検証するための Google\
        \ の Java、C++、および JavaScript 共通ライブラリを使用して電話番号を検証する"
    - title: Data Cloud への Salesforce データの接続
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_connect_data_task_steps.htm&language=ja&type=5
      reason: このドキュメントは、データストリームのマッピング画面で、ソースの電話番号項目（例：Business Phone）をData Cloudデータモデルの「Formatted
        E164 Phone Number」項目に対応付ける具体的な手順を示しています。これは、選択肢Cで述べられている操作を実践する方法を説明しています。
      supporting_text: '[データモデルエンティティ] で、検索ボックスを使用して連絡先電話オブジェクトの [書式設定された E164 電話番号]
        項目を見つけます。セクションを展開するには、［Unmapped］ をクリックします。

        [Formatted E164 Phone Number] フィールドをクリックして、左側の [Business Phone] に対応付けます。'
    - title: 'Customer 360 データモデル: 個人および連絡先'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_cloud_information_model_individual_and_contact_points.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudのデータモデル内に「FormattedE164PhoneNumber」というフィールドが存在し、その目的が「E164
        形式の電話番号。処理の標準化された値としてバックエンドシステムで使用します。」と定義されていることを示しています。これにより、E.164への標準化がプラットフォームの意図された機能であることがわかります。
      supporting_text: "FormattedE164PhoneNumber\tE164 形式の電話番号。処理の標準化された値としてバックエンドシステムで使用します。"
    ai_verification:
      status: 一致
      justification: 問題は、様々な形式の電話番号を効率的にE.164形式に標準化する方法を尋ねています。正解のCは、データストリーム作成時に適切なフィールドタイプ（またはマッピング）を割り当てることを提案しています。公式ドキュメント「[あいまい]
        および [完全] 照合方法」によると、データモデルオブジェクト（DMO）の「Formatted E164 Phone Number」フィールドにマッピングすることで、Data
        Cloudが自動的に電話番号をE.164形式に解析・検証・書式設定することが明記されています。また、「Data Cloud への Salesforce
        データの接続」などのドキュメントでは、データストリームのマッピングでこの操作を行う具体的な手順が示されています。これは、Data Cloudの組み込み機能を利用した最も効率的な標準化方法であり、正答と完全に一致します。
- question_id: 10
  question_text: 'Northern Trail Outfitters (NTO) は、CRM データを Data Cloud に取り込み始める準備を進めています。

    コネクタを設定する際、データ ストリームが初めて展開されるときに、NTO はどのようなタイプの更新を予期する必要がありますか?'
  choices:
    A: 増分
    B: 手動更新
    C: 部分更新
    D: 完全更新
  correct_answer: D
  japanese_explanation: 'データ ストリームのデプロイメント: Salesforce Data Cloud でデータ ストリームを設定する場合、最初のデプロイメントでは包括的なデータ
    ロードが必要です。

    リフレッシュの種類:

    * 増分更新: 前回の更新以降の新規データまたは変更されたデータのみを更新します。

    * 手動更新: ユーザーがデータのロードを手動で開始する必要があります。

    * 部分更新: データのサブセットのみが更新されます。

    * 完全更新: データセット全体をシステムに読み込みます。

    初回のデプロイメント: データ ストリームの最初のデプロイメントでは、ソース システムのすべてのデータが Salesforce Data Cloud に確実に取り込まれるように、完全な更新が必要です。

    参考文献:

    * Salesforceドキュメント: データストリームの設定

    * Salesforce データクラウドガイド'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 問題は、Data Cloudのデータストリームを初めて展開する際の更新タイプを問うています。正答は「完全更新」であり、これはデータストリームの初回データロード時にソースの全データを取得する動作を指します。提供された公式ドキュメント候補には、Data
        Cloudのデータモデル、接続、データフローの概要などが記載されていますが、データストリームの初回展開が「完全更新 (Full Refresh)」であると直接的かつ明確に記述した箇所は見つかりませんでした。したがって、提示された情報だけでは正答を裏付けることができません。
- question_id: 11
  question_text: 検出中に、複数のデータ ソースがあり、個人に関するデータを 1 つの統合プロファイルに一致させて調整する必要がある顧客に対して、コンサルタントはどの機能を強調する必要がありますか?
  choices:
    A: データクレンジング
    B: 調和
    C: データ統合
    D: アイデンティティ解決
  correct_answer: D
  japanese_explanation: 'アイデンティティ照合は、データクラウドが複数のデータソースから個人に関するデータを照合し、単一の統合プロファイルに統合する機能です。アイデンティティ照合では、ルールセットを使用して、名前、メールアドレス、電話番号、当事者IDなどの共通属性に基づいて、ソースプロファイルの照合と統合方法を定義します。アイデンティティ照合により、データクラウドは、異なるデータソースやシステムにわたって各顧客の360度ビューを作成できます12。他のオプションは、以下の理由により、この顧客ニーズに最適な機能ではありません。

    * A. データクレンジングとは、重複、欠損値、無効な形式など、データ内のエラーや不整合を検出し、修正するプロセスです。データクレンジングはデータの品質と精度を向上させますが、異なるデータソース間のデータの照合や調整を行うものではありません3。

    * B. ハーモナイゼーションとは、異なるデータソースから取得したデータを標準化し、共通の形式と構造に変換するプロセスです。ハーモナイゼーションによってデータの統合と相互運用性は実現できますが、異なるデータソース間でデータの整合性や調整を行うことはできません4。

    * C. データ統合とは、異なるソースからのデータを単一のデータセットまたはシステムに統合するプロセスです。データ統合によってデータの冗長性と複雑さを軽減できますが、異なるデータソース間のデータのマッチングや調整は行いません5。参考文献：1:
    Data and Identity in Data Cloud | Salesforce Trailhead、2: Data Cloud Identiy Resolution
    | Salesforce AI Research、3: [データクレンジング - Salesforce]、4: [Harmonization - Salesforce]、5:
    [データ統合 - Salesforce]'
  ai_analysis:
    related_docs:
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: このドキュメントは、ID解決が「さまざまなソースのデータを顧客と取引先の包括的なビューにまとめる」機能であり、「一致ルールと調整ルールを使用して、人や取引先に関するデータを統合プロファイルにリンクする」と明確に説明しています。これは問題文の「複数のデータソース」「一致させて調整する」「1つの統合プロファイル」という要件に完全に合致するため、正答が「アイデンティティ解決」であることを直接的に裏付けています。
      supporting_text: ID 解決を使用して、さまざまなソースのデータを顧客と取引先の包括的なビューにまとめます。ID 解決では、一致ルールと調整ルールを使用して、人や取引先に関するデータを統合プロファイルにリンクします。各統合プロファイルには、すべてのソースの一意の連絡先値がすべて含まれます。
    - title: ID 解決ルールセット
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_ruleset.htm&language=ja&type=5
      reason: このドキュメントは、ID解決の核心要素であるルールセットが、「複数のデータソースを統合プロファイルにリンクする方法を...指示する一致ルールと調整ルール」を含むと定義しています。これにより、問題文で求められている「一致させて調整する」プロセスがID解決の主要機能であることがわかります。
      supporting_text: ルールセットには、複数のデータソースを統合プロファイルにリンクする方法を Customer Data Platform
        に指示する一致ルールと調整ルールが含まれます。統合プロファイル情報は、ルールセットによって作成されたデータモデルオブジェクトに保存されます。
    - title: Data Cloud Architecture
      url: https://developer.salesforce.com/docs/data/data-cloud-dev/guide/dc-architecture.html
      reason: この開発者向けドキュメントは、「identity resolution process」が「match rules」と「reconciliation
        rules」を適用して、複数のソースから最良のデータを選択し、「unified profile」を生成するプロセスであると簡潔に定義しており、問題のシナリオそのものを英語で説明しています。
      supporting_text: The identity resolution process involves applying match rules
        to group individuals, and reconciliation rules to select the best quality
        data from these groups to generate a gold standard unified profile. The match
        rules have configurable criteria like fuzzy, exact, and normalized matching,
        based on factors like frequency, last updated attribute, or trusted data sources.
    ai_verification:
      status: 一致
      justification: 問題文は「複数のデータソース」から「個人に関するデータを1つの統合プロファイルに一致させて調整する」機能を問うています。公式ドキュメント「ソースプロファイルの統合」では、「ID
        解決を使用して、さまざまなソースのデータを...まとめます。ID 解決では、一致ルールと調整ルールを使用して...統合プロファイルにリンクします。」と明確に記載されています。これは、問題の要件と「アイデンティティ解決」という機能が完全に一致することを示しており、正答を強く支持します。
- question_id: 12
  question_text: 'Cumulus Financialは、Data Cloudを利用して銀行顧客をセグメント化し、クラウドファイルストレージのアクティベーションを通じてダイレクトメールの配信対象者を絞り込んでいます。また、過去2年間にセグメントに含まれていた個人を分析したいと考えています。

    どの Data Cloud コンポーネントがこれを可能にしますか?'
  choices:
    A: セグメント除外
    B: ネストされたセグメント
    C: セグメントメンバーシップデータモデルオブジェクト
    D: 計算された洞察
  correct_answer: C
  japanese_explanation: 'Data Cloud では、セグメントメンバーシップデータモデルオブジェクトを使用して、個人のセグメントメンバーシップ履歴を分析できます。このオブジェクトには、個人がセグメントに参加または離脱した時期に関する情報が保存されており、レポートやダッシュボードを作成してセグメントのパフォーマンスを時系列で追跡できます。Cumulus
    Financial はこのオブジェクトを使用して、過去 2 年以内にセグメントに所属していた個人をフィルタリングし、他の指標と比較することができます。

    その他のオプションは、この分析を可能にするData Cloudコンポーネントではありません。セグメント除外は、別のセグメントに基づいてセグメントから個人を除外できる機能です。ネストされたセグメントは、論理演算子を使用して他のセグメントから作成されたセグメントです。計算されたインサイトは、既存のデータから数式を使用して作成された派生属性です。

    参照：

    セグメントメンバーシップデータモデルオブジェクト

    データクラウドレポートとダッシュボード

    データクラウドでセグメントを作成する'
  ai_analysis:
    related_docs:
    - title: 新しいサービスプロモーション通知 (B2C) の使用事例のメール送信
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_activation_filtering_uc2_service_main.htm&language=ja&type=5
      reason: このドキュメントはData Cloudでの「オーディエンスセグメントの作成」と「セグメントの絞り込み」について具体的に説明しており、問題文の「セグメント化」という操作に直接関連しています。問題は過去のセグメントメンバーシップの分析に関するものですが、このドキュメントはセグメント機能の基本的な利用方法を理解する上で参考になります。
      supporting_text: 'Data Cloud でのオーディエンスセグメントの作成

        オーディエンスセグメントは、メールキャンペーンへのエンゲージメント率が高い顧客で構成されます。新しいサービスに関する自動メールを作成するには、Data
        Cloud で次の手順に従ってオーディエンスセグメントを作成します。

        セグメントの絞り込みと Marketing Cloud Engagement への公開

        セグメントを作成したら、検索条件を追加して利用者を絞り込むことができます。この使用事例では、同意状況と、ユーザーがメールの受信をオプトインしているかどうかで絞り込みます。'
    ai_verification:
      status: 判断不能
      justification: 問題は「過去2年間にセグメントに含まれていた個人」の分析方法を問うており、これはセグメントの履歴データを参照する機能が必要です。正答の「セグメントメンバーシップデータモデルオブジェクト」は、個人がいつ、どのセグメントに所属していたかの履歴情報を保持する標準データモデルオブジェクトであり、この要件を満たします。しかし、提供された公式ドキュメント候補は、主にData
        CloudとMarketing Cloud Engagementの連携や特定のキャンペーンシナリオに焦点を当てており、「セグメントメンバーシップデータモデルオブジェクト」の機能や、それを用いた過去データの分析方法について直接的かつ明確に説明している箇所が見当たりませんでした。そのため、提供されたドキュメントのみでは正答の裏付けができません。
- question_id: 13
  question_text: 'コンサルタントは、セグメント化したい従業員のリストを人事データベースから取り込んでいます。

    このデータを取り込むときにコンサルタントはどのデータ ストリーム カテゴリを選択する必要がありますか?'
  choices:
    A: プロファイルデータ
    B: 連絡先データ
    C: その他のデータ
    D: エンゲージメントデータ
  correct_answer: C
  japanese_explanation: '* データストリームのカテゴリ:

    プロファイル データ: 顧客プロファイルと人口統計情報。

    連絡先データ: 電子メールや電話番号などの連絡先。

    その他のデータ: 他のカテゴリに当てはまらないさまざまなデータ。

    エンゲージメント データ: インタラクションと行動のデータ。

    参照：

    * 従業員データの取り込み:

    従業員データは通常、顧客データ用のプロファイル、連絡先、エンゲージメントのカテゴリには当てはまりません。

    「その他のデータ」は、従業員情報など、顧客固有ではないデータに適しています。

    * 従業員データを取り込む手順:

    Salesforce Data Cloud のデータ取り込み設定に移動します。

    「新しいデータ ストリームの作成」を選択し、「その他のデータ」カテゴリを選択します。

    HR データベースのフィールドを Data Cloud の対応するフィールドにマップします。

    * 実用的な応用:

    例: 企業は従業員データを取り込んで、社内コミュニケーションをセグメント化したり、従業員の指標を分析したりします。

    「その他のデータ」カテゴリを選択すると、顧客以外のデータが正しく管理および利用されるようになります。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供された公式ドキュメントには、Data Cloudでデータストリームを作成する際のカテゴリ（プロファイルデータ、エンゲージメントデータ、その他のデータ）の具体的な定義や使い分けについて直接説明している箇所が見つかりませんでした。問題は、顧客プロファイルや顧客の行動データではない「従業員のリスト」という人事データの取り込みについてです。このような補助的なデータは一般的に「その他のデータ」カテゴリに分類されると考えられますが、この判断を提示されたドキュメントのみで裏付けることはできません。
- question_id: 14
  question_text: '顧客は、顧客生涯価値に基づいてユーザーのセグメントを作成したいと考えています。

    ただし、Data Cloud に取り込まれるソース データには、その主要業績評価指標 (KPI) は含まれていません。

    この要件を満たすためにコンサルタントはどのような手順を踏む必要がありますか?'
  choices:
    A: データの取り込み > データモデルへのデータのマッピング > 計算されたインサイトの作成 > セグメンテーションでの使用
    B: 計算されたインサイトの作成 > データモデルへのデータのマッピング > データの取り込み > セグメンテーションでの使用
    C: 計算されたインサイトの作成 > データの取り込み > データをデータモデルにマッピング > セグメンテーションでの使用
    D: データの取り込み > 計算されたインサイトの作成 > データのデータモデルへのマッピング > セグメンテーションでの使用
  correct_answer: A
  japanese_explanation: 顧客生涯価値（CLV）に基づいてユーザーセグメントを作成するには、コンサルタントが「データの取り込み」>「データモデルへのデータのマッピング」>「計算されたインサイトの作成」>「セグメンテーションでの使用」という手順に従う必要があります。これは、最初のステップでデータストリーム1を使用してソースデータをData
    Cloudに取り込むためです。2番目のステップでは、ソースデータをデータモデルにマッピングし、データの構造と属性を定義します2。3番目のステップでは、計算されたインサイトを作成します。これは、ソースデータまたは統合データに基づいて計算される派生属性です3。この場合、計算されたインサイトはCLVであり、販売注文データ4に基づく数式またはクエリを使用して計算できます。4番目のステップでは、計算されたインサイトをセグメンテーションで使用します。セグメンテーションとは、個人またはエンティティの属性と行動に基づいてグループを作成するプロセスです。CLV計算されたインサイトを使用することで、コンサルタントはブランドとの関係の存続期間から予測される収益に基づいてユーザーをセグメント化できます。その他のオプションは、要件を満たすための正しい手順に従っていないため、正しくありません。選択肢Bは不正解です。計算されたインサイトはデータモデルオブジェクト3に依存するため、データの取り込みとマッピング前には作成できません。選択肢Cは不正解です。計算されたインサイトはデータモデルオブジェクト3に依存するため、データのマッピング前には作成できません。選択肢Dは不正解です。計算されたインサイトは正しいデータモデル構造と属性3を反映していない可能性があるため、データのマッピング前に作成することは推奨されません。参考資料：データストリームの概要、データモデルオブジェクトの概要、計算されたインサイトの概要、Salesforceを使用した顧客生涯価値（CLV）の計算、[セグメンテーションの概要]
  ai_analysis:
    related_docs:
    - title: インサイトによるデータの拡張
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_insights.htm&language=ja&type=5
      reason: このドキュメントは、問題で要求されている「顧客生涯価値（LTV）」が計算済みインサイトで作成できるKPIの明確な例であることを示しています。また、作成した評価指標をセグメンテーションの条件として使用する流れを説明しており、問題のシナリオに直接関連しています。
      supporting_text: 評価指標には、プロファイル、セグメント、母集団レベル、またはその他の目的の特殊評価指標での顧客生涯価値 (LTV)、参照回数が最多のカテゴリ、および顧客満足度スコア
        (CSAT) などがあります。...マーケティング担当者は、評価指標、ディメンション、および検索条件を使用して、有効化のセグメント条件とパーソナライズ属性を定義できます。
    - title: 計算済みインサイトを使用したセールスデータの分析
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_analyze_ci_dc4sales.htm&language=ja&type=5
      reason: このドキュメントは、計算済みインサイトが「マッピングされたオブジェクトや項目から」作成されることを明記しています。これにより、「データモデルへのデータのマッピング」が「計算されたインサイトの作成」の前に行われるべきステップであることが裏付けられ、正答のプロセスの順序を技術的に支持します。
      supporting_text: Data Cloud 管理者またはデータアウェアスペシャリストは、SQL 式を作成したり、SQL インサイトビルダーを使用してマッピングされたオブジェクトや項目から総計値やディメンションを作成したりできます。
    - title: Data Cloud からのデータの分析
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_business_intelligence_analytics.htm&language=ja&type=5
      reason: このドキュメントは、計算済みインサイト（パフォーマンスインサイト）を使用してセグメントを構築・強化できることを示しており、「計算されたインサイトの作成」の後に「セグメンテーションでの使用」というステップが続くことの妥当性を説明しています。
      supporting_text: アクション可能なパフォーマンスインサイトを使用してセグメントを構築および強化し、より関連性の高いオーディエンスとキャンペーンを使用してマーケティングの投資収益率
        (ROI) を向上させます。
    ai_verification:
      status: 一致
      justification: 問題は、ソースデータにないKPI（顧客生涯価値）を算出し、セグメンテーションに利用するためのData Cloudでの手順を問うています。正答「A.
        データの取り込み > データモデルへのデータのマッピング > 計算されたインサイトの作成 > セグメンテーションでの使用」は、Data Cloudの標準的なデータ処理フローと一致します。まずデータをシステムに取り込み（取り込み）、それを構造化されたデータモデルにマップし（マッピング）、そのマップされたデータに基づいて新しい指標を計算し（計算されたインサイト）、最終的にその指標をセグメンテーションの条件として利用します。参照ドキュメント「インサイトによるデータの拡張」では、LTVが計算済みインサイトの例として挙げられ、セグメント条件に利用できると記載されています。また、「計算済みインサイトを使用したセールスデータの分析」では、計算済みインサイトがマッピングされたオブジェクトから作成されることが明記されており、このプロセスの順序が正しいことを裏付けています。
- question_id: 15
  question_text: 'Cumulus Financialは現在、Data Cloudを活用し、S3コネクタを介してバックエンドシステムから取引データをアップサートモードで取り込みています。6ヶ月前の初期設定時に、同社はData
    Cloudにカスタム分類を作成するための数式フィールドを作成しました。現在、より多くの分類に対応するために、この数式を更新する必要があります。

    S3 コネクタを使用する場合、コンサルタントは数式フィールドの更新に関してどのような点に留意する必要がありますか?'
  choices:
    A: Data Cloud は $3 からデータの完全更新を開始し、すべてのレコードの数式を更新します。
    B: Data Cloud は、新しいレコードに対してのみ、今後数式を更新します。
    C: Data Cloud は、upsert タイプのデータ ストリームの数式フィールドの更新をサポートしていません。
    D: Data Cloud は、次回の増分アップサート更新時にすべてのレコードの数式を更新します。
  correct_answer: D
  japanese_explanation: '数式フィールドとは、他のフィールドまたは定数に基づいて値を計算するフィールドです。S3 コネクタを使用して Amazon
    S3 バケットからデータを取り込む場合、Data Cloud は、S3 ソースのデータを格納するデータレイクオブジェクト (DLO) 上の数式フィールドの作成と更新をサポートします。ただし、数式フィールドの更新はすぐには適用されず、データストリームの次回の増分アップサート更新時に適用されます。増分アップサート更新とは、主キーフィールドに基づいて、S3
    ソースから DLO に新しいレコードを追加し、既存のレコードを更新するプロセスです。したがって、コンサルタントは、数式フィールドの更新は新しいレコードと既存のレコードの両方に影響しますが、データストリームの次回の増分アップサート更新後にのみ適用されることを念頭に置く必要があります。Data
    Cloud は S3 からのデータの完全更新を開始せず、新しいレコードに対してのみ数式を更新せず、アップサートタイプのデータストリームに対する数式フィールドの更新をサポートしているため、他のオプションは正しくありません。参考資料:
    数式フィールドの作成、Amazon S3 接続、Data Lake オブジェクト'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提示された公式ドキュメント候補は、主にCumulus社のMarketing Cloudとの連携ユースケースやデータ基盤に関する内容です。問題で問われている「S3コネクタのアップサートモードでデータストリームの数式フィールドを更新した場合の具体的な動作（既存レコードへの影響）」について、直接的かつ明確に記述している箇所は見つかりませんでした。そのため、提供された情報だけでは正答Dが正しいかを検証することはできません。
- question_id: 16
  question_text: Salesforce Data Cloud の典型的な使用例は何ですか?
  choices:
    A: Salesforceエコシステム全体でのデータ同期
    B: CRMデータをPromiseに保存する
    C: 複数のプラットフォーム間でのデータの調和
    D: 大規模なパーソナライズメールの送信
  correct_answer: C
  japanese_explanation: 'Salesforce Data Cloud の典型的なユースケースは、複数のプラットフォーム間でのデータの調和です。その理由は次のとおりです。

    Salesforce データクラウドを理解する

    Salesforce Data Cloud は、CRM、Marketing Cloud、外部システム、サードパーティ プラットフォームなどの複数のソースから顧客データを集約、統合、分析するように設計されています。

    その主な目的は、パーソナライズされたエクスペリエンスと実用的な洞察のために顧客データの統合ビューを提供することです。

    複数のプラットフォーム間でデータを調和させる理由

    データの調和：

    Data Cloud は、さまざまなソースからのデータを標準化およびクレンジングすることで、データを調和させます。

    これにより、プラットフォーム間の一貫性と正確性が確保され、組織は顧客データの唯一の信頼できるソースを作成できるようになります。

    ユースケースの調整:

    データの調和は Data Cloud のコア機能であり、提供されるオプションの中で最も関連性の高いユースケースとなります。

    その他のオプションはあまり重要ではありません:

    A . Salesforce エコシステム全体でのデータ同期: Data Cloud は Salesforce 製品と統合されますが、主な焦点は Salesforce
    だけでなく複数のプラットフォームからのデータを統合することにあります。

    B. CRM データをオンプレミスで保存: Data Cloud はクラウドベースのソリューションであり、オンプレミスのストレージをサポートしていません。

    D. パーソナライズされたメールを大規模に送信する: これは、Data Cloud ではなく Marketing Cloud のユースケースです。

    データの調和を実現するための手順

    ステップ1: データの取り込み

    複数のソース (CRM、Marketing Cloud、外部システムなど) から顧客データを Data Cloud に取り込みます。

    ステップ2: データの標準化とクレンジング

    バッチ変換またはストリーミング変換を使用して、形式を標準化し、重複を削除し、データをクレンジングします。

    ステップ3: 統合プロファイルを作成する

    ID 解決を使用して、関連するレコードを 1 つの統合プロファイルにマージします。

    ステップ4: インサイトを有効にする

    調整されたデータを活用して、セグメンテーション、パーソナライゼーション、分析を行います。

    結論

    Salesforce Data Cloud の最も一般的な使用例は、複数のプラットフォーム間でのデータの調和であり、組織が顧客データを効果的に統合して活用できるようにします。'
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudの基本機能として「すべてのデータソースを接続」し、「データを標準データモデルにハーモナイズ」し、「データを統合します」と明確に記載しており、正答である「複数のプラットフォーム間でのデータの調和」を直接的に説明しているため。
      supporting_text: Salesforce Data Cloud を使用して、ストリーミングデータとバッチデータの取得、ハーモナイズ、統合、分析を行いましょう。...データが非構造化データか構造化データかに関係なく、すべてのデータソースを接続します。...データを標準データモデルにハーモナイズします。ID
        解決ルールセットを使用してデータを統合します。
    - title: カスタマーサービスデータの統合によるサポートの向上
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_service_cloud_guide.htm&language=ja&type=5
      reason: Service Cloudという具体的なプラットフォームを例に挙げ、「すべてのカスタマーサービスデータを統合してハーモナイズする」ことがData
        Cloudの機能であると述べており、「複数のプラットフォーム間でのデータの調和」という使用例を具体的に示しているため。
      supporting_text: Data Cloud では、Service Cloud のすべてのカスタマーサービスデータを統合してハーモナイズすることで、顧客の全体像を把握できます。...個人データモデルオブジェクトに基づく一致ルールと調整ルールを含む
        ID 解決ルールセットを使用して、複数のデータソースを統合プロファイルにリンクします。
    - title: 目標販売のリードの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_sales_unify.htm&language=ja&type=5
      reason: このドキュメントは、Sales Cloudのデータを例に取り、「ID解決を使用して、複数のデータソースを統合プロファイルにリンクする」と説明しており、これも「複数のプラットフォーム間でのデータの調和」という使用例に合致するため。
      supporting_text: Data Cloud では、多くのデータソースに接続できます。...ID 解決ルールセットを使用して、複数のデータソースを統合プロファイルにリンクします。ルールセットには、取引先データモデルオブジェクトまたは個人データモデルオブジェクトに基づく一致ルールと調整ルールが含まれます。
    ai_verification:
      status: 一致
      justification: 複数の公式ドキュメント（「Salesforce Data Cloud について」、「カスタマーサービスデータの統合によるサポートの向上」など）において、Data
        Cloudの中核機能が、様々なソース（プラットフォーム）からのデータを接続し、「ハーモナイズ（調和）」し、「統合」することであると一貫して説明されている。これは、正答「C.
        複数のプラットフォーム間でのデータの調和」と完全に一致する。
- question_id: 17
  question_text: どのソリューションが、Marketing Cloud の加入者プロファイル属性を毎日 Data Cloud に取り込む簡単な方法を提供しますか?
  choices:
    A: Automation Studio およびプロファイル ファイル API
    B: マーケティングクラウド接続 API
    C: Marketing Cloud データ拡張機能のデータストリーム
    D: Email Studio スターター データ バンドル
  correct_answer: C
  japanese_explanation: 'Marketing Cloud の購読者プロファイル属性を Data Cloud に日々簡単に取り込むソリューションが、Marketing
    Cloud データ拡張機能「データストリーム」です。Marketing Cloud データ拡張機能「データストリーム」は、Marketing Cloud データ拡張機能から
    Data Cloud データスペースにデータをストリーミングできる機能です。ストリーミングするデータ拡張機能を選択すると、Data Cloud がデータスペース内に対応するデータモデルオブジェクト
    (DMO) を自動的に作成し、更新します。

    お客様は、ユーザーインターフェースまたはAPIを使用して、データ拡張フィールドをDMO属性にマッピングすることもできます。Marketing Cloudデータ拡張のデータストリームを使用すると、コードを記述したり複雑な統合を設定したりすることなく、Marketing
    CloudからData Cloudにサブスクライバープロファイル属性などのデータを取り込むことができます。

    その他のオプションは、Marketing Cloud の購読者プロファイル属性を Data Cloud に日常的に簡単に取り込むことができるソリューションではありません。Automation
    Studio と Profile file API は、Marketing Cloud から外部システムにデータをエクスポートするために使用できるツールですが、スクリプトの作成、ファイル転送の設定、自動化のスケジュール設定など、お客様自身で行う必要があります。Marketing
    Cloud Connect API は、Sales Cloud や Service Cloud などの他の Salesforce ソリューションで Marketing
    Cloud のデータにアクセスするために使用できる API ですが、Data Cloud へのデータのストリーミングはサポートしていません。Email Studio
    Starter Data Bundle は、Email Studio 用のサンプルデータとセグメントを含むデータキットですが、購読者プロファイル属性は含まれておらず、Data
    Cloud へのデータのストリーミングもサポートされていません。

    参考文献:

    * マーケティングクラウドデータ拡張データストリーム

    * データクラウドデータ取り込み

    * [Marketing Cloud データ拡張データストリーム API]

    * [マーケティングクラウドコネクトAPI]

    * [Email Studio スターター データ バンドル]'
  ai_analysis:
    related_docs:
    - title: Data Cloud の Marketing Cloud Engagement Starter データバンドル
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_starter_data_bundles.htm&language=ja&type=5
      reason: このドキュメントは、Email Studioのスターターデータバンドルが「エンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリーム」を取得することを明記しており、これが問題の「加入者プロファイル属性」の取り込みに直接対応しています。これにより、データストリームがプロファイル属性を取り込むためのソリューションであることがわかります。
      supporting_text: Email Studio データセットには、送信、開封、クリック、バウンス、苦情、登録解除、Einstein エンゲージメントスコアなどのメールエンゲージメントイベントがあります。これらの総計値はキャンペーン、ジャーニー、メールテンプレートメタデータから取得されます。これらのシステム定義のテーブルに加えて、メールコネクタによってエンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリームが取得されます。このデータは、メールを操作している登録者基盤について人口統計上のコンテキストを提供します。
    - title: Marketing Cloud Engagement Starter バンドルからのデータストリームの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_marketing_cloud_data_stream.htm&language=ja&type=5
      reason: このドキュメントは、Marketing Cloud EngagementからData Cloudへデータを取り込む基本的な方法が「データストリームの作成」であることを示しています。これにより、選択肢C「データストリーム」が正しいアプローチであることが裏付けられます。
      supporting_text: Marketing Cloud Engagement ソースから Data Cloud へのデータフローを開始するには、スターターバンドルからデータストリームを作成します。Data
        Cloud では、SFMC エンタープライズプロファイル属性データストリームの数式項目のみがサポートされています。
    - title: Data Cloud での Marketing Cloud Engagement 接続の設定
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_set_up_marketing_cloud_connection.htm&language=ja&type=5
      reason: このドキュメントは、Marketing CloudとData Cloudの接続設定について説明しており、その中で「後でデータエクステンションを手動で追加することもできます」と記載されています。これは、スターターバンドルだけでなく、任意のデータ拡張機能をソースとしてデータストリームを作成できることを示しており、正答の「データ拡張機能のデータストリーム」を直接的に支持します。
      supporting_text: データバンドルを使用して、複数のデータストリームをすばやく簡単に作成して Engagement からシステム所有のデータを取得します。後でデータエクステンションを手動で追加することもできます。
    ai_verification:
      status: 一致
      justification: 問題は、Marketing Cloudの加入者プロファイル属性をData Cloudに簡単に取り込む方法を問うています。正答「Marketing
        Cloud データ拡張機能のデータストリーム」は、Data Cloudの標準的なデータ取り込み機能です。公式ドキュメントには、「メールコネクタによってエンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリームが取得されます」と明記されており、プロファイル属性をデータストリームで取り込むことが示されています。さらに、「後でデータエクステンションを手動で追加することもできます」との記述もあり、データ拡張機能をソースとするデータストリームの作成が、簡単で標準的な方法であることを裏付けています。したがって、正答はドキュメントの内容と一致します。
- question_id: 18
  question_text: 'Northern Trail Outfittersは毎日、過去24時間の店舗取引の概要をAmazon S3バケット内の新しいファイルにアップロードしています。7日以上経過したファイルは自動的に削除されます。各ファイルには、標準化された命名規則に従ってタイムスタンプが付けられています。

    このデータ ストリームを取り込むときにコンサルタントが設定する必要がある 2 つのオプションはどれですか。

    2つの回答を選択してください'
  choices:
    A: 古いファイルの削除が有効になっていることを確認します。
    B: 更新モードが「Upsert」に設定されていることを確認します。
    C: タイムスタンプを収容するためにファイル名にワイルドカードが含まれていることを確認します。
    D: 更新モードが「完全更新」に設定されていることを確認します。
  correct_answer: B,C
  japanese_explanation: 'Amazon S3 バケットからデータを取り込む場合、コンサルタントは次のオプションを設定する必要があります。

    更新モードは「Upsert」に設定する必要があります。これは、新規レコードと更新されたレコードがData Cloudに追加または更新され、既存のレコードは保持されることを意味します。これにより、データは常に最新の状態になり、ソースとの整合性が確保されます。

    ファイル名には、タイムスタンプに対応するワイルドカードを含める必要があります。つまり、ファイル名のパターンには、タイムスタンプの形式に一致する変数部分を含める必要があります。例えば、ファイル名がstore_transactions_2023-12-18.csvの場合、ワイルドカードはstore_transactions_*.csvとなります。これにより、取り込みプロセスは毎日正しいファイルを識別して処理できるようになります。

    その他のオプションは、このシナリオには必要ありません。

    古いファイルの削除はAmazon S3バケットの機能であり、Data Cloudの取り込みプロセスではありません。Data Cloudはソースからファイルを削除することはなく、取り込み後にソースファイルを削除する必要もありません。

    フルリフレッシュは、Data Cloud 内の既存のレコードをすべて削除し、ソースファイルのレコードに置き換えるリフレッシュモードです。このモードは、特にソースファイルに過去
    24 時間のトランザクションの概要のみが含まれている場合、データの損失と不整合が発生する可能性があるため、このシナリオには適していません。参考：Amazon
    S3 からのデータの取り込み、リフレッシュモード'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 問題は、Amazon S3から日次で生成されるタイムスタンプ付きのファイルを取り込む際のData Cloudデータストリーム設定について問うています。正解の選択肢である「更新モードをUpsertに設定」と「ファイル名にワイルドカードを使用」は、このようなシナリオにおける標準的な設定です。Upsertは新規データと更新データの両方を効率的に処理し、ワイルドカードは日付ごとに変わるファイル名を動的に指定するために不可欠です。しかし、提供された公式ドキュメントの抜粋には、データモデル、ID解決、セグメンテーション、有効化に関する情報や、S3コネクタの概要が記載されているのみで、データストリーム設定時の「更新モード」や「ワイルドカード」といった具体的なオプションについて直接言及している箇所は見つかりませんでした。したがって、提供された情報のみでは正解の妥当性を検証できません。
- question_id: 19
  question_text: 'Northern Trail Outfitters (NTO) は、B2C コマース データを Data Cloud に接続し、2
    年間の取引履歴を Data Cloud に取り込むことを望んでいます。

    これを達成するために NTO は何を使うべきでしょうか?'
  choices:
    A: B2Cコマーススターターバンドル
    B: 直接販売注文エンティティの取り込み
    C: 直接販売製品エンティティの取り込み
    D: B2C コマース スターター バンドルとカスタム抽出
  correct_answer: D
  japanese_explanation: 'B2C Commerceスターターバンドルは、B2C Commerceから注文データと商品データをData Cloudに取り込むための事前定義されたデータストリームです。ただし、スターターバンドルはデフォルトで過去90日間のデータのみを取得します。2年間の取引履歴を取り込むには、NTOはB2C
    Commerceから履歴データを含むカスタム抽出を使用し、そのカスタム抽出をソースとして使用するようにデータストリームを設定する必要があります。他の方法では、以下の理由により、この目的を達成できません。

    A. B2C Commerce スターターバンドルは、デフォルトでは過去 90 日間のデータのみを取り込みま す。

    B. 直接販売注文エンティティの取り込みは、B2C CommerceデータをData Cloudに接続するためのサポートされていない方法です。Data CloudはB2C
    Commerceデータへの直接アクセス接続を提供しておらず、データの取り込みのみを提供しています。

    C. 直接販売商品エンティティの取り込みは、B2C CommerceデータをData Cloudに接続するためのサポートされていない方法です。Data CloudはB2C
    Commerceデータへの直接アクセス接続を提供しておらず、データの取り込みのみを提供しています。参考：B2C Commerceデータバンドルの作成 - Salesforce、B2C
    Commerceコネクタ - Salesforce、Salesforce B2C Commerceの料金プランと費用'
  ai_analysis:
    related_docs:
    - title: B2C Commerce コネクタ
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_commerce_cloud_connector.htm&language=ja&type=5
      reason: このドキュメントには、B2C Commerceコネクタが標準で取り込む履歴データは30日間に限定されることが明記されています。問題の要件である「2年間の取引履歴」を満たすには標準機能だけでは不十分であり、追加の「カスタム抽出」が必要であることの直接的な根拠となります。
      supporting_text: B2C Commerce と Data Cloud 間の接続を確立すると、B2C Commerce コネクタは 30
        日間の履歴データを取り込みます。たとえば、5 月 1 日に接続を確立した場合、B2C Commerce コネクタは 4 月 2 日から 5 月 1
        日までの履歴データを取り込みます。
    - title: B2C Commerce データストリームの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_commerce_cloud_starter_bundle.htm&language=ja&type=5
      reason: このドキュメントは、B2C CommerceからData Cloudへデータを取り込むための標準的な方法として「注文バンドル」（スターターバンドルの一種）を使用することを示しています。これは、正答の「B2C
        コマース スターター バンドル」部分の妥当性を裏付けています。
      supporting_text: Data Cloud 管理者は注文バンドルを使用して、B2C Commerce インスタンスからデータを取り込むデータストリームを作成できます。データバンドルでは、データストリームの作成とマッピングが行われます。注文バンドルは一種のデータバンドルです。
    ai_verification:
      status: 一致
      justification: 公式ドキュメント「B2C Commerce コネクタ」には、標準のコネクタが取り込む履歴データは過去30日分に限定されると記載されています。問題の要件である「2年間の取引履歴」を取り込むためには、標準の「B2C
        コマース スターター バンドル」に加えて、30日を超える期間のデータを補うための「カスタム抽出」が必要となります。したがって、両者を組み合わせた選択肢Dが正答であると判断できます。
- question_id: 20
  question_text: Interaction SDK または Mobile SDK を介して収集されたデータに対して 15 分間のウィンドウで集計を実行する場合、コンサルタントはどの方法を使用する必要がありますか?
  choices:
    A: バッチ変換
    B: 計算された洞察力
    C: ストリーミングの洞察
    D: 数式フィールド
  correct_answer: C
  japanese_explanation: ストリーミングインサイトは、Interaction SDK または Mobile SDK を介して収集されたデータに対して、15
    分間隔で集計を実行できる手法です。ストリーミングインサイトは、Web、モバイル、IoT デバイスなど、さまざまなソースからのストリーミングデータに基づいて、リアルタイムの指標とインサイトを作成できる機能です。ストリーミングインサイトを使用すると、カウント、合計、平均、最小、最大、パーセンタイルなどの集計ルールを定義し、15
    分間隔でストリーミングデータに適用できます。例えば、ストリーミングインサイトを使用して、ウェブサイトまたはアプリの訪問者数、平均セッション継続時間、コンバージョン率を
    15 分間隔で計算できます。また、ストリーミングインサイトを使用すると、集計データをダッシュボード、グラフ、または表で視覚化して調査することもできます。参考：ストリーミングインサイト、ストリーミングインサイトの作成
  ai_analysis:
    related_docs:
    - title: インサイトによるデータの拡張
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_insights.htm&language=ja&type=5
      reason: このドキュメントは、「ストリーミングインサイト」がWeb SDKやMobile SDKなどのストリーミングデータソースからのデータに対して、直近の期間で集計クエリを実行する機能であることを直接説明しており、問題の要件と完全に一致するため。
      supporting_text: ストリーミングインサイトは、直近の期間のリアルタイムエンゲージメントデータに基づく集計クエリです。データは、Web SDK
        や Mobile SDK などのストリーミングデータソースから処理されます。ストリーミングインサイトを使用して、ほぼリアルタイムで時系列集計を作成し、Data
        Cloud でオーケストレーションやデータアクションを促進できます。
    - title: ビルダーを使用したストリーミングインサイトの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_streaming_insight.htm&language=ja&type=5
      reason: ストリーミングインサイトを作成する際のデータソースとして、Web SDKやMobile SDKから作成されたオブジェクトが指定されていることを明確に示しており、問題文のシナリオを裏付けているため。
      supporting_text: ストリーミングインサイトの作成に使用できるのは、Web SDK や Mobile SDK などのストリーミングデータソースから作成されたオブジェクトのみです。
    - title: Web およびモバイルアプリケーションコネクタ
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_web_mobile_app_connector.htm&language=ja&type=5
      reason: 問題文の「15分間」という具体的な時間枠に関連する記述があり、Web/Mobile SDKからのエンゲージメントデータが15分以下の間隔でData
        Cloudに取り込まれることを示しているため。これはストリーミング処理の文脈を補強する。
      supporting_text: Data Cloud では、エンゲージメントデータは 15 分以下、プロファイルデータは 2 分以下ごとに取り込まれます。
    ai_verification:
      status: 一致
      justification: 問題は「Interaction SDKまたはMobile SDK」からのデータに対し「15分間のウィンドウで集計」する方法を尋ねています。公式ドキュメント「インサイトによるデータの拡張」では、「ストリーミングインサイト」が「Web
        SDK や Mobile SDK などのストリーミングデータソースから」のデータに対し「直近の期間のリアルタイムエンゲージメントデータに基づく集計クエリ」を実行する機能であると明確に記載されています。また、「Web
        およびモバイルアプリケーションコネクタ」のドキュメントは、SDKからのデータ取り込みが「15分以下」で行われることを示しており、問題のシナリオと整合します。したがって、正答「C.
        ストリーミングの洞察」はドキュメントの記述と完全に一致します。
- question_id: 21
  question_text: '小売顧客はさまざまなソースから顧客データを取得したいと考えています

    そして、アイデンティティ解決を利用して、

    セグメンテーションに使用されます。

    アクティベーション メンバーシップではどのエンティティにセグメント化する必要がありますか?'
  choices:
    A: 加入者
    B: 統合された個体
    C: 統合連絡先
    D: 個人
  correct_answer: B
  japanese_explanation: '正解はB（統合個人）です。統合個人とは、異なるデータソースにまたがる顧客を表すレコードで、ID解決ルールセットを適用することで作成されます。ID解決ルールセットとは、共通属性に基づいて異なるソースのデータをリンクおよびマージする方法を定義する、一致および調整ルールのセットです。Data
    Cloudは、ID解決ルールセットを使用して複数のデータソースにまたがるデータを解決し、データの取得元に関係なく、顧客ごとに1つのレコードを作成できるようにします1。異なるソースから顧客データを取得し、ID解決をセグメンテーションに使用したい小売顧客は、解決済みおよび統合済みの顧客データを含む統合個人エンティティでセグメント化する必要があります。その他の選択肢は、異なるソースにまたがる解決済みの顧客データを表していないため、不正解です。購読者とは、マーケティングコミュニケーションの受信をオプトインした顧客を表すレコードです。統合連絡先とは、特定の事業部門と関係のある顧客を表すレコードです。個人とは、単一のデータソースからの顧客のプロファイルデータを表すレコードです。参考：

    アイデンティティ解決ルールセットの処理結果

    セグメンテーションにおけるデータの影響を考慮する

    Salesforce データクラウド コンサルタント資格取得の準備

    AIベースのID解決：多様な顧客データをリンク'
  ai_analysis:
    related_docs:
    - title: ID 解決でのスケジュール済み一致とリアルタイム一致
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_match_type_compare.htm&language=ja&type=5
      reason: このドキュメントには、ID解決のスケジュール済み一致の結果、更新されたプロファイル情報が「統合個人データモデルオブジェクト」に保存されると明確に記載されています。これは、ID解決によって生成されセグメンテーションに使用されるエンティティが「統合個人
        (Unified Individual)」であることを直接的に裏付ける最も強力な証拠です。
      supporting_text: スケジュール済み照合では、選択した照合方法を使用して、新規および更新されたソースデータが 1 日に数回確認されます。更新された統合プロファイル情報は、統合取引先または統合個人データモデルオブジェクトに保存されます。
    - title: ID 解決ルールセット
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_ruleset.htm&language=ja&type=5
      reason: このドキュメントは、ID解決の基本概念を説明しており、「統合プロファイル」を作成するプロセスであること、およびその結果として「統合個人プロファイル」が生成されることを示しています。これにより、問題の文脈と正答の妥当性が補強されます。
      supporting_text: ルールセットには、複数のデータソースを統合プロファイルにリンクする方法を Customer Data Platform
        に指示する一致ルールと調整ルールが含まれます。統合プロファイル情報は、ルールセットによって作成されたデータモデルオブジェクトに保存されます。...ソースデータでいずれかのソースプロファイルが既知として指定されている場合、統合個人プロファイルは既知とみなされます。
    - title: ID 解決を使用したセールスデータの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_unify_data_dc4sales.htm&language=ja&type=5
      reason: このドキュメントは、ID解決ルールセットを作成する際にプライマリデータオブジェクトとして「個人」を選択し、その結果「統合プロファイル」が作成される具体的な手順を示しています。これは、「個人」オブジェクトが統合されて「統合個人」になるという概念を理解するのに役立ちます。
      supporting_text: ID 解決ルールセットを使用して、複数のデータソースを統合プロファイルにリンクします。ルールセットには、取引先データモデルオブジェクトまたは個人データモデルオブジェクトに基づく一致ルールと調整ルールが含まれます。
    ai_verification:
      status: 一致
      justification: 問題は、Data CloudのID解決プロセスを経た後、セグメンテーションとアクティベーションに使用すべきエンティティは何かを問うています。ドキュメント「ID
        解決でのスケジュール済み一致とリアルタイム一致」には、『更新された統合プロファイル情報は、...統合個人データモデルオブジェクトに保存されます』と明確に記載されています。また、他のドキュメントでも「統合個人プロファイル」という用語が使われています。ID解決は、様々なソースの「個人」に関するデータを統合し、「統合個人
        (Unified Individual)」という単一のプロファイルを作成するプロセスです。セグメンテーションはこの統合されたエンティティに対して行われるため、正答「B.
        統合された個体」はドキュメントの内容と完全に一致します。
- question_id: 22
  question_text: 'ある顧客が、過去30日間に注文を行った顧客の大規模なセグメントを作成し、…から関連属性をアクティベーションに追加しました。Marketing
    Cloudでアクティベーションを確認すると、30日以上前の注文が含まれていることに気付きました。

    この問題を解決するためにコンサルタントは何をすべきでしょうか?'
  choices:
    A: Marketing Cloud Engagement で SQL を使用して、30 日以上経過した注文を削除します。
    B: データ スペース フィッターを適用して、30 日以上経過した注文を除外します。
    C: 購入注文日にフィルターを適用して、30 日以上経過した注文を除外します。
    D: 30 日間のデータのみを含むデータ グラフを使用します。
  correct_answer: C
  japanese_explanation: ''
  ai_analysis:
    related_docs:
    - title: 標準セグメントの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_a_segment.htm&language=ja&type=5
      reason: 問題は、セグメント作成時に意図した条件（過去30日間の注文）が正しく設定されていないことが原因です。このドキュメントには、セグメント作成プロセスにおいて「コンテナで特定の条件を適用」できることが記載されています。これが正答である「購入注文日にフィルターを適用する」という操作に直接該当し、問題解決の根拠となります。
      supporting_text: セグメントの場合、コンテナで特定の条件を適用できますが、デフォルトのルックバック期間と異なることがあります。そのため、セグメントレベルのルックバックが
        90 日に設定され、コンテナ条件が 60 日に設定されている場合、コンテナ条件が優先され、データは 60 日間のみ取り込まれます。
    - title: Marketing Cloud Engagement のデータ基盤要件の確立
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_req.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudが「セグメント化」の役割を担うことを明確に定義しています。これにより、問題の解決策がアクティベーション先（Marketing
        Cloud）でのデータ操作（選択肢A）ではなく、Data Cloud内でのセグメント定義の修正（選択肢C）であるべきだという原則を裏付けています。
      supporting_text: Data Cloud は、データの取り込み、解決、変換、セグメント化、強化を行うように設計されています。Marketing
        Cloud Engagement は、パーソナライズされたメッセージングキャンペーンを調整するエンゲージメント製品です。
    ai_verification:
      status: 一致
      justification: 問題は、Data Cloudで作成した「過去30日間の注文」セグメントに、意図せず30日以上前のデータが含まれてしまう事象です。これは、セグメント作成時に期間を指定するフィルターが正しく適用されていないことが原因と考えられます。正答「C.
        購入注文日にフィルターを適用して、30 日以上経過した注文を除外します。」は、Data Cloudのセグメントビルダー内で直接的な条件を設定し、問題を根本から解決する正しいアプローチです。公式ドキュメント「標準セグメントの作成」には、セグメント作成時にコンテナで特定の条件を適用できる旨が記載されており、これが正答の操作を裏付けています。したがって、正答は公式ドキュメントで説明されているData
        Cloudのセグメンテーション機能と一致します。
- question_id: 23
  question_text: 信頼に基づくファーストパーティ データ資産を構築するとはどういう意味ですか?
  choices:
    A: 使用に同意し、その見返りに価値を受け取る個人から収集したデータの透明性とセキュリティを確保するため
    B: すべてのコンプライアンス規制に準拠した、信頼できるファーストパーティデータをデータクラウドマーケットプレイスで提供する
    C: 法律で義務付けられているすべての電子メールマーケティングでオプトインの同意が収集されるようにするため
    D: インタビュー、アンケート、世論調査を通じて信頼できる情報源から競合データを入手する
  correct_answer: A
  japanese_explanation: 信頼に基づくファーストパーティデータ資産を構築するということは、顧客や見込み客のプライバシーと嗜好を尊重しながらデータを収集、管理、活用することを意味します。また、データの使用方法、データ共有によるメリット、そしてデータの管理方法について、明確かつ誠実な情報を顧客に提供することも意味します。そうすることで、顧客と相互に有益な関係を築き、責任ある倫理的なデータ利用を信頼してもらえるようになり、より関連性の高いパーソナライズされたエクスペリエンスを提供できるようになります。信頼に基づくファーストパーティデータ資産は、顧客ロイヤルティ、顧客維持率、顧客成長の向上、そしてデータ保護規制や標準への準拠に役立ちます。参考資料：ファーストパーティデータを活用し、強力なデジタルエクスペリエンスを実現する、ファーストパーティデータがデータプライバシーの鍵となる理由、ファーストパーティデータ戦略の構築
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供されたドキュメント候補は、パスワード管理、ログイン、レコード所有権、データ整理といったSalesforceの基本的な機能や操作に関するものです。問題が問うている「信頼に基づくファーストパーティデータ資産の構築」という、データプライバシー、同意管理、透明性、顧客との価値交換といった、より戦略的で概念的なトピックについて直接言及している情報は見当たりません。そのため、提供されたドキュメントだけでは正答の妥当性を判断することはできません。
- question_id: 24
  question_text: '世界的なファッション小売業者は、AMFR、FMFA、APAC 全体でオンライン販売プラットフォームを運営しています。顧客、注文、製品情報のデータ形式は地域によって異なり、コンプライアンス規制では元のデータ
    ソースでデータを変更せずに維持することが求められています。また、リアルタイムのパーソナライゼーションと分析のために、顧客プロファイルの統合ビューも必要です。

    これらの要件を考慮すると、企業は受信データ ストリームを標準化およびクレンジングするためにどのような変換アプローチを実装する必要がありますか?'
  choices:
    A: ストリーミング データ変換を実装します。
    B: バッチデータ変換を実装します。
    C: Apex を使用してデータを変換およびクレンジングします。
    D: Data Cloud に取り込む前にデータを変換します。
  correct_answer: A
  japanese_explanation: ''
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 問題は、複数の地域からリアルタイムで受信する、形式の異なるデータを統合・標準化するための最適なアプローチを問うています。要件である「リアルタイムのパーソナライゼーションと分析」と「元のデータソースの変更不可」という制約から、Data
        Cloudの「ストリーミングデータ変換」が最も適した解決策です。しかし、提供された公式ドキュメント候補には、このストリーミングデータ変換機能や、リアルタイムのデータ処理アーキテクチャについて直接的に解説したものが含まれていません。提示されたドキュメントは、データエクスプローラーでのフィルタリング、AIモデルの品質、セキュリティ（MFA）など、問題の核心とは異なるトピックを扱っており、正解の根拠を検証することができません。
- question_id: 25
  question_text: 'ある銀行は、ローン申込者と富裕層顧客の顧客データを収集しています。顧客はローン申込者と富裕層顧客の両方である可能性があり、その結果、データが重複することになります。

    コンサルタントはどのようにしてこのデータを Data Cloud に取り込み、マッピングすればよいでしょうか?'
  choices:
    A: データを 2 つの DLO に取り込み、それぞれを個人および連絡先の電子メール DMO にマップします。
    B: データを 2 つの DLO に取り込み、2 つのカスタム DMO にマップします。
    C: データ変換を使用してデータを 1 つの DLO に統合し、それを個々の DMO と連絡先メール DMO にマップします。
    D: データを 1 つの DLO に取り込み、1 つのカスタム DMO にマップします。
  correct_answer: C
  japanese_explanation: ''
  ai_analysis:
    related_docs:
    - title: データの準備とモデル化
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_prepare_and_model_data.htm&language=ja&type=5
      reason: このドキュメントは、正解の選択肢にある「データ変換」について直接言及しており、複数のデータソースを扱う際のデータの整理と準備の重要性を説明しているため、問題解決の核心となる考え方を裏付けています。
      supporting_text: 'Data Cloud の一括処理データ変換: クイックルック

        Data Cloud のセグメンテーションおよび有効化機能を正常に動作させるには、データの整理と準備が不可欠です。'
    - title: データマッピングのベストプラクティス
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_mapping_best_practices.htm&language=ja&type=5
      reason: このドキュメントは、複数のデータソースをどのように「個人」などの統合オブジェクトに関連付けるかを検討することの重要性を強調しています。問題のシナリオである2つの顧客データソースを統合し、個人DMOにマッピングするというアプローチの正当性を強く支持します。
      supporting_text: '各データソースと対応する項目が、統合するオブジェクト (個人オブジェクトや取引先オブジェクトなど) にどのように関連するかを検討します。

        データをマッピングできる使用可能な標準データモデルオブジェクト (DMO) と関連項目を確認します。'
    - title: データマッピング
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_mapping.htm&language=ja&type=5
      reason: このドキュメントは、データがDLOに書き込まれた後、DMOにマッピングするというData Cloudの基本的なプロセスを説明しています。問題で問われている「取り込みとマッピング」の基本的な流れを理解する上で不可欠です。
      supporting_text: すべてのデータストリームによって取り込まれたデータは、データレークオブジェクト (DLO) に書き込まれます。データストリームを作成したら、DLO
        をデータモデルオブジェクト (DMO) に関連付ける必要があります。リレーションによりマッピングされた項目およびオブジェクトのみをセグメンテーションと有効化で使用できます。
    - title: Data Cloud 用語集
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_glossary_guide.htm&language=ja&type=5
      reason: 問題と選択肢で使われているDLO（データレークオブジェクト）とDMO（データモデルオブジェクト）、データマッピングという基本用語の正確な定義が記載されており、問題の意図を正しく理解するための基礎知識を提供します。
      supporting_text: 'データレークオブジェクト (DLO)

        Data Cloud 内のすべてのデータストリームに取り込まれるデータのデータレーク内のストレージコンテナ。

        データモデルオブジェクト (DMO)

        データストリーム、インサイト、およびその他のソースから作成された (属性で構成される) データのグルーピング。

        データマッピング

        データが Data Cloud に取り込まれた後に、データレークオブジェクト (DLO) をデータモデルオブジェクト (DMO) に関連付ける (マッピングする)
        プロセス。'
    ai_verification:
      status: 一致
      justification: 問題は、重複の可能性がある2つのデータソースをData Cloudに統合する最適な方法を問うています。正解Cは、「データ変換」を用いてデータを1つのDLOに統合し、それを標準の「個人DMO」と「連絡先メールDMO」にマッピングするアプローチを提案しています。これはData
        Cloudのベストプラクティスと完全に一致します。「データの準備とモデル化」のドキュメントで言及されているように、データ変換は取り込みデータの整理・準備に不可欠です。また、「データマッピングのベストプラクティス」では、複数のソースを個人DMOのような標準オブジェクトに統合することが推奨されています。他の選択肢は、データを非効率的に分離したままにしたり（A,
        B）、統合の具体的な方法に言及していなかったり（D）するため、Cが最も優れた解決策です。
- question_id: 26
  question_text: 'Data Cloud コンサルタントが、アカウント DMO と連絡先ポイント アドレス DMO 間の新しい 1 対 1 の関係を保存しようとしましたが、エラーが発生します。

    このエラーを修正するにはコンサルタントは何をすべきでしょうか?'
  choices:
    A: 追加フィールドを連絡先アドレス DMO にマップします。
    B: アカウント レコードの合計数が ID 解決に十分な大きさであることを確認します。
    C: アカウントごとに複数の連絡先に対応するために、カーディナリティを多対 1 に変更します。
    D: アカウントを連絡先の電子メールと連絡先の電話にもマッピングします。
  correct_answer: C
  japanese_explanation: '* リレーションシップのカーディナリティ: Salesforce Data Cloud では、データ モデル オブジェクト
    (DMO) 間の正しいリレーションシップのカーディナリティを定義することが、正確なデータ表現と統合に不可欠です。

    * 1 対 1 の関係エラー: アカウント DMO と連絡先ポイント アドレス DMO の関係が 1 対 1 に設定されているため、各アカウントが持つことができる連絡先ポイント
    アドレスは 1 つだけであるために、エラーが発生します。

    * 解決：

    カーディナリティの変更：リレーションシップのカーディナリティを多対1に変更します。これにより、複数の連絡先アドレスを単一のアカウントに関連付けることができ、実際のシナリオをより正確に反映できます。

    手順:

    Data Cloud のデータ モデル構成に移動します。

    アカウント DMO と連絡先アドレス DMO の関係を見つけます。

    関係タイプを 1 対 1 から多対 1 に変更します。

    * 利点：

    正確な表現: アカウントに複数の連絡先がある可能性がある実際のデータ シナリオに対応します。

    エラー解決: エラーを解決し、スムーズなデータ統合を保証します。

    * 参照：

    Salesforce Data Cloud ドキュメント: リレーションシップ

    Salesforce ヘルプ: Data Cloud でのデータモデリング'
  ai_analysis:
    related_docs:
    - title: データモデルオブジェクトの表示
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_model_object_view.htm&language=ja&type=5
      reason: 問題はData CloudのDMO間のリレーション設定に関するエラーについて尋ねています。このドキュメントは、DMOのリレーションを作成・編集する具体的な手順に言及しており、「リレーションを表示、編集、または無効化するには、リストビューまたはグラフビューから
        DMO を選択します。[リレーション] に移動して、[編集] または [新規] をクリックします。オブジェクトと項目間のリレーションを作成します」と説明しています。この操作の中でカーディナリティ（1対1、多対1など）を設定するため、問題の根本原因である不適切なカーディナリティ設定を修正する場所と操作に直接関連します。
      supporting_text: リレーションを表示、編集、または無効化するには、リストビューまたはグラフビューから DMO を選択します。[リレーション]
        に移動して、[編集] または [新規] をクリックします。オブジェクトと項目間のリレーションを作成します。
    ai_verification:
      status: 一致
      justification: 問題は、アカウントDMOと連絡先ポイントアドレスDMO間のリレーションを「1対1」で保存しようとしてエラーが出た状況についてです。通常、1つのアカウント（会社）には複数の連絡先が存在する可能性があるため、データモデルとして「1対1」は不適切です。この関係は「1対多」で表現するのが一般的です。SalesforceのDMOリレーションでは、子オブジェクト側（この場合は連絡先ポイントアドレス）から見て「多対1」として設定します。したがって、正答である「C.
        アカウントごとに複数の連絡先に対応するために、カーディナリティを多対1に変更します。」は、データモデリングの観点から論理的に正しい解決策です。他の選択肢は、フィールドマッピングやID解決のデータ量に関するものであり、リレーションの多重度（カーディナリティ）という根本的な問題には触れていません。
- question_id: 27
  question_text: '顧客は、特定のセグメントのアクティベーションが失敗するたびに通知を受け取る必要があります。

    このユースケースを解決するためにコンサルタントはどの機能を使用する必要がありますか?'
  choices:
    A: フロー
    B: レポート
    C: アクティベーションアラート
    D: ダッシュボード
  correct_answer: C
  japanese_explanation: コンサルタントがこのユースケースを解決するために活用すべき機能は、C. アクティベーションアラートです。アクティベーションアラートとは、セグメントのアクティベーションが失敗または成功した際にユーザーに送信される通知です。アクティベーションアラートは「アクティベーション設定」ページで設定でき、コンサルタントはアラートの受信者、頻度、送信条件を指定できます。アクティベーションアラートは、顧客がアクティベーションのステータスを監視し、発生する可能性のある問題をトラブルシューティングするのに役立ちます。参考：Salesforce
    Data Cloud コンサルタント試験ガイド、アクティベーションアラート
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 問題は「セグメントのアクティベーションが失敗した場合の通知」に関する機能を問うており、正答は「アクティベーションアラート」とされています。この機能名は問題の要件に合致していると考えられますが、提供された公式ドキュメント候補の中には「アクティベーションアラート」について直接言及しているものがありません。そのため、提供された情報だけでは正答の妥当性を検証できません。
- question_id: 28
  question_text: '顧客は、Salesforce CRMの標準連絡先オブジェクトに関連付けられたカスタム顧客メールオブジェクトを保有しています。このカスタムオブジェクトには、アクティベーションに使用する連絡先のメールアドレスが格納されます。

    どのデータ エンティティがマップされますか?'
  choices:
    A: 連絡先
    B: 連絡先メールアドレス
    C: カスタム顧客 Email__c オブジェクト
    D: 個人
  correct_answer: B
  japanese_explanation: 'Contact Point_Email オブジェクトは、Data Cloud 内の個人に関連付けられたメールアドレスを表すデータエンティティです。これは、顧客データの共通エンティティとリレーションシップを定義する標準化されたデータモデルである
    Customer 360 データモデルの一部です。Contact Point_Email オブジェクトは、Salesforce CRM 内のメールアドレスを格納する任意のカスタムオブジェクトまたは標準オブジェクト（カスタム
    Customer Email__c オブジェクトなど）にマッピングできます。その他のオプションは、以下の理由により、マッピングする適切なデータエンティティではありません。

    A. 連絡先オブジェクトは、Salesforce CRMの顧客、パートナー、または競合他社の取引先に関連付けられた個人を表すデータエンティティです。Data
    Cloudのメールアドレスを表すデータエンティティではありません。

    C. カスタム Customer Email__c オブジェクトは、Data Cloud のデータエンティティではなく、Salesforce CRM のカスタムオブジェクトです。Contact
    Point_Email オブジェクトなどの Data Cloud のデータエンティティにマッピングできますが、それ自体はデータエンティティではありません。

    D . 個人オブジェクトは、Data Cloud において固有の個人を表すデータエンティティです。同意とプライバシー設定を管理するための中核エンティティであり、メールアドレス、電話番号、ソーシャルメディアのハンドルなど、1
    つ以上の連絡先に関連付けることができます。Data Cloud においてメールアドレスを表すデータエンティティではありません。参考資料: Customer
    360 データモデル: 個人と連絡先 - Salesforce、Contact Point_Email | Salesforce Platform のオブジェクトリファレンス
    | Salesforce Developers、[連絡先 | Salesforce Platform のオブジェクトリファレンス | Salesforce
    Developers]、[個人 | Salesforce Platform のオブジェクトリファレンス | Salesforce Developers]'
  ai_analysis:
    related_docs:
    - title: Contact Point Email Schema
      url: https://developer.salesforce.com/docs/data/data-cloud-ref/guide/c360a-api-engagement-mobile-sdk-contact-point-email-schema.html
      reason: このドキュメントは、Data Cloudの「Contact Point Email」スキーマについて直接説明しており、これがプロファイルデータ（この問題ではカスタムオブジェクトのメールアドレス）をキャプチャし、個人のデータストリームにマッピングするために使用されることを明確に示しています。正答である「連絡先メールアドレス」の存在と役割を直接裏付ける最も強力な証拠です。
      supporting_text: Use the contact point email schema to capture profile data
        to map to individual data streams.
    - title: 'Customer 360 データモデル: 個人および連絡先'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_cloud_information_model_individual_and_contact_points.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudのデータモデルにおける「個人(Individual)」と「連絡先(Contact Point)」が基本となる重要な概念であることを説明しています。これにより、個人そのものを表すエンティティと、メールアドレスのような連絡先情報を格納するエンティティが区別されていることがわかります。この概念は、なぜ「個人」ではなく「連絡先メールアドレス」にマッピングするのかという理由を補強します。
      supporting_text: 個人および連絡先オブジェクトは、正常かつ完全なデータストリームの重要な概念です。
    - title: Customer 360 データモデル
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_c360datamodel.htm&language=ja&type=5
      reason: このドキュメントは、Customer 360 データモデルの全体像を説明し、その中に「関係者データモデル」が存在することを示しています。このモデルが「特定の顧客または取引先の取引先責任者情報
        (個人または法人)」をグループ化すると記述されており、メールアドレスのような具体的な連絡先情報が、個人を表す上位の概念とは別の、専用のエンティティ（この場合は連絡先ポイント）にマッピングされるというデータモデルの構造を裏付けています。
      supporting_text: '関係者データモデル

        Customer 360 データモデル関係者主題では、特定の顧客または取引先の取引先責任者情報 (個人または法人) が反映されたデータモデルオブジェクト
        (DMO) をグループ化します。'
    ai_verification:
      status: 一致
      justification: 問題は、CRMのカスタムオブジェクトに格納されたメールアドレスをData Cloudにマッピングする際の適切なデータエンティティを問うています。正答は「B.
        連絡先メールアドレス」です。これはCustomer 360 データモデルの標準的な設計と一致します。このモデルでは、個人そのものを表す「個人 (Individual)」DMOと、メールアドレスや電話番号といった連絡手段を格納する「連絡先ポイント
        (Contact Point)」DMO群が明確に区別されています。公式ドキュメント「Contact Point Email Schema」は、メールアドレスをマッピングするための専用スキーマの存在を直接示しています。したがって、ソースとなるカスタムオブジェクトのメールアドレスフィールドは、Data
        Cloudの「連絡先メールアドレス (Contact Point Email)」DMOにマッピングするのが正しいです。
- question_id: 29
  question_text: '顧客は生涯価値について計算された洞察力を持っています。

    計算された洞察の場合、コンサルタントは何に注意する必要がありますか。

    変更が必要ですか?'
  choices:
    A: 新しいディメンションを追加できます。
    B: 既存のディメンションを削除できます。
    C: 既存の対策を削除できます。
    D: 新しい対策を追加できます。
  correct_answer: B
  japanese_explanation: '計算インサイトとは、SQL式を用いてデータから定義・計算される多次元指標です。計算インサイトには、ディメンションとメジャーを含めることができます。ディメンションとは、顧客ID、製品カテゴリ、地域など、データをグループ化またはフィルタリングするために使用されるフィールドです。メジャーとは、売上高、数量、平均注文額など、計算や集計を実行するために使用されるフィールドです。計算インサイトは、SQL式を編集するか、データスペースを変更することで変更できます。ただし、コンサルタントは計算インサイトを変更する際に、以下の制限事項と考慮事項に注意する必要があります12。

    既存のディメンションは削除できません。SQL式からディメンションを削除すると、計算インサイトの実行に失敗し、エラーメッセージが表示されます。これは、そのディメンションが計算インサイトオブジェクトの主キーの作成に使用されているため、削除すると既存のデータとの競合が発生するためです。したがって、正解はBです。

    新しいディメンションを追加できます。SQL式にディメンションを追加すると、計算インサイトが実行され、計算インサイトオブジェクトにそのディメンション用の新しいフィールドが作成されます。ただし、コンサルタントはディメンションを追加しすぎないように注意する必要があります。ディメンションを追加しすぎると、計算インサイトのパフォーマンスとユーザビリティに影響する可能性があります。

    既存のメジャーは削除可能です。SQL式からメジャーを削除すると、計算インサイトが実行され、計算インサイトオブジェクトからそのメジャーのフィールドが削除されます。ただし、コンサルタントは、メジャーを削除すると、計算インサイトを使用している既存のセグメントやアクティベーションに影響する可能性があることに注意する必要があります。

    新しいメジャーを追加できます。SQL式にメジャーを追加すると、計算インサイトが実行され、計算インサイトオブジェクト内にそのメジャー用の新しいフィールドが作成されます。ただし、コンサルタントはメジャーを追加しすぎないように注意する必要があります。計算インサイトのパフォーマンスとユーザビリティに影響を及ぼす可能性があります。参考資料：計算インサイト、データスペースにおける計算インサイト。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供されたドキュメントには、一度作成・有効化した計算済みインサイト（Calculated Insight）の変更に関する制約について、具体的な記述が見つかりませんでした。問題は、既存の計算済みインサイトのディメンションやメジャー（対策）をどのように変更できるかを問うていますが、参照ドキュメントはData
        CloudのID解決、データ変換、計算済みインサイトの作成方法に関する一般的な説明に留まっており、作成後の編集ルール（ディメンションやメジャーの追加・削除の可否）について直接言及している部分はありません。したがって、正答が「B.
        既存のディメンションを削除できます。」であることの根拠を提示できません。
- question_id: 30
  question_text: 'ある企業は顧客データを Marketing Cloud に保存し、Marketing Cloud Connector を使用してデータを
    Data Cloud に取り込みます。

    データ削除または忘れられる権利の要求はどこに提出すればよいですか?'
  choices:
    A: データクラウド設定
    B: データクラウドの個々のデータプロファイルについて
    C: マーケティングクラウドの設定
    D: Consent API 経由
  correct_answer: C
  japanese_explanation: 'データ削除リクエスト: Salesforce Marketing Cloud および Data Cloud を使用している企業にとって、データのプライバシーと削除リクエストの管理は不可欠です。

    Marketing Cloud コネクタ: このコネクタは Marketing Cloud と Data Cloud 間のデータ統合を容易にしますが、データ削除リクエストは特定の手順に従う必要があります。

    Marketing Cloud での削除リクエスト:

    * データ管理: データの削除または忘れられる権利のリクエストは、顧客データが元々保存および管理されている Marketing Cloud 設定を通じて送信されます。

    * 伝播: リクエストが Marketing Cloud で処理されると、変更はコネクタを通じて Data Cloud に伝播されます。

    参考文献:

    * Salesforce Marketing Cloud ドキュメント: データ管理

    * Salesforce データクラウドコネクタガイド'
  ai_analysis:
    related_docs:
    - title: Data Cloud のデータソース
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_connectors.htm&language=ja&type=5
      reason: 問題のシナリオである「Marketing Cloud Connectorを使用してデータを Data Cloud に取り込む」構成において、Marketing
        CloudがData Cloudの「データソース」であることを明確に定義しているため。データ削除要求は、データの源泉であるソースシステムで対応するのが原則であり、このドキュメントはその関係性を示しています。
      supporting_text: データソースは、Marketing Cloud Engagement コネクタや CRM コネクタなどの Salesforce
        コネクタになります。Salesforce コネクタには、データストリームをすばやく設定できるようにオブジェクトとマッピングを事前定義するスターターデータバンドルが用意されています。
    - title: Data Cloud での Marketing Cloud Engagement 接続の設定
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_set_up_marketing_cloud_connection.htm&language=ja&type=5
      reason: このドキュメントは、Marketing CloudからData Cloudへの接続設定について詳述しています。「最上位のビジネスユニットは事前に選択されており、メールチャネルのすべての登録者データがこのレベルであるため、選択解除できません」という記述は、顧客の根幹データである「登録者データ」がMarketing
        Cloud側でマスターとして管理されていることを示唆します。したがって、データ削除もマスターデータを保持するMarketing Cloudで行うべきという正答の強い根拠となります。
      supporting_text: 最上位のビジネスユニットは事前に選択されており、メールチャネルのすべての登録者データがこのレベルであるため、選択解除できません。
    - title: データスペースへの Marketing Cloud エンゲージメントバンドルのリリース
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_deploy_a_marketing_cloud_bundle_to_a_data_space.htm&language=ja&type=5
      reason: このドキュメントは、Marketing Cloudの購読者データがData Cloudに取り込まれるプロセスを説明しています。「Engagement
        購読者が、Data Cloud に取り込まれた同じビジネスユニットにマッピングされていることを確認します」という記述から、顧客データの主体がMarketing
        Cloud側にあることがわかります。Data Cloudはあくまでそのデータのコピーを利用する側であるため、削除要求はデータの発生源であるMarketing
        Cloudで処理するのが適切だと判断できます。
      supporting_text: Engagement 設定で [プロファイルビジネスユニットのデータマッピングを許可] が有効になっている場合、Engagement
        購読者が、Data Cloud に取り込まれた同じビジネスユニットにマッピングされていることを確認します。
    ai_verification:
      status: 一致
      justification: 問題は、Marketing Cloud(MC)をデータソースとしてData Cloud(DC)にデータを取り込んでいる場合のデータ削除要求の提出先を問うています。正答は「Marketing
        Cloud の設定」です。これは、MCがデータの一次ソース（Source of Truth）であり、DCはそのデータのコピーを利用する従属的な立場にあるというアーキテクチャに基づいています。関連ドキュメントは、MCがDCの「データソース」であること、そして顧客の根幹情報である「登録者データ」がMC側で管理されていることを明確に示しています。データ管理の原則として、削除要求はデータのマスターを保持するソースシステムで処理されるべきであるため、提供されたドキュメントは正答を完全に支持しています。
- question_id: 31
  question_text: 'Northern Trail Outfitters (NTO) は、メール キャンペーンの特定のセグメントに該当する連絡先のリストを
    Data Cloud コンサルタントに依頼しました。

    コンサルタントはこのリストを NTO にどのように提供すればよいでしょうか?'
  choices:
    A: セグメントを作成し、「ダウンロード」をクリックして、NTO に提供するセグメント メンバーシップの詳細を取得します。
    B: 新しいファイル ストレージ アクティベーション ターゲットを作成し、セグメントを作成してから、新しいアクティベーション ターゲットに対してセグメントをアクティベートします。
    C: セグメントを作成し、アクティベーション ターゲットとして電子メールを選択し、NTO に近いセグメントをアクティベートします。
    D: セグメントを作成し、そのセグメントを NTO の Salesforce CRM に対してアクティブ化します。
  correct_answer: B
  japanese_explanation: 'Data Cloud でのセグメント作成: Salesforce Data Cloud を使用すると、ターゲットを絞ったマーケティング
    キャンペーンの特定の基準に基づいてセグメントを作成できます。

    アクティベーションターゲット：セグメントを作成したら、データを利用できるようにするにはアクティベーションを行う必要があります。セグメントデータの使用方法に応じて、様々なアクティベーションターゲットを設定できます。

    ファイルストレージアクティベーションターゲット：セグメントに適合する連絡先リストを提供するために、ファイルストレージアクティベーションターゲットを作成すると、セグメントデータをファイルとしてエクスポートできます。このファイルは、NTOのメーリングキャンペーンで共有できます。

    プロセス：

    * Salesforce Data Cloud でセグメント基準を定義します。

    * 新しいファイルストレージアクティベーションターゲットを作成します。

    * このターゲットに対してセグメントをアクティブ化すると、セグメント メンバーシップの詳細を含むダウンロード可能なファイルが生成されます。

    参考文献:

    * Salesforce Data Cloud ドキュメント: セグメンテーション

    * Salesforce データクラウドのアクティベーション'
  ai_analysis:
    related_docs:
    - title: データフロー
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_flow.htm&language=ja&type=5
      reason: 問題はData Cloudで作成したセグメントのリストを外部に提供する方法を問うています。正解の選択肢Bは「ファイル ストレージ アクティベーション
        ターゲット」を作成し、セグメントをアクティベートする手順を説明しています。このドキュメントは、「データターゲット」という概念を説明し、セグメントをSFTP、Amazon
        S3、Google Cloud Storageなどのファイルストレージに「有効化（アクティベート）」できることを明確に記載しており、正解のプロセスを直接裏付けています。
      supporting_text: 'ターゲットは次の目的で使用されます。


        Marketing Cloud Engagement、Amazon S3、SFTP、Google Cloud Storage (GCS)、Microsoft
        Azure Blob Storage に対してセグメントを有効化する。'
    ai_verification:
      status: 一致
      justification: 問題は、Data Cloudで作成したセグメントの連絡先リストをファイルとして提供する方法を尋ねています。正答である選択肢Bは、ファイルストレージをアクティベーションターゲットとして設定し、そこにセグメントをアクティベート（出力）する手順を示しています。関連ドキュメント「データフロー」には、「ターゲットは次の目的で使用されます。...Amazon
        S3、SFTP、Google Cloud Storage (GCS)、Microsoft Azure Blob Storage に対してセグメントを有効化する。」と明記されており、セグメントをファイルとして外部ストレージに出力する機能（アクティベーション）の存在を裏付けています。したがって、正答はドキュメントの内容と一致します。
- question_id: 32
  question_text: 'Cumulus Financialは、Data Cloudを利用して銀行顧客をセグメント化し、クラウドファイルストレージのアクティベーションを通じてダイレクトメールの配信対象者を絞り込んでいます。また、過去2年間にセグメントに含まれていた個人を分析したいと考えています。

    どの Data Cloud コンポーネントがこれを可能にしますか?'
  choices:
    A: ネストされたセグメント
    B: セグメント除外
    C: 計算された洞察
    D: セグメントメンバーシップデータモデルオブジェクト
  correct_answer: D
  japanese_explanation: 'セグメントメンバーシップデータモデルオブジェクトは、特定の期間内にセグメントに所属していた個人を分析できるData
    Cloudコンポーネントです。セグメントメンバーシップデータモデルオブジェクトは、どの個人がどのセグメントに属しているか、またいつセグメントに追加または削除されたかに関する情報を格納するテーブルです。このオブジェクトは、セグメントのサイズ、セグメントの期間、セグメントの重複、セグメントの保持率など、セグメンテーションおよびアクティベーション戦略の有効性を測定するのに役立つ計算されたインサイトを作成するために使用できます。セグメントメンバーシップデータモデルオブジェクトは、セグメント名、セグメントタイプ、セグメントの日付範囲などのセグメントメンバーシップ基準に基づいて、ネストされたセグメントまたはセグメント除外を作成するためにも使用できます。その他のオプションは、過去2年以内にセグメントに所属していた個人を分析できるData
    Cloudコンポーネントではないため、正しくありません。ネストされたセグメントとセグメント除外は、既存のセグメントに基づいてより複雑なセグメントを作成できる機能ですが、セグメントメンバーシップに関する履歴データは提供しません。計算されたインサイトは、データモデルオブジェクトまたはデータレイクオブジェクトから派生したカスタム指標またはメジャーですが、それ自体ではセグメントメンバーシップ情報を保存しません。参照:
    セグメント メンバーシップ データ モデル オブジェクト、計算されたインサイトの作成、ネストされたセグメントの作成'
  ai_analysis:
    related_docs:
    - title: 新しいサービスプロモーション通知 (B2C) の使用事例のメール送信
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_activation_filtering_uc2_service_main.htm&language=ja&type=5
      reason: 問題文に登場する「Cumulus」が「Data Cloudでオーディエンスセグメントを作成する」事例として記載されており、問題の背景を理解する上で関連性があります。ただし、問題の核心である「過去のセグメントメンバーシップの分析」については触れられていません。
      supporting_text: Cumulus Bank は、新しいサービスに関するメールを顧客に送信したいと考えています。...Data Cloud
        でのオーディエンスセグメントの作成 オーディエンスセグメントは、メールキャンペーンへのエンゲージメント率が高い顧客で構成されます。新しいサービスに関する自動メールを作成するには、Data
        Cloud で次の手順に従ってオーディエンスセグメントを作成します。
    - title: 連絡先と有効化メンバーシップの絞り込み
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_activation_filtering_main.htm&language=ja&type=5
      reason: 問題文の「アクティベーション」というキーワードと、登場企業「Cumulus Bank and Financial Services」のユースケースが記載されているため関連があります。しかし、こちらも過去のメンバーシップ分析に関する直接的な記述はありません。
      supporting_text: 'Data Cloudの連絡先と有効化メンバーシップを介して連絡するユーザーをより詳細に制御することで、マーケティング
        コミュニケーションをパーソナライズします。検索条件を使用して、マーケティングセグメントで使用するデータの量と種類を制御します。


        連絡先と有効化メンバーシップの絞り込みのしくみを理解するには、架空の保険会社 Cumulus Bank and Financial Services
        の次の使用事例を確認してください。'
    ai_verification:
      status: 判断不能
      justification: 問題の要点は「過去2年間にセグメントに含まれていた個人を分析する」方法についてですが、提供された公式ドキュメントには、セグメントのメンバーシップ履歴を保持・分析する機能についての直接的な記述がありません。ドキュメントはCumulus社によるセグメント作成やアクティベーションの一般的なユースケースを示していますが、正答である「セグメントメンバーシップデータモデルオブジェクト」というコンポーネントやその役割については言及されていません。したがって、提供された情報のみに基づいて正答の妥当性を検証することはできません。
- question_id: 33
  question_text: 'コンサルタントは、顧客の注文の住所詳細が統合プロファイルに保存するために最適に選択されていることを確認したいと考えています。

    これを達成するためにコンサルタントは何をすべきでしょうか?'
  choices:
    A: 連絡先アドレスのアドレス詳細を選択します。特定のアドレス属性の照合ルールを「ソース優先度」に変更し、個人DMOを一番下に移動します。
    B: 連絡先アドレスのデフォルトの調整ルールを使用します。
    C: 連絡先アドレスのアドレス詳細を選択します。特定のアドレス属性の照合ルールを「ソース優先度」に変更し、「注文DMO」を最上位に移動します。
    D: 個別のデフォルトの調整ルールをソース優先度に変更します。
  correct_answer: C
  japanese_explanation: '統合プロファイル: Salesforce Data Cloud で統合された顧客プロファイルを作成するには、さまざまなソースからのデータを統合する必要があります。

    照合ルール：これらのルールは、競合するデータが発生した場合にどのデータソースが「最適」であると判断されるかを決定します。照合ルールを変更することで、特定のソースを優先することができます。

    ソースの優先順位: ソースの優先順位を設定するには、特定の属性に対してどのデータ ソースを他のデータ ソースよりも優先させるかを定義する必要があります。

    プロセス：

    * ステップ 1: 調整ルールの Data Cloud 設定にアクセスします。

    * ステップ 2: 連絡先の住所の詳細を選択します。

    * ステップ 3: アドレス属性の調整ルールを「ソース優先度」に変更します。

    * ステップ4：注文DMOを優先リストの一番上に移動します。これにより、顧客の注文の住所情報が優先され、統合プロファイルに保存するのに最適なデータとして選択されます。

    利点：

    * 精度: 統合プロファイルで最も正確で信頼性の高い住所データが使用されるようにします。

    * 関連性: 最も関連性が高く、頻繁に更新されるソース (顧客の注文) を優先します。

    参考文献:

    * Salesforce Data Cloud 調整ルール

    * Salesforce統合顧客プロファイル'
  ai_analysis:
    related_docs:
    - title: データマッピングのベストプラクティス
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_mapping_best_practices.htm&language=ja&type=5
      reason: 問題は、複数のデータソースから統合プロファイルの値を決定する際の優先順位付け（調整ルール）に関するものです。このドキュメントは、その前提となるデータマッピングの計画段階で「各データソースと対応する項目が、統合するオブジェクト...にどのように関連するかを検討する」必要性に言及しており、データソースの役割を考慮するコンセプトが関連しています。
      supporting_text: 各データソースと対応する項目が、統合するオブジェクト (個人オブジェクトや取引先オブジェクトなど) にどのように関連するかを検討します。
    - title: データの準備とモデル化
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_prepare_and_model_data.htm&language=ja&type=5
      reason: 問題が扱う統合プロファイルの属性値の最適化（調整）は、「データの準備とモデル化」という広範なプロセスの一部です。このドキュメントは、DLOからDMOへのマッピングなど、調整ルールの設定に至るまでの前提プロセスを概説しており、問題のコンテキストを理解する上で参考になります。
      supporting_text: Data Cloud のセグメンテーションおよび有効化機能を正常に動作させるには、データの整理と準備が不可欠です。すべてのデータストリームによって取り込まれたデータは、データレークオブジェクト
        (DLO) に書き込まれます。データストリームを作成したら、DLO をデータモデルオブジェクト (DMO) に関連付ける必要があります。
    ai_verification:
      status: 判断不能
      justification: 提供されたドキュメントには、ID解決プロセスにおける「調整ルール（Reconciliation Rules）」および「ソース優先度（Source
        Priority）」という、問題と正答の核心となる機能について具体的な説明が含まれていません。問題は、複数のデータソースから統合プロファイルの特定の属性値（住所）を決定するための設定方法を問うています。正答Cの内容（特定の属性の調整ルールをソース優先度に変更し、優先するDMOを最上位に移動する）は、Salesforce
        Data Cloudの標準的な機能と一致していますが、この操作の正当性を提示されたドキュメントから直接検証することはできません。
- question_id: 34
  question_text: 'データ クラウド コンサルタントは、新しいサービスベースのデータ ソースのデータ ストリームを設定中です。

    ケースデータを取り込む場合、どのフィールドをイベント時間フィールドに関連付けることが推奨されますか?'
  choices:
    A: 最終更新日
    B: 解決日
    C: エスカレーション日
    D: 作成日
  correct_answer: A
  japanese_explanation: イベント時間フィールドは、データストリーム内のイベントのタイムスタンプを取得する特別なフィールドタイプです。イベントの時系列を追跡し、時間ベースのセグメンテーションとアクティベーションを可能にするために使用されます。ケースデータを取り込む際に、イベント時間フィールドに関連付ける推奨フィールドは、最終更新日フィールドです。このフィールドはケースの最新の更新を反映し、ケースの期間、解決時間、顧客満足度を測定するために使用できます。解決日、エスカレーション日、作成日などの他のフィールドは、ケースの最新のステータスを取得できないか、すべてのケースに適用できない可能性があるため、イベント時間フィールドには適していません。参考資料：データストリームフィールドタイプ、Salesforce
    Data Cloud 試験問題
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提示された公式ドキュメントには、Data Cloudのデータストリームを設定する際に、ケースデータの「イベント時間フィールド」としてどの項目をマッピングすることが推奨されるかについての直接的な記述が含まれていません。正答である「最終更新日」が適切である理由は、ケースレコードに対する最新の変更や活動をイベントとして捉えることが、顧客の行動を時系列で追跡する上で最も有効であるという一般的なベストプラクティスに基づきますが、提供されたドキュメント群からこの結論を裏付けることはできません。
- question_id: 35
  question_text: 組織は、在庫管理システムからデータ クラウドに在庫レベルを高速かつスケーラブルに、ほぼリアルタイムでストリーミングするために何を使用すればよいでしょうか。
  choices:
    A: クラウドストレージコネクタ
    B: コマースクラウドコネクタ
    C: インジェスチョンAPI
    D: マーケティングクラウドパーソナライゼーションコネクタ
  correct_answer: C
  japanese_explanation: 'Ingestion APIは、あらゆるソースから高速かつスケーラブルにデータをデータクラウドにストリーミングできるRESTful
    APIです。Ingestion APIを使用すると、在庫管理システムからJSONオブジェクトとしてデータクラウドに送信し、データクラウドを使用して在庫データに基づいたデータモデル、セグメント、インサイトを作成できます。Ingestion
    APIはバッチモードとストリーミングモードの両方をサポートし、最大

    1秒あたり10万件のレコードを処理できます。Ingestion APIは、データ検証、暗号化、圧縮、再試行メカニズムなどの機能も提供し、データの品質とセキュリティを確保します。参考資料：Ingestion
    API開発者ガイド、データクラウドへのデータの取り込み'
  ai_analysis:
    related_docs:
    - title: Ingest Data into Data Cloud
      url: https://developer.salesforce.com/docs/data/data-cloud-ref/guide/c360a-api-salesforce-cdp-ingestion.html
      reason: このドキュメントは、Ingestion APIがストリーミングとバルクの両方のパターンをサポートしていることを明確に述べています。特に「ほぼリアルタイムで更新されるレコードの小さなマイクロバッチにはストリーミングインジェスチョンを使用する」という記述は、問題の「高速」「ほぼリアルタイム」「ストリーミング」という要件に直接合致しており、正答がIngestion
        APIであることの強力な根拠となります。
      supporting_text: 'The Ingestion API provides a RESTful interface that supports
        both streaming and bulk interaction patterns for loading data into Data Cloud.
        You can use a single Ingestion API connector for performing both bulk and
        streaming uploads.


        Consider the data source and the problem you’re trying to solve when choosing
        the ingestion mode.

        ... Use streaming ingestion for small micro-batches of records being updated
        in near-real time, such as:

        Source system built on modern streaming architectures.

        Change data capture events.

        Consuming data from webhooks.'
    - title: Streaming Ingestion Walkthrough
      url: https://developer.salesforce.com/docs/data/data-cloud-ref/guide/c360a-api-streaming-insert-example.html
      reason: このドキュメントは、Ingestion APIを使用したストリーミングインジェスチョンの具体的な手順を解説しており、正答である「インジェスチョンAPI」が、問題で問われているストリーミングによるデータ取り込みというユースケースで実際に使用されることを示しています。
      supporting_text: 'Streaming Ingestion Walkthrough


        Use this walkthrough to understand the steps for loading records using streaming
        ingestion.


        Before you can start, make sure you’ve completed the prerequisites required
        to set up your Ingestion API:'
    - title: Get Started with Ingestion API
      url: https://developer.salesforce.com/docs/data/data-cloud-ref/guide/c360a-api-get-started.html
      reason: 'このドキュメントは、Ingestion APIの利用開始について説明しており、その中でストリーミングインジェスチョンとバルクインジェスチョンの両方に言及しています。「For
        streaming: Small payloads (up to 200 KB per single request)」という記述は、Ingestion
        APIがストリーミング機能を持ち、小規模なデータを高頻度で取り込むことを想定していることを裏付けています。'
      supporting_text: 'Before using Ingestion API in Data Cloud, complete the prerequisites,
        set up authentication, and know the limits that apply to bulk ingestion and
        streaming ingestion. ... For streaming: Small payloads (up to 200 KB per single
        request)'
    ai_verification:
      status: 一致
      justification: 問題は、在庫管理システムからData Cloudへ、高速かつほぼリアルタイムでデータをストリーミングする方法を尋ねています。公式ドキュメント「Ingest
        Data into Data Cloud」には、Ingestion APIがRESTfulインターフェースを提供し、ストリーミングとバルクの両方のパターンをサポートしていること、そして「ほぼリアルタイムで更新されるレコードの小さなマイクロバッチにはストリーミングインジェスチョンを使用する」ことが明記されています。これは問題の要件と完全に一致します。したがって、正答である「C.
        インジェスチョンAPI」は正しいです。
- question_id: 36
  question_text: データクラウド コンサルタントは、セグメンテーション中に同意を適切に適用するにはどうすればよいでしょうか?
  choices:
    A: 該当するエンゲージメント チャネルのアクティベーション中に、ゴールデン レコードからの同意ステータスを含めます。
    B: 各セグメントのフィルター条件に、該当するエンゲージメント チャネルのパーティ ID を含めます。
    C: 該当するエンゲージメント チャネルのセグメンテーション中に、統合プロファイルを含めます。
    D: 各セグメントのフィルター条件に、該当するエンゲージメント チャネルの同意ステータスを含めます。
  correct_answer: D
  japanese_explanation: '* Salesforce Data Cloud における同意管理について:

    同意管理は、GDPRやCCPAなどのデータ保護規制へのコンプライアンスを維持するために不可欠です。これにより、顧客データが付与された許可に従って使用されることが保証されます。

    参照：

    * セグメンテーションにおける同意ステータスの役割:

    同意ステータスは、顧客が特定の種類の通信またはデータ処理アクティビティに同意またはオプトインしたかどうかを示します。

    セグメンテーション中に正しい同意ステータスを適用することで、必要な許可を提供した顧客だけが対象キャンペーンに含まれるようになります。

    * セグメンテーションにおける同意ステータスの実装:

    セグメントを作成するときに、フィルター条件に同意ステータスを含めると、同意の設定に基づいてオーディエンスを動的にセグメント化するのに役立ちます。

    これにより、コンプライアンスが確保され、コミュニケーションの関連性とパーソナライゼーションが向上します。

    例: 電子メールによるアウトリーチのマーケティング キャンペーンを作成する場合、セグメントには電子メールによる通信を許可する同意ステータスを持つ顧客のみが含まれます。

    * 実用的な応用:

    Salesforce Data Cloud 内のセグメンテーション ツールに移動します。

    フィルター条件に、エンゲージメント チャネルに関連する同意ステータス属性を追加します。

    準拠した顧客プロファイルのみが含まれるように、値 (例: オプトイン、サブスクライブ済み) を定義します。'
  ai_analysis:
    related_docs:
    - title: 同意管理
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_consent_management.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudにおける同意管理の概要を説明しており、特に「セグメンテーションでの同意設定の使用」というセクションで、問題の核心であるセグメンテーション中に同意を適用する方法について直接言及しているため。
      supporting_text: 'セグメンテーションでの同意設定の使用

        Data Cloud のセグメンテーションでの同意設定の使用方法についての詳細を説明します。'
    - title: データ倫理
      url: https://help.salesforce.com/s/articleView?id=data.c360a_ethics.htm&language=ja&type=5
      reason: このドキュメントは、顧客の設定を尊重することの重要性を強調しており、セグメンテーションで同意フィルターを適用するという行為の倫理的な根拠を提供しているため。
      supporting_text: 顧客が自分の情報に関する設定をコントロールできるようにします。顧客には自分のデータの使用について発言する権利があります。最も重要なのは、顧客が設定を指定したら、必ずその設定を尊重することです。
    ai_verification:
      status: 一致
      justification: 問題はセグメンテーション中に同意を適切に適用する方法を尋ねている。正答である選択肢D「各セグメントのフィルター条件に、該当するエンゲージメント
        チャネルの同意ステータスを含めます。」は、セグメンテーションの絞り込み機能を使って同意を得ている顧客のみを対象にするという具体的な方法を示している。公式ドキュメント「同意管理」には「セグメンテーションでの同意設定の使用」という項目があり、Data
        Cloudのセグメンテーション機能で同意設定を利用することが想定されていることを明確に示している。したがって、正答はドキュメントの内容と一致する。
- question_id: 37
  question_text: Data Cloud が CRM データを取り込む方法に関連する考慮事項のうち正しいものはどれですか?
  choices:
    A: CRMデータは手動で更新できず、次回のスケジュールされた同期まで待つ必要があります。
    B: CRM コネクタの同期時間は、最大 15 分間隔にカスタマイズできます。
    C: 数式フィールドは定期的な同期間隔で更新され、次回の完全更新時に更新されます。
    D: CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。
  correct_answer: D
  japanese_explanation: '正解は D です。CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。

    つまり、CRMデータソースの標準フィールドへの変更は、次回のスケジュールされた同期を待たずに、ほぼ瞬時にData Cloudに反映されます。この機能により、Data
    Cloudはセグメンテーションとアクティベーションに必要な最新かつ正確なCRMデータを保持できます1。

    その他のオプションは、次の理由により正しくありません。

    A: CRMデータは、データストリーム詳細ページ2の「更新」ボタンをクリックすることで、いつでも手動で更新できます。このオプションは無効です。

    B: CRMコネクタの同期時間は、最大60分間隔までカスタマイズできます。

    15分間隔3。このオプションは無効です。

    C: 数式フィールドは定期的な同期間隔ではなく、次回の完全更新4時にのみ更新されます。完全更新とは、24時間ごと、または手動でトリガーされたときに実行される完全なデータ取り込みプロセスです。このオプションはFalseです。

    参考文献:

    1: Salesforce ヘルプの「Data Cloud でデータを接続して取り込む」の記事

    2: Trailhead の Data Cloud ユニットのデータソース

    3: Trailheadの管理者向けデータクラウドモジュール

    4: Trailheadの[Data Cloudの数式項目]ユニット

    5: Trailhead の [Data Cloud のデータストリーム] ユニット'
  ai_analysis:
    related_docs:
    - title: Data Cloud への Salesforce CRM 組織の接続
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_connect_salesforce_orgs.htm&language=ja&type=5
      reason: このドキュメントは、問題の主題である「Salesforce組織をData Cloudに接続して、Salesforceオブジェクトからデータを取得する」というCRMデータ取り込みの基本的な概念について説明しているため、関連性が高いです。
      supporting_text: Salesforce 組織を Data Cloud に接続して、Salesforce オブジェクトからデータを取得し、Data
        Cloud で処理と統合します。
    - title: ユーザーの設定と Sales Cloud データバンドルのインストール
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_conf_connect_dc4sales.htm&language=ja&type=5
      reason: このドキュメントは、Salesforce CRMコネクタの具体的な設定手順に触れており、問題で問われているCRMデータ取り込みの前提となる操作を説明しているため関連があります。
      supporting_text: 'Data Cloud での Salesforce 接続の設定


        データソースとデータアクションターゲットは、Data Cloud を設定した組織で自動的に作成されます。Sandbox 組織を含む他の Salesforce
        組織を接続するには、手動で接続を設定する必要があります。'
    - title: 標準の Salesforce CRM と Data Cloud One コンパニオン接続の比較
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_compare_salesforce_connections.htm&language=ja&type=5
      reason: CRMデータ取り込みに使用される接続種別の違いについて説明しており、データ取り込み方法の考慮事項を理解する上で背景情報として関連します。
      supporting_text: Salesforce 組織を Data Cloud に接続するには、標準 Salesforce CRM 接続または標準接続と組み合わせた
        Data Cloud One コンパニオン接続を使用します。次の表に、これらの接続種別の違いを示します。
    ai_verification:
      status: 判断不能
      justification: 正答である「D. CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。」で述べられている『リアルタイムストリーミング』という具体的なデータ同期の仕様について、提供された公式ドキュメント群には直接的な言及や裏付けとなる記述が見つかりませんでした。同様に、他の選択肢（A,
        B, C）の内容が正しいか誤っているかを判断するための情報も含まれていません。ドキュメントはCRM接続の概要、設定方法、アーキテクチャに焦点を当てており、同期の技術的な詳細（タイミング、対象フィールド）については触れていません。
- question_id: 38
  question_text: 空の値を無視するオプションは、ID 解決で何を行いますか?
  choices:
    A: カスタムマッチルールを実行するときに空のフィールドを無視します
    B: 照合ルールを実行するときに空のフィールドを無視します
    C: アイデンティティ解決ルールを実行するときに、空のフィールドを持つ個々のオブジェクトレコードを無視します。
    D: 標準の一致ルールを実行するときに空のフィールドを無視します
  correct_answer: B
  japanese_explanation: 'アイデンティティ解決の「空の値を無視」オプションを使用すると、調整ルールの実行時に空のフィールドを無視できます。調整ルールは、さまざまなソースの値に基づいて、統合された個人プロファイルの属性の最終的な値を決定するために使用されます。調整ルール内の各属性に対して、「空の値を無視」オプションを
    true または false に設定できます。true に設定すると、調整ルールはその属性の値が空であるソースをスキップし、優先順位の次のソースに進みます。false
    に設定すると、調整ルールはその属性の値が空であるソースを有効なソースと見なし、それを使用して統合された個人プロファイルの属性値を入力します。

    他のオプションは、アイデンティティ解決における「空の値を無視」オプションの動作を正しく説明していません。「空の値を無視」オプションは、異なるソース間で属性に基づいて個人を識別およびリンクするために使用されるカスタム一致ルールおよび標準一致ルールには影響しません。また、「空の値を無視」オプションは、アイデンティティ解決ルールの実行時に空のフィールドを持つ個々のオブジェクトレコードを無視しません。これは、アイデンティティ解決ルールがレコードレベルではなく属性レベルで実行されるためです。

    参考文献:

    * データクラウドアイデンティティ解決調整ルール入力

    * アイデンティティ解決ルールセットを構成する

    * データクラウドにおけるデータとアイデンティティ'
  ai_analysis:
    related_docs:
    - title: デフォルトの調整ルールの設定
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_reconciliation_rules_setdefault.htm&language=ja&type=5
      reason: このドキュメントでは、「空の値を無視」オプションがID解決の「調整ルール」の設定項目であることが明記されています。問題は「ID解決」におけるこのオプションの役割を問うており、このドキュメントが最も直接的な説明を提供しています。しかし、問題の正答が「照合ルール」と述べている点とは矛盾します。
      supporting_text: 'デフォルトの調整ルールでは、オブジェクトのすべての項目の値を選択する方法を ID 解決プロセスに指示します。

        ...

        必要に応じて、[空の値を無視] を選択します。'
    - title: ID 解決一致ルールの関係者識別子
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_partyidentifier.htm&language=ja&type=5
      reason: このドキュメントは「一致ルール」（照合ルール）における空白の値の扱いについて言及しており、「関係者識別子に基づく一致ルールでは、[空白の一致]
        オプションを使用できません」と記載されています。これは「空の値を無視する」オプションとは異なりますが、「照合ルール」と「空白の値」というキーワードで関連しています。
      supporting_text: '関係者識別子に基づく一致ルールでは、[空白の一致] オプションを使用できません。

        ...

        空白の識別番号は照合できません。'
    ai_verification:
      status: 矛盾の可能性あり
      justification: 問題の正答は「空の値を無視」オプションが「照合ルール」で機能するとしています。しかし、公式ドキュメント「デフォルトの調整ルールの設定」によると、このオプションは「調整ルール」の設定項目として明確に説明されています。「調整ルール」は統合プロファイルの項目値を決定するルールであり、「照合ルール」はレコードが同一であるかを判断するルールです。これらはID解決における異なるプロセスであるため、問題の正答と公式ドキュメントの記述には矛盾があると考えられます。
- question_id: 39
  question_text: 'Northern Trail Outfitters は Data Cloud を実装したいと考えており、いくつかのユースケースを考えています。

    Data Cloud に適していると考えられるユースケースはどれですか?

    2つの回答を選択してください'
  choices:
    A: さまざまなソースからデータを取り込み統合し、顧客IDを調整する
    B: クロスチャネルマーケティングメッセージを作成し、調整する
    C: 調和されたデータを使用して、顧客とビジネスへの影響をより正確に理解する
    D: ビジネスインテリジェンスとITデータ管理ツールを別々に用意する必要がなくなる
  correct_answer: A,C
  japanese_explanation: 'Data Cloudは、Salesforceや外部の様々なソースからデータを接続、準備、調和、統合、クエリ、分析し、それらに基づいて行動するのに役立つデータプラットフォームです。Data
    Cloudに適したユースケースとしては、以下のようなものが挙げられます。

    * 顧客IDを統合するために、様々なソースからデータを取り込み、統合します。Data Cloudは、ストリーミングデータからバッチデータまで、あらゆるデータをSalesforceに取り込み、共通のデータモデルにマッピングするお手伝いをします。また、Data
    Cloudは、異なるチャネルやソースにまたがるIDを解決し、顧客の統合プロファイルを作成するお手伝いもします。

    * 調和されたデータを活用し、顧客とビジネスへの影響をより正確に把握します。Data Cloudは、お客様がデータを利用する前に変換・クレンジングし、計算されたインサイトや関連属性でデータを拡充するお手伝いをします。また、Data
    Cloudは、お客様がデータに基づいてセグメントやオーディエンスを作成し、あらゆるチャネルで活用できるよう支援します。さらに、AIを活用して顧客の行動や成果を予測するお手伝いもします。

    他の2つのオプションは、Data Cloudに適したユースケースとは考えられません。Data Cloudには、クロスチャネルマーケティングメッセージの作成とオーケストレーションの機能はありません。これは通常、Marketing
    Cloudなどの他のSalesforceソリューションで処理されます。また、Data CloudはビジネスインテリジェンスツールやITデータ管理ツールと連携し、それらの機能を補完するように設計されているため、別途ビジネスインテリジェンスツールやITデータ管理ツールを用意する必要がなくなるわけではありません。

    参考文献:

    * データクラウドの仕組みを学ぶ

    * Salesforce Data Cloudについて

    * プラットフォームのユースケースを発見する

    * 一般的なデータ分析のユースケースを理解する'
  ai_analysis:
    related_docs:
    - title: Data Cloud への Salesforce CRM 組織の接続
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_connect_salesforce_orgs.htm&language=ja&type=5
      reason: 正答A「さまざまなソースからデータを取り込み統合し、顧客IDを調整する」を裏付けるドキュメントです。Data CloudがSalesforce組織など複数のソースからデータを取り込み、処理と統合を行うプラットフォームであることが明記されています。
      supporting_text: Salesforce 組織を Data Cloud に接続して、Salesforce オブジェクトからデータを取得し、Data
        Cloud で処理と統合します。
    - title: 'Customer 360 データモデル: 個人および連絡先'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_cloud_information_model_individual_and_contact_points.htm&language=ja&type=5
      reason: 正答Aの「顧客IDを調整する」という部分を直接的に裏付けるドキュメントです。インポートしたデータの顧客識別子を「個人ID」項目にマッピングすることで、ID解決が機能し、データの一貫性が保たれることが説明されています。
      supporting_text: 'ID 解決を動作させて、データセグメントを作成するときに正確なデータを受け取るには、インポートしたデータの顧客識別子を
        [個人 ID] 項目にマッピングする必要があります。


        個人 ID オブジェクトは、Data Cloud のデータの健全性を保つために重要です。顧客情報をインポートすると、その情報がこのオブジェクトにマッピングされ、製品全体で一貫性が保たれます。'
    - title: Data Cloud での Einstein セグメントの適切なプロンプトの記述方法
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_segment_einstein_prompts.htm&language=ja&type=5
      reason: 正答C「調和されたデータを使用して、顧客とビジネスへの影響をより正確に理解する」を裏付けるドキュメントです。Data Cloudで統合・調和されたデータ（DMOや属性）を使い、セグメントを作成することで、特定の条件を持つ顧客グループを抽出し、理解を深めるユースケースが示されています。
      supporting_text: "結果の改善に役立つ例をいくつか紹介します。要求に応答するときに生成 AI モデルが常に一貫しているとは限らないため、同じプロンプトを入力したときに異なる結果になることがあります。\n\
        ベストプラクティス\t推奨されないプロンプト\t推奨プロンプト\nプロンプトを一般的ではなく具体的にします。\t英国に住む顧客\t過去 60 日間に私の製品にエンゲージした英国在住のお客様"
    - title: セグメンテーションでの同意設定の使用
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_using_consent_preferences_in_segmentation.htm&language=ja&type=5
      reason: 正答C「調和されたデータを使用して、顧客とビジネスへの影響をより正確に理解する」の具体的な応用例を示すドキュメントです。同意設定という調和されたデータを用いて顧客をセグメント化し、マーケティング活動の対象者を正確に把握するユースケースが説明されています。
      supporting_text: たとえば、Northern Trail Outfitters は、メールコミュニケーションをオプトインし、プロモーションをオプトアウトしていない個人のセグメントを作成しました。セグメントに個人の同意設定が反映されるように、[同意状況]
        属性を検索条件として使用します。
    ai_verification:
      status: 一致
      justification: '問題はData Cloudの適切なユースケースを問うています。正答A「さまざまなソースからデータを取り込み統合し、顧客IDを調整する」は、Data
        Cloudの根幹機能であるデータの取り込み、統合、ID解決を指します。これはドキュメント「Data Cloud への Salesforce CRM
        組織の接続」や「Customer 360 データモデル: 個人および連絡先」で明確に裏付けられています。正答C「調和されたデータを使用して、顧客とビジネスへの影響をより正確に理解する」は、統合されたデータを活用してインサイトを得るというData
        Cloudの主要な価値提案です。これはドキュメント「Data Cloud での Einstein セグメントの適切なプロンプトの記述方法」や「セグメンテーションでの同意設定の使用」で示されるセグメンテーション機能によって具体化されています。したがって、提示された正答は公式ドキュメントの内容と一致しています。'
- question_id: 40
  question_text: 'ある組織では、ユーザーがオプションの選択リストからテキスト属性を識別して選択できるようにしたいと考えています。

    このユースケースに役立つ Data Cloud の機能はどれですか?'
  choices:
    A: 値の提案
    B: データの調和
    C: 変換式
    D: グローバル選択リスト
  correct_answer: A
  japanese_explanation: 値の提案は、セグメントフィルターを作成する際にテキストフィールドに入力可能な値を表示して選択できるデータクラウド機能です。値の提案は、データモデルオブジェクト（DMO）レコードホームの各DMOフィールドに対して有効または無効にできます。値の提案により、ユーザーは正確な値を入力したり記憶したりすることなく、選択肢からテキスト属性を特定して選択できます。また、値の提案は、セグメントフィルターの一貫性と有効性を確保することで、エラーを削減し、データ品質を向上させることができます。参考資料：セグメンテーションにおける値の提案の使用、関連属性の選択に関する考慮事項
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供された公式ドキュメント候補の中に、正答である「値の提案」という機能について直接的または間接的に説明している記述が見つかりませんでした。問題は、セグメンテーションや計算済みインサイトなどでテキスト属性の値を入力する際に、既存の値のリストから選択できるUI機能に関するものと推測されます。しかし、提供されたドキュメント群ではこの具体的な機能を裏付ける情報が不足しているため、問題と正答の正当性を検証することはできません。
- question_id: 41
  question_text: '小売顧客はさまざまなソースから顧客データを取得したいと考えています

    そして、アイデンティティ解決を利用して、

    セグメンテーションに使用されます。

    アクティベーション メンバーシップではどのエンティティにセグメント化する必要がありますか?'
  choices:
    A: 加入者
    B: 統合された個体
    C: 統合連絡先
    D: 個人
  correct_answer: B
  japanese_explanation: '正解はB（統合個人）です。統合個人とは、異なるデータソースにまたがる顧客を表すレコードで、ID解決ルールセットを適用することで作成されます。ID解決ルールセットとは、共通属性に基づいて異なるソースのデータをリンクおよびマージする方法を定義する、一致および調整ルールのセットです。Data
    Cloudは、ID解決ルールセットを使用して複数のデータソースにまたがるデータを解決し、データの取得元に関係なく、顧客ごとに1つのレコードを作成できるようにします1。異なるソースから顧客データを取得し、ID解決をセグメンテーションに使用したい小売顧客は、解決済みおよび統合済みの顧客データを含む統合個人エンティティでセグメント化する必要があります。その他の選択肢は、異なるソースにまたがる解決済みの顧客データを表していないため、不正解です。購読者とは、マーケティングコミュニケーションの受信をオプトインした顧客を表すレコードです。統合連絡先とは、特定の事業部門と関係のある顧客を表すレコードです。個人とは、単一のデータソースからの顧客のプロファイルデータを表すレコードです。参考資料：

    * アイデンティティ解決ルールセットの処理結果

    * セグメンテーションにおけるデータの影響を考慮する

    * Salesforce データクラウドコンサルタント資格取得の準備

    * AIベースのID解決：多様な顧客データをリンク'
  ai_analysis:
    related_docs:
    - title: ID 解決でのスケジュール済み一致とリアルタイム一致
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_match_type_compare.htm&language=ja&type=5
      reason: ID解決のスケジュール済み照合の結果、更新されたプロファイル情報が「統合個人データモデルオブジェクト」に保存されると明記しており、これがセグメンテーションの対象となるエンティティであることを直接的に示しています。
      supporting_text: スケジュール済み照合では、選択した照合方法を使用して、新規および更新されたソースデータが 1 日に数回確認されます。更新された統合プロファイル情報は、統合取引先または統合個人データモデルオブジェクトに保存されます。
    - title: ID 解決ルールセット
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_ruleset.htm&language=ja&type=5
      reason: ID解決のルールセットによって「統合プロファイル」が作成され、その情報がデータモデルオブジェクトに保存されることを説明しています。また、「統合個人プロファイル」という用語が使われており、これが正答「統合された個体」と同義であることを示唆しています。
      supporting_text: 'ルールセットには、複数のデータソースを統合プロファイルにリンクする方法を Customer Data Platform
        に指示する一致ルールと調整ルールが含まれます。統合プロファイル情報は、ルールセットによって作成されたデータモデルオブジェクトに保存されます。

        ...ソースデータでいずれかのソースプロファイルが既知として指定されている場合、統合個人プロファイルは既知とみなされます。'
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: Data Cloudの全体的なプロセスとして、「データを統合」した後に「データをセグメント化および有効化」する流れを説明しており、問題のシナリオ（ID解決後のセグメンテーション）がData
        Cloudの標準的な利用方法であることを裏付けています。
      supporting_text: 'ID 解決ルールセットを使用してデータを統合します。

        インサイトを使用してデータの照会および分析を行います。

        AI を使用して行動を予測します。

        データをセグメント化および有効化し、さまざまなチャネルで使用して、パーソナライズした環境を作成します。'
    ai_verification:
      status: 一致
      justification: 問題は、Data CloudでID解決を行った後にセグメンテーションを行う対象のエンティティを尋ねています。公式ドキュメント「ID
        解決でのスケジュール済み一致とリアルタイム一致」では、ID解決の結果として更新されたプロファイル情報が「統合個人データモデルオブジェクト」に保存されると明確に記述されています。また、「ID
        解決ルールセット」ドキュメントでも「統合個人プロファイル」が作成されると言及されています。これらは正答である「B. 統合された個体 (Unified
        Individual)」を指すものです。したがって、様々なソースから取得した顧客データをID解決で統合し、その結果生成された「統合された個体」を基にセグメンテーションを行うというプロセスは、ドキュメントの内容と完全に一致します。
- question_id: 42
  question_text: 'Cumulus Financial のリーダーシップ チームは、過去 5 年間に 25 万ドル以上を預金し、アドバイザリー サービスを利用していない顧客を、来年のすべての新規キャンペーンの中心に据えることを決定しました。

    このユースケースをサポートする機能はどれですか?'
  choices:
    A: 計算された洞察とデータアクション
    B: 計算された洞察とセグメント
    C: ストリーミングの洞察とセグメント
    D: ストリーミングの洞察とデータアクション
  correct_answer: B
  japanese_explanation: 'ユースケースを理解する:

    * 経営陣は、過去 5 年間に 25 万ドル以上を預け入れており、アドバイザリ サービスを利用していない顧客に重点を置きたいと考えています。'
  ai_analysis:
    related_docs:
    - title: Data Cloud からのデータを使用した Marketing Cloud Engagement でのデータ基盤の実装
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_guide.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudの主要な機能として「セグメント化」を明確に定義しており、それがキャンペーンの対象者を作成するために使用されることを示唆しています。問題のシナリオは、特定の条件を満たす顧客グループ（セグメント）を作成し、キャンペーンの中心に据えることであるため、このドキュメントは解答の「セグメント」部分を裏付けています。
      supporting_text: Data Cloud は、データの取り込み、解決、変換、セグメント化、強化を行うように設計されています。Marketing
        Cloud Engagement は、パーソナライズされたメッセージングキャンペーンを調整するエンゲージメント製品です。
    ai_verification:
      status: 一致
      justification: '問題の要件は、①「過去5年間に25万ドル以上を預金した」という複数のレコードにまたがる集計計算と、②その結果をもとに「アドバイザリーサービスを利用していない」顧客を抽出し、③キャンペーン対象のグループを作成することです。

        ①の集計計算には、バッチで実行される「計算された洞察 (Calculated Insights)」が最適です。リアルタイム処理を目的とする「ストリーミングの洞察」は適していません。

        ②と③の、計算結果と他の属性を組み合わせてキャンペーン対象のリストを作成するプロセスは、「セグメント」機能の典型的な使用例です。リアルタイムのアクションをトリガーする「データアクション」は、この要件には合致しません。

        したがって、「計算された洞察」で指標を作成し、それを用いて「セグメント」を作成するという組み合わせが、このユースケースをサポートする最も適切な機能であるため、正答は論理的に正しいです。'
- question_id: 43
  question_text: Data Cloud はどのようにして顧客データの高可用性とフォールト トレランスを確保するのでしょうか?
  choices:
    A: 複数の地域やデータセンターにデータを分散することで
    B: 堅牢なバックアップを備えたデータセンターを使用することで
    C: 自動データ回復手順を実装することにより
    D: データアクセスを必須の担当者に制限することで
  correct_answer: A
  japanese_explanation: '* 高可用性とフォールトトレランスの確保:

    高可用性とは、継続的に動作し、アクセス可能なシステムを指します。一方、フォールト トレランスは、障害が発生した場合でも機能を継続する能力を指します。

    参照：

    * 複数の地域とデータセンターにわたるデータ分散:

    Salesforce Data Cloud は、複数の地理的地域とデータセンターにデータを複製することで高可用性を確保します。この分散により、局所的な障害に伴うリスクが軽減されます。

    1 つのデータ センターがダウンした場合でも、データとサービスは別の場所から引き続き提供されるため、中断のないサービスが保証されます。

    * 地域データ配信のメリット:

    冗長性: 複数のリージョンにデータのコピーを複数保存すると冗長性が確保され、災害復旧に重要になります。

    負荷分散: トラフィックをデータセンター全体に分散して、パフォーマンスを最適化し、待ち時間を削減できます。

    規制コンプライアンス: データをさまざまな地域に保存すると、ローカルのデータ保存要件を満たすのに役立ちます。

    * Salesforce Data Cloud への実装:

    Salesforce は、データの整合性と可用性を維持するために、データ複製とフェイルオーバー メカニズムを含む堅牢なアーキテクチャを活用します。

    このアーキテクチャにより、地域的な障害が発生した場合でも、顧客データは安全に保護され、アクセス可能になります。'
  ai_analysis:
    related_docs:
    - title: Data Cloud アーキテクチャ戦略
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud_architecture_strategy.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudが複数の「地域」や「領域」にまたがってデータをホストし、取り込むことができるアーキテクチャを採用していることを説明しています。これは、正答である「複数の地域やデータセンターにデータを分散することで」高可用性とフォールトトレランスを確保するという概念を裏付けています。
      supporting_text: Data Cloud 組織は、他の Salesforce クラウドや外部ソースシステムとは異なる領域でホストできます。Data
        Cloud では複数の地域からデータを取り込むことができますが、取り込む前に弁護士と相談し、データレジデンシーに関する組織のポリシーを確認してください。また、地域ごとに
        1 つの Data Cloud を作成し、Data Cloud を使用してその地域の複数の組織のデータを統合および強化することもできます。
    ai_verification:
      status: 一致
      justification: 提供されたドキュメントには、高可用性やフォールトトレランスという用語の直接的な記述はありません。しかし、「Data Cloud
        アーキテクチャ戦略」のドキュメントに「Data Cloud 組織は、他の Salesforce クラウドや外部ソースシステムとは異なる領域でホストできます」「Data
        Cloud では複数の地域からデータを取り込むことができます」と記載されています。これは、Data Cloudが地理的に分散したアーキテクチャを持つことを示唆しており、システムを複数の地域やデータセンターに分散させることは、高可用性とフォールトトレランスを実現するための一般的な手法です。したがって、この記述は正答である「複数の地域やデータセンターにデータを分散することで」という選択肢を強く支持しています。
- question_id: 44
  question_text: 'Northern Trail Outfittersは毎日、過去24時間の店舗取引の概要をAmazon S3バケット内の新しいファイルにアップロードしています。7日以上経過したファイルは自動的に削除されます。各ファイルには、標準化された命名規則に従ってタイムスタンプが付けられています。

    このデータ ストリームを取り込むときにコンサルタントが設定する必要がある 2 つのオプションはどれですか。

    2つの回答を選択してください'
  choices:
    A: 古いファイルの削除が有効になっていることを確認します。
    B: 更新モードが「Upsert」に設定されていることを確認します。
    C: タイムスタンプを収容するためにファイル名にワイルドカードが含まれていることを確認します。
    D: 更新モードが「完全更新」に設定されていることを確認します。
  correct_answer: B,C
  japanese_explanation: 'Amazon S3 バケットからデータを取り込む場合、コンサルタントは次のオプションを設定する必要があります。

    * 更新モードは「Upsert」に設定する必要があります。これは、新規レコードと更新されたレコードがData Cloudに追加または更新され、既存のレコードは保持されることを意味します。これにより、データは常に最新の状態になり、ソースとの整合性が確保されます。

    * ファイル名には、タイムスタンプに対応するワイルドカードを含める必要があります。つまり、ファイル名のパターンには、タイムスタンプの形式に一致する変数部分を含める必要があります。例えば、ファイル名がstore_transactions_2023-12-18.csvの場合、ワイルドカードはstore_transactions_*.csvとなります。これにより、取り込みプロセスは毎日正しいファイルを識別して処理できるようになります。

    その他のオプションは、このシナリオには必要ありません。

    * 古いファイルの削除はAmazon S3バケットの機能であり、Data Cloudの取り込みプロセスではありません。Data Cloudはソースからファイルを削除することはなく、取り込み後にソースファイルを削除する必要もありません。

    * フルリフレッシュは、Data Cloud 内の既存のレコードをすべて削除し、ソースファイルのレコードに置き換えるリフレッシュモードです。このシナリオには適していません。特にソースファイルに過去
    24 時間のトランザクションの概要のみが含まれている場合、データの損失と不整合が発生する可能性があります。参考資料: Amazon S3 からのデータの取り込み、リフレッシュモード'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 問題は、Amazon S3からのデータ取り込みにおけるデータストリームの設定についてです。具体的には、タイムスタンプ付きで毎日生成されるファイルを取り込むためのファイル名指定方法と、データの更新方法が問われています。正解は、ファイル名の動的な部分をワイルドカードで指定し、更新モードを「Upsert」に設定することを示唆しています。しかし、提供された公式ドキュメントには、Amazon
        S3コネクタの存在やNTOの使用例は記載されているものの、データストリーム設定におけるワイルドカードの使用や更新モード（Upsert/完全更新）に関する具体的な説明は見つかりませんでした。したがって、提示されたドキュメントだけでは正答を直接裏付けることができません。
- question_id: 45
  question_text: 'Northern Trail Outfitters（NTD）は、統合された顧客について、顧客満足度、頻度、金額（RFM）スコアに関する計算されたインサイトを作成します。そして、これらのスコアに基づいてセグメントを作成し、Marketing
    Cloudのアクティベーションターゲットにアクティベートします。

    アクティベーションを構成するときに必要な 2 つのアクションはどれですか。

    2つの回答を選択してください'
  choices:
    A: 追加の属性を追加します。
    B: セグメントを選択します。
    C: 接触点を選択します。
    D: 計算されたインサイトをアクティベーションに追加します。
  correct_answer: B,C
  japanese_explanation: 'Marketing Cloud のアクティベーションターゲットへのアクティベーションを設定するには、セグメントとコンタクトポイントを選択する必要があります。セグメントを選択すると、アクティベーションする統合された個人を指定できます。

    コンタクトポイントを選択すると、セグメントの属性をMarketing Cloudデータエクステンションのフィールドにマッピングできます。これらの属性や計算済みインサイトは既にセグメント定義に含まれているため、アクティベーションで追加属性や計算済みインサイトを追加する必要はありません。参考資料：Marketing
    Cloudアクティベーションターゲットの作成、データクラウドのデータターゲットの種類'
  ai_analysis:
    related_docs:
    - title: Data Cloud からのデータを使用した Marketing Cloud Engagement でのデータ基盤の実装
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_guide.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudで作成したセグメントをMarketing Cloud Engagementに有効化（アクティベート）するプロセスを包括的に説明しています。問題は、まさにこのアクティベーション設定時に必要なアクションを問うており、ドキュメントの目次にある「Data
        Cloud でのコア有効化の作成」という項目が、問題のシナリオと完全に一致するため、最も直接的な根拠となります。
      supporting_text: 'Data Cloud は、データの取り込み、解決、変換、セグメント化、強化を行うように設計されています。Marketing
        Cloud Engagement は、パーソナライズされたメッセージングキャンペーンを調整するエンゲージメント製品です。

        Data Cloud でコア有効化を作成する手順を確認しましょう。'
    - title: その他の標準データモデルオブジェクト
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_software_application_data_model.htm&language=ja&type=5
      reason: このドキュメントは「マーケットセグメント」が「マーケティング目的でまとめられた...グループ」であると定義しています。問題はセグメントをアクティベーションの対象とすることであり、この定義は「セグメント」がアクティベーションの構成要素であることを裏付けています。
      supporting_text: "マーケットセグメント\tマーケティング目的でまとめられた 1 つ以上の共通特性を共有する人のグループの Data Cloud\
        \ DMO。"
    ai_verification:
      status: 一致
      justification: Data Cloudでアクティベーションを設定する際、基本的なプロセスとして、(1)どの「セグメント」を対象とするかを選択し、(2)そのデータをどこに送信するか、つまり「接触点」（Activation
        Target）を選択する必要があります。この2つはアクティベーション構成の必須要素です。したがって、正答である「B. セグメントを選択します。」と「C.
        接触点を選択します。」は、実際の操作フローと一致しており、論理的に正しいです。選択肢A（追加の属性）は必須ではなく、選択肢D（計算されたインサイト）はセグメント作成の段階で使用されるものであり、アクティベーション設定の段階で追加するものではありません。
- question_id: 46
  question_text: 'Cloud Kicks は、過去 7 日以内に自社の Web サイトにアクセスした顧客のセグメントを構築したいと考えています。

    このユースケースに適したエンゲージメント日フィールドのフィルター演算子はどれですか?'
  choices:
    A: 間にある
    B: 最後の数より大きい
    C: 次の日数
    D: 最後の日数
  correct_answer: D
  japanese_explanation: 'フィルター演算子「過去日数」を使用すると、今日から何日前の日付範囲で、日付フィールドをフィルタリングできます。例えば、この演算子を使用して、過去7日間、過去30日間、または任意の日数以内にウェブサイトにアクセスした顧客をフィルタリングできます。この演算子は、現在の日付に基づいて自動的に更新される動的セグメントを作成するのに役立ちます12。参考：

    相対日付フィルターリファレンス

    フィルタリングされたセグメントを作成する'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供された公式ドキュメント候補は、データアクション、データストリーム、コネクタに関するリリースノートであり、Data Cloudのセグメンテーション機能で使用される日付フィルター演算子について具体的に説明している箇所は見つかりませんでした。問題の要件である「過去
        7 日以内」のセグメント作成には、「最後の日数」という相対的な日付演算子が論理的に最も適していますが、提供された資料からはその機能の存在や仕様を裏付けることができないため、正誤を判断できません。
- question_id: 47
  question_text: 毎日評価される誕生日キャンペーンのセグメントを作成するには、コンサルタントはどの演算子を使用する必要がありますか?
  choices:
    A: 今日は
    B: 誕生日です
    C: 〜の間
    D: 記念日です
  correct_answer: D
  japanese_explanation: '毎日評価される誕生日キャンペーンのセグメントを作成するには、「記念日」演算子を使用する必要があります。この演算子は、日付フィールドと現在の日付を比較し、年に関係なく月と日が同じ場合にtrueを返します。例えば、日付フィールドが1990-01-01で、現在の日付が2023-01-01の場合、演算子はtrueを返します。これにより、コンサルタントは、現在の日付と同じ日に誕生日を迎えるすべての顧客を含むセグメントを作成でき、セグメントは毎日新しい誕生日で更新されます。他の演算子は、以下の理由により、この目的には最適ではありません。

    A) 「今日」演算子は、日付フィールドと現在の日付を比較し、年を含め日付が一致する場合にtrueを返します。例えば、日付フィールドが1990-01-01で、現在の日付が2023-01-01の場合、この演算子はfalseを返します。この演算子は、現在の日付と同じ年日に生まれた顧客のみを対象としますが、そのような可能性は非常に低いため、誕生日キャンペーンには適していません。

    B）「誕生日」演算子はData Cloudでは有効な演算子ではありません。セグメントキャンバスや計算インサイトエディターでは、この演算子は使用できません。

    C) Is Between演算子は、日付フィールドと日付範囲を比較し、日付が範囲内（両端を含む）にある場合にtrueを返します。例えば、日付フィールドが1990-01-01で、範囲が2022-12-25から2022-12-25の場合、

    2023-01-05 の場合、演算子は true を返します。この演算子は、誕生日が特定の日付範囲内にある顧客のみを対象とし、セグメントは毎日新しい誕生日で更新されないため、誕生日キャンペーンには適していません。'
  ai_analysis:
    related_docs:
    - title: Data Cloud のセグメンテーション演算子
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_datatype_expression_operators.htm&language=ja&type=5
      reason: 問題で問われている「誕生日キャンペーン」に適したセグメンテーション演算子が明記されているため。このドキュメントには、Date型の演算子として「次のアニバーサリーの日付」があり、その機能が「日と月が今日の日付と月に一致する」レコードを検索するもので、まさに誕生日の判定ロジックと合致する。
      supporting_text: "日付演算子\t返されるデータ\n次のアニバーサリーの日付\t日と月が今日の日付と月に一致する属性の利用者メンバーを検索します。"
    - title: Release Notes - Data Cloud (Pages 270-294) - Part 91
      url: Salesforce Winter '25 リリースノート.pdf
      reason: このドキュメントは、「次のアニバーサリーの日付」演算子が実際に存在し、機能強化の対象となっていることを裏付けており、この演算子の重要性を示しているため。
      supporting_text: 'セグメントスケジュール時刻を使用した正確な絞り込み

        セグメントの絞り込みの精度を高めるため、実行時刻ではなくセグメントスケジュール時刻が使用されま す。この機能強化は、外部テーブル (BYOL) の
        Date または DateTime 列で[次のアニバーサリーの日付 ]および [次のアニバーサリーの日付ではない ]の演算子を使用する区分条件に適用されます。'
    ai_verification:
      status: 一致
      justification: 問題は、毎日評価される誕生日キャンペーン用のセグメントを作成するための演算子を特定することを求めている。これは、年に関係なく、月と日が今日と一致するレコードを抽出する機能が必要であることを意味する。公式ドキュメント「Data
        Cloud のセグメンテーション演算子」には、Date型の演算子として「次のアニバーサリーの日付」が記載されており、その説明は「日と月が今日の日付と月に一致する属性の利用者メンバーを検索します」とある。これは問題の要件に完全に合致する。選択肢「D.
        記念日です」は、「Anniversary」の日本語訳であり、この演算子を指していると判断できるため、正答はドキュメントの内容と一致する。
- question_id: 48
  question_text: どのソリューションが、Marketing Cloud の加入者プロファイル属性を毎日 Data Cloud に取り込む簡単な方法を提供しますか?
  choices:
    A: Automation Studio およびプロファイル ファイル API
    B: マーケティングクラウド接続 API
    C: Marketing Cloud データ拡張機能のデータストリーム
    D: Email Studio スターター データ バンドル
  correct_answer: C
  japanese_explanation: 'Marketing Cloud の購読者プロファイル属性を Data Cloud に毎日簡単に取り込むことができるソリューションが、Marketing
    Cloud データ拡張機能のデータストリームです。Marketing Cloud データ拡張機能のデータストリームは、Marketing Cloud データ拡張機能から
    Data Cloud データスペースにデータをストリーミングできる機能です。ストリーミングするデータ拡張機能を選択すると、Data Cloud によってデータスペース内の対応するデータモデルオブジェクト
    (DMO) が自動的に作成され、更新されます。また、ユーザーインターフェースまたは API を使用して、データ拡張機能フィールドを DMO 属性にマッピングすることもできます。Marketing
    Cloud データ拡張機能のデータストリームを使用すると、コードを記述したり複雑な統合を設定したりすることなく、Marketing Cloud から Data
    Cloud に購読者プロファイル属性などのデータを取り込むことができます。

    その他のオプションは、Marketing Cloud の購読者プロファイル属性を Data Cloud に日常的に簡単に取り込むことができるソリューションではありません。Automation
    Studio と Profile file API は、Marketing Cloud から外部システムにデータをエクスポートするために使用できるツールですが、スクリプトの作成、ファイル転送の設定、自動化のスケジュール設定など、お客様自身で行う必要があります。Marketing
    Cloud Connect API は、Sales Cloud や Service Cloud などの他の Salesforce ソリューションで Marketing
    Cloud のデータにアクセスするために使用できる API ですが、Data Cloud へのデータのストリーミングはサポートしていません。Email Studio
    Starter Data Bundle は、Email Studio 用のサンプルデータとセグメントを含むデータキットですが、購読者プロファイル属性は含まれておらず、Data
    Cloud へのデータのストリーミングもサポートされていません。

    参考文献:

    マーケティングクラウドデータ拡張データストリーム

    データクラウドデータ取り込み

    [Marketing Cloud データ拡張データストリーム API]

    [マーケティングクラウドコネクトAPI]

    [Email Studio スターター データ バンドル]'
  ai_analysis:
    related_docs:
    - title: Data Cloud の Marketing Cloud Engagement Starter データバンドル
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_starter_data_bundles.htm&language=ja&type=5
      reason: このドキュメントは、Email Studioのスターターデータバンドルに「エンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリーム」が含まれることを明記しており、問題の「加入者プロファイル属性」の取り込みに直接関連するため。
      supporting_text: Email Studio データセットには、送信、開封、クリック、バウンス、苦情、登録解除、Einstein エンゲージメントスコアなどのメールエンゲージメントイベントがあります。これらの総計値はキャンペーン、ジャーニー、メールテンプレートメタデータから取得されます。これらのシステム定義のテーブルに加えて、メールコネクタによってエンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリームが取得されます。このデータは、メールを操作している登録者基盤について人口統計上のコンテキストを提供します。
    - title: Marketing Cloud Engagement Starter バンドルからのデータストリームの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_marketing_cloud_data_stream.htm&language=ja&type=5
      reason: このドキュメントは、Marketing CloudからData Cloudへデータを取り込む「簡単な方法」として、スターターバンドルからデータストリームを作成する具体的な手順を説明しているため。
      supporting_text: Marketing Cloud Engagement ソースから Data Cloud へのデータフローを開始するには、スターターバンドルからデータストリームを作成します。Data
        Cloud では、SFMC エンタープライズプロファイル属性データストリームの数式項目のみがサポートされています。
    - title: Data Cloud での Marketing Cloud Engagement 接続の設定
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_set_up_marketing_cloud_connection.htm&language=ja&type=5
      reason: このドキュメントは、データバンドルがデータストリームを簡単に作成する方法であること、そして手動でデータエクステンションを追加できることにも言及しており、データエクステンションをソースとするデータストリームが基本のソリューションであることを示唆しているため。
      supporting_text: データバンドルソースが表示されます。データバンドルを使用して、複数のデータストリームをすばやく簡単に作成して Engagement
        からシステム所有のデータを取得します。後でデータエクステンションを手動で追加することもできます。
    ai_verification:
      status: 一致
      justification: 問題は、Marketing Cloudの加入者プロファイル属性をData Cloudに取り込む簡単な方法を問うています。公式ドキュメント「Data
        Cloud の Marketing Cloud Engagement Starter データバンドル」には、「メールコネクタによってエンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリームが取得されます」と明記されています。Marketing
        Cloudのプロファイル属性はデータエクステンションとして扱われ、それをソースとするデータストリームを作成することでData Cloudに取り込まれます。スターターバンドルは、関連するデータエクステンションからのデータストリーム作成を簡略化するパッケージです。したがって、根本的なソリューションは「Marketing
        Cloud データ拡張機能のデータストリーム」であり、正答Cとドキュメントの内容は一致します。
- question_id: 49
  question_text: セグメンテーションまたはアクティベーションを実行する場合、データの公開と更新にはどのタイムゾーンが使用されますか?
  choices:
    A: アクティビティ作成時に指定されたタイムゾーン
    B: アクティビティを作成したユーザーのタイムゾーン
    C: データクラウド管理者ユーザーのタイムゾーン
    D: Salesforce Data Cloud 組織によって設定されたタイムゾーン
  correct_answer: D
  japanese_explanation: セグメンテーションまたはアクティベーションを実行する際にデータの公開と更新に使用されるタイムゾーンはDです。Salesforce
    Data Cloud組織によって設定されたタイムゾーンです。このタイムゾーンは、Data Cloudのプロビジョニング時に組織設定で設定され、Data Cloud内のすべてのユーザーとアクティビティに適用されます。このタイムゾーンによって、セグメントの更新スケジュールとアクティベーションの公開スケジュールが決まります。したがって、セグメンテーションとアクティベーションの戦略を計画する際には、Data
    Cloud組織と対象システムまたはチャネル間のタイムゾーン差を考慮することが重要です。参考資料：Salesforce Data Cloudコンサルタント試験ガイド、セグメンテーション、アクティベーション
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供された公式ドキュメントのいずれにも、セグメンテーションやアクティベーションの公開・更新に使用されるタイムゾーンについて直接言及している箇所は見つかりませんでした。正答である「Salesforce
        Data Cloud 組織によって設定されたタイムゾーン」は、Salesforceプラットフォームの一般的な動作（スケジュールされたジョブは組織のタイムゾーンで実行される）と一致するため論理的に正しいと考えられますが、提示されたドキュメント内にはその裏付けとなる明確な記述が存在しません。
- question_id: 50
  question_text: '顧客はCRMからData Cloudに取り込むためのマスター顧客テーブルを持っています。このテーブルには、氏名、メインのメールアドレス、その他の個人識別情報（PLL）が含まれています。

    ID 解決をサポートするには、フィールドをどのようにマッピングする必要がありますか?'
  choices:
    A: 入力テーブルに直接一致するフィールドを持つ新しいカスタム オブジェクトを作成します。
    B: すべてのフィールドを Customer オブジェクトにマップします。
    C: 名前を個人オブジェクトにマップし、電子メール アドレスを連絡先電話番号電子メール オブジェクトにマップします。
    D: すべてのフィールドを個人オブジェクトにマップし、電子メール アドレスのカスタム フィールドを追加します。
  correct_answer: C
  japanese_explanation: 'Data Cloud で ID 解決をサポートするには、マスター顧客テーブルのフィールドを、この目的のために設計された標準データモデルオブジェクトにマッピングする必要があります。個人オブジェクトは、顧客の名前やその他の個人識別情報
    (PII) を保存するために使用され、連絡先電話番号メールオブジェクトは、顧客の主要なメールアドレスやその他の連絡先情報を保存するために使用されます。これらのオブジェクトは、連絡先情報が個人に属していることを示すリレーションフィールドによってリンクされています。これらのオブジェクトにフィールドをマッピングすることで、Data
    Cloud は ID 解決ルールを使用して、名前とメールアドレスのフィールドに基づいて、さまざまなソースのプロファイルを照合および調整できます。その他のオプションは、標準データモデルに含まれない新しいカスタムオブジェクトを作成するか、すべてのフィールドを
    ID 解決用ではない顧客オブジェクトにマッピングするか、すべてのフィールドを標準のメールアドレスフィールドを持たない個人オブジェクトにマッピングするため、推奨されません。参考資料:
    ID 解決のためのデータモデリング要件、統合された個人プロファイルの作成'
  ai_analysis:
    related_docs:
    - title: ID 解決一致ルール
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_match_rules.htm&language=ja&type=5
      reason: 問題はID解決のためのデータマッピングについて問うています。このドキュメントは、個人のID解決（照合）を行う際に使用するオブジェクトを具体的に列挙しており、「個人」オブジェクトと「連絡先メール」オブジェクトが含まれています。これは、氏名を個人オブジェクトに、メールアドレスを連絡先メールオブジェクトにマッピングするという正答の直接的な根拠となります。
      supporting_text: 個人を照合する場合 — 個人、連絡先住所、連絡先アプリケーション、連絡先メール、連絡先電話、連絡先ソーシャル、関係者
        ID
    - title: ID 解決のデータモデリング要件
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_data_modeling_requirements.htm&language=ja&type=5
      reason: このドキュメントは、ID解決が正しく機能するためのデータマッピングの要件を説明しています。問題の核心である「ID解決をサポートするためのフィールドマッピング」に直接関連し、個人データを「個人オブジェクト」に正しくマッピングする必要があることを示しています。
      supporting_text: ID 解決でデータを処理して統合プロファイルにまとめるには、データが正しくマッピングされている必要があります。データモデリング要件を確認し、個人、取引先、連絡先データの統合準備が整っていることを確認します。
        ... 個人オブジェクトのデータモデリングの要件 データモデリング時に次の項目をマッピングして、ID 解決プロセス用に個人に関するデータを準備します。
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: このドキュメントでは、個人情報と連絡先情報が別々に扱われ、「統合連絡先オブジェクト」によって連絡先が集約されることが説明されています。これは、氏名のような個人属性と、メールアドレスのような連絡先情報を、それぞれ「個人」オブジェクトと「連絡先ポイント」系のオブジェクトに分けてマッピングするという、Data
        Cloudの基本的なデータモデリングの考え方を裏付けています。
      supporting_text: 個人または取引先には、統合個人または統合取引先ごとに保持する必要がある複数の有効な連絡先がある可能性があります。たとえば、個人に自宅電話番号と携帯電話番号の両方がある場合があります。Data
        Cloud では、各ルールセットのマッピングやルールに基づいてさまざまなデータソースの連絡先を集計する統合連絡先オブジェクトが作成されます。
    ai_verification:
      status: 一致
      justification: 問題は、Data CloudのID解決のために顧客情報をどのようにマッピングすべきかを問うています。正答「C. 名前を個人オブジェクトにマップし、電子メール
        アドレスを連絡先電話番号電子メール オブジェクトにマップします。」は、Data Cloudの標準的なデータモデリングプラクティスを反映しています。公式ドキュメント「ID
        解決一致ルール」では、個人の照合に使用するオブジェクトとして「個人」および「連絡先メール」が明記されています。また、「ID 解決のデータモデリング要件」や「ソースプロファイルの統合」も、個人属性と連絡先情報をそれぞれの適切な標準オブジェクトにマッピングすることの重要性を示しており、正答の選択を強力に裏付けています。
- question_id: 51
  question_text: 'Cloud Kicksのマーケティングマネージャーは、自社の取引先の企業電話番号をData Cloudに取り込む予定です。電話番号を保存するには、データを「電話」に設定したカスタムフィールドを使用する予定です。

    電話番号を取り込む際に正しい記述はどれですか?'
  choices:
    A: 電話データ型フィールドへの取り込みにテキスト値を受け入れることができます。
    B: Data Cloud は、取り込み時に電話番号の形式を検証します。
    C: 電話番号フィールドは 10 桁の値のみを受け入れます。
    D: 電話番号フィールドを主キーとして使用する必要があります。
  correct_answer: A
  japanese_explanation: 'Salesforce Data Cloud の Phone データ型のカスタムフィールドに電話番号を取り込む場合、正しくはテキスト値も
    phone データ型のフィールドに取り込める、ということになります。その理由は次のとおりです。

    要件を理解する

    Cloud Kicks のマーケティング マネージャーは、電話データ型のカスタム フィールドを使用して、企業の電話番号を Data Cloud に取り込む予定です。

    電話番号が取り込み時にどのように検証され、保存されるかを理解することが重要です。

    テキスト値が受け入れられる理由

    電話データ型の動作:

    Salesforceの電話データ型は、電話番号が通常文字列として保存されるため、テキスト値を受け入れます（例：

    「+1-800-555-1234」）。

    このフィールドは電話番号用に設計されていますが、取り込み時に厳密な書式設定ルールは適用されません。

    取り込み中の検証:

    Salesforce は、取り込み時に電話番号の形式を検証しません。

    検証は、データがフォーマット規則を適用する下流のシステムまたはアプリケーションで使用される場合にのみ行われます。

    その他のオプションが間違っています:

    B). Data Cloud は取り込み時に電話番号の形式を検証します。これは誤りです。Data Cloud は取り込み時に電話番号の形式を検証しません。

    C) 電話番号フィールドは 10 桁の値のみを受け入れることができます。電話データ型は国際電話番号を含むさまざまな形式をサポートしているため、これは誤りです。

    D) 電話番号フィールドは主キーとして使用する必要があります。電話番号は一意の識別子ではないため、主キーとして使用すべきではないため、これは誤りです。

    電話番号を取得する手順

    ステップ1: カスタムフィールドを作成する

    「オブジェクト マネージャー」>「アカウント」>「フィールドとリレーションシップ」に移動し、電話データ型のカスタム フィールドを作成します。

    ステップ2: データ取り込みを構成する

    ソース データに電話番号がテキスト値として含まれていることを確認します。

    ソースの電話番号フィールドを Data Cloud のカスタム フィールドにマップします。

    ステップ3: データ使用量の検証

    取り込んだデータをテストして、ダウンストリームの要件 (ダイヤル用のフォーマットなど) を満たしていることを確認します。

    結論

    電話番号は文字列として保存され、プロセスの後半で書式の検証が行われるため、テキスト値は電話データ型フィールドに取り込むことができます。'
  ai_analysis:
    related_docs:
    - title: Data Cloud のデータ型
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_types.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudの「電話」データ型について直接説明しています。正答の根拠となる「電話データ型項目への取り込みには、有効なテキスト値を使用できます」という記述と、誤答の根拠となる「Data
        Cloud では、電話番号の形式は検証されません」という記述が明確に含まれているため、最も関連性が高いです。
      supporting_text: '電話番号を保存します。Data Cloud では、電話番号の形式は検証されません。Phone データ型は、テキストデータ型に基づいてモデル化されます。電話データ型項目への取り込みには、有効なテキスト値を使用できます。


        ソース項目を電話番号として処理する場合は、ソース項目の電話データ型を明示的に選択できます。電話番号項目はプライマリキーとして使用できますが、エンゲージメント日付項目としては使用できません。


        テキスト値を使用する数式関数は、電話データ型の入力を受け入れます。これらの数式関数からのテキスト出力を電話データ型に変換できます。詳細は、「サポートされるライブラリ関数」を参照してください。'
    ai_verification:
      status: 一致
      justification: 公式ドキュメント「Data Cloud のデータ型」には、「電話データ型項目への取り込みには、有効なテキスト値を使用できます。」と明記されています。これは、問題の正答「電話データ型フィールドへの取り込みにテキスト値を受け入れることができます。」と完全に一致します。また、同ドキュメントには「Data
        Cloud では、電話番号の形式は検証されません。」と記載されており、選択肢Bが誤りであることも確認できます。さらに、「電話番号項目はプライマリキーとして使用できますが、...」という記述から、選択肢Dの「主キーとして使用する必要があります」という断定が誤りであることもわかります。
- question_id: 52
  question_text: 'Northern Trail Outfitters (NTO) は、B2C コマース データを Data Cloud に接続し、2
    年間の取引履歴を Data Cloud に取り込むことを望んでいます。

    これを達成するために NTO は何を使うべきでしょうか?'
  choices:
    A: B2Cコマーススターターバンドル
    B: 直接販売注文エンティティの取り込み
    C: 直接販売製品エンティティの取り込み
    D: B2C コマース スターター バンドルとカスタム抽出
  correct_answer: D
  japanese_explanation: 'B2C Commerceスターターバンドルは、B2C Commerceから注文データと商品データをData Cloudに取り込むための事前定義されたデータストリームです。ただし、スターターバンドルはデフォルトで過去90日間のデータのみを取得します。2年間の取引履歴を取り込むには、NTOはB2C
    Commerceから履歴データを含むカスタム抽出を使用し、そのカスタム抽出をソースとして使用するようにデータストリームを設定する必要があります。他の方法では、以下の理由により、この目的を達成できません。

    * A. B2C Commerce スターター バンドルは、デフォルトでは過去 90 日間のデータのみを取り込みま す。

    * B. 直接販売注文エンティティの取り込みは、B2C Commerceデータの接続方法としてはサポートされていません。

    * Data Cloud を使用。Data Cloud では、B2C Commerce データへの直接アクセス接続は提供されず、データの取り込みのみ提供されます。

    * C. 直接販売商品エンティティの取り込みは、B2C CommerceデータをData Cloudに接続するためのサポートされていない方法です。Data
    CloudはB2C Commerceデータへの直接アクセス接続を提供しておらず、データの取り込みのみを提供しています。参考資料：B2C Commerceデータバンドルの作成
    - Salesforce、B2C Commerceコネクタ - Salesforce、Salesforce B2C Commerceの料金プランと費用'
  ai_analysis:
    related_docs:
    - title: B2C Commerce コネクタ
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_commerce_cloud_connector.htm&language=ja&type=5
      reason: このドキュメントには、B2C Commerceコネクタが標準で取り込む履歴データの期間が「30日間」であると明記されています。問題の要件である「2年間」の履歴を取り込むためには、標準のコネクタだけでは不十分であり、追加の手段が必要であることを示す直接的な根拠となります。
      supporting_text: B2C Commerce と Data Cloud 間の接続を確立すると、B2C Commerce コネクタは 30
        日間の履歴データを取り込みます。たとえば、5 月 1 日に接続を確立した場合、B2C Commerce コネクタは 4 月 2 日から 5 月 1
        日までの履歴データを取り込みます。 これ以降、B2C Commerce コネクタは引き続きデータを取り込みます。
    - title: B2C Commerce データストリームの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_commerce_cloud_starter_bundle.htm&language=ja&type=5
      reason: このドキュメントは、B2C Commerceからのデータ取り込みに「注文バンドル」を使用することを説明しており、これが正答に含まれる「B2C
        コマース スターター バンドル」に該当します。標準的なデータ取り込み方法としてスターターバンドルを利用することの正当性を示しています。
      supporting_text: Data Cloud 管理者は注文バンドルを使用して、B2C Commerce インスタンスからデータを取り込むデータストリームを作成できます。データバンドルでは、データストリームの作成とマッピングが行われます。注文バンドルは一種のデータバンドルです。
    ai_verification:
      status: 一致
      justification: 問題は、B2Cコマースから2年間の取引履歴をData Cloudに取り込む方法を尋ねています。公式ドキュメント「B2C Commerce
        コネクタ」によると、標準のコネクタ機能（スターターバンドルの一部）では、過去30日間の履歴データしか自動で取り込めません。したがって、2年間という長期の履歴データを満たすためには、標準の「B2C
        コマース スターター バンドル」を利用しつつ、30日を超える過去のデータについては別途「カスタム抽出」を行う必要があります。この2つの組み合わせが要件を満たす唯一の方法であるため、正答Dは正しいです。
- question_id: 53
  question_text: 'コンサルタントは、複数の断片化されたデータ ソースを持つ顧客と Data Cloud の利点について話し合っています。

    顧客データの管理に関してコンサルタントが強調すべき 2 つの機能領域はどれですか?

    2つの回答を選択してください'
  choices:
    A: データの調和
    B: 統合プロファイル
    C: マスターデータ管理
    D: データマーケットプレイス
  correct_answer: A,B
  japanese_explanation: 'データクラウドは、オープンで拡張可能なデータプラットフォームであり、ファーストパーティデータと業界データへの安全なアクセスを実現しながら、よりスマートで効率的なAIを実現します1。コンサルタントが顧客データ管理に関して強調すべき2つの機能領域は次のとおりです。

    * データのハーモナイゼーション：Data Cloudは、複数のソースと形式から取得したデータを共通のスキーマにハーモナイズすることで、顧客データの信頼できる唯一の情報源を実現します1。また、Data
    Cloudはデータ品質ルールと変換を適用し、データの正確性と一貫性を確保します。

    * 統合プロファイル：データクラウドは、メールアドレス、電話番号、Cookie、デバイスID1など、さまざまな識別子にまたがるデータをリンクすることで、顧客と見込み客の統合プロファイルを作成します。統合プロファイルは、チャネルやタッチポイントをまたがる顧客の行動、嗜好、インタラクションを包括的に把握できます。その他の選択肢は、以下の理由により正しくありません。

    * マスターデータ管理：マスターデータ管理（MDM）は、製品、顧客、サプライヤー、位置情報などのマスターデータを、一貫性と信頼性に優れた単一のソースとして作成・管理するプロセスです。Data
    Cloud は MDM 機能を提供していませんが、MDM ソリューションと統合することで顧客データを拡充できます。

    * データマーケットプレイス：データマーケットプレイスは、Data Cloudの機能の一つで、ユーザーはサードパーティプロバイダーから提供される人口統計データ、行動データ、インテントデータなどのデータを発見、アクセス、活用することができます。データマーケットプレイスは、顧客データの管理に関連する機能領域ではなく、顧客データを強化できる外部データソースです。参考資料：

    * Salesforce データクラウド

    * [データクラウドのためのデータハーモナイゼーション]

    * [データクラウドの統合プロファイル]

    * [マスターデータ管理とは]

    * [データクラウドとマスターデータ管理の統合]

    * [データクラウド向けデータマーケットプレイス]'
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: このドキュメントはData Cloudの基本的な仕組みを説明しており、「データを標準データモデルにハーモナイズします」および「ID 解決ルールセットを使用してデータを統合します」という記述が含まれています。これらはそれぞれ正答の「データの調和」と「統合プロファイル」の作成プロセスに直接対応しており、問題のシナリオ（断片化されたデータソースの管理）におけるData
        Cloudの主要な利点を明確に示しています。
      supporting_text: 'しくみ

        データが非構造化データか構造化データかに関係なく、すべてのデータソースを接続します。

        バッチまたはストリーミングデータを取り込みます。

        ゼロコピーデータ統合を使用してデータを接続します。

        変換機能とデータガバナンス機能を使用してデータを準備します。

        データを標準データモデルにハーモナイズします。

        ID 解決ルールセットを使用してデータを統合します。'
    - title: Data Cloud の機能と学習パス
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_customer360_lm.htm&language=ja&type=5
      reason: このドキュメントはData Cloudで実現できることをリストアップしており、「ID、エンゲージメントデータ、顧客注文、ロイヤルティ、マーケティングジャーニーを接続して、すべてのタッチポイントで統合されたプロファイルを作成する」という記述があります。これは正答の「統合プロファイル」を直接裏付ける強力な根拠となります。
      supporting_text: 'Data Cloud を使用すると、以下を行うことができます。

        ...

        ID、エンゲージメントデータ、顧客注文、ロイヤルティ、マーケティングジャーニーを接続して、すべてのタッチポイントで統合されたプロファイルを作成する。'
    - title: Data Cloud 用語集
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_glossary_guide.htm&language=ja&type=5
      reason: この用語集には「ルールセット」の定義があり、「ソースレコードを組み合わせて ID を解決し、統合プロファイルを作成するために使用される」と説明されています。これは、正答である「統合プロファイル」がData
        Cloudの機能の一部であることを裏付けています。
      supporting_text: 'ルールセット

        ソースレコードを組み合わせて ID を解決し、統合プロファイルを作成するために使用される、ユーザーが選択した一致ルールと調整ルールの組み合わせです。「ID
        解決ルールセット」を参照してください。'
    ai_verification:
      status: 一致
      justification: 問題は、複数の断片化されたデータソースを管理する上でのData Cloudの主要な利点を問うています。正答である「データの調和」と「統合プロファイル」は、Data
        Cloudの核心的な機能です。公式ドキュメント「Salesforce Data Cloud について」では、「データを標準データモデルにハーモナイズします」と「ID
        解決ルールセットを使用してデータを統合します」というプロセスが明記されています。また、「Data Cloud の機能と学習パス」では、「すべてのタッチポイントで統合されたプロファイルを作成する」ことが主要機能として挙げられています。これらの記述は、断片化されたデータを意味のある形に整え（調和）、顧客ごとに一つにまとめる（統合プロファイル）という正答を明確に裏付けています。
- question_id: 54
  question_text: 'お客様には2つのData Cloud組織があります。Data Cloud組織の1つで、Amazon S3データストリームとそのマッピングの新しい設定が完了し、テストが完了しました。

    この構成をパッケージ化して顧客の 2 番目の組織に宣伝するには、どのようなことが推奨されますか?'
  choices:
    A: メタデータ API を使用します。
    B: Salesforce CRM コネクタを使用します。
    C: データキットを作成します。
    D: AppExchange アプリケーションとしてパッケージ化します。
  correct_answer: C
  japanese_explanation: '* Data Cloud 構成のプロモーション: 複数の Salesforce Data Cloud 組織にわたって構成を管理する場合は、プロモーション
    プロセスの一貫性と正確性を確保するツールを使用することが重要です。

    * データキット：Salesforce Data Cloud では、データキットを使用して設定をパッケージ化し、プロモートすることができます。これらのキットは、データストリームの定義、マッピング、その他の構成要素をポータブルな形式でカプセル化します。

    * プロセス：

    ソース組織に、Amazon S3 データストリームの構成とマッピングを含むデータキットを作成します。

    ソース組織からデータキットをエクスポートします。

    データ キットをターゲット組織にインポートし、すべての構成が正確に転送されることを確認します。

    * 利点: データ キットを使用すると、移行プロセスが簡素化され、構成エラーのリスクが軽減され、すべての設定とマッピングが新しい組織で一貫して適用されるようになります。

    * 参照：

    Salesforce データクラウド開発者ガイド

    Salesforce データクラウドパッケージ'
  ai_analysis:
    related_docs:
    - title: Data Cloud のデータストリーム
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_streams.htm&language=ja&type=5
      reason: 問題は、Data Cloudのデータストリームとそのマッピング設定を別の組織に移行する方法を尋ねています。このドキュメントには「データキットからの非構造化データレイクオブジェクトの作成」という項目があり、「Data
        Cloud にデータキットをリリースしたら、非構造化データレイクオブジェクト (UDLO) を作成できます。すべてのフィールドが自動的にマッピングされます。」と記載されています。これは、データキットがデータストリームとマッピングを含む構成をパッケージ化し、他の組織に展開（リリース）するための仕組みであることを示しており、正答「C.
        データキットを作成します。」を直接裏付けています。
      supporting_text: 'データキットからの非構造化データレイクオブジェクトの作成

        Data Cloud にデータキットをリリースしたら、非構造化データレイクオブジェクト (UDLO) を作成できます。すべてのフィールドが自動的にマッピングされます。'
    ai_verification:
      status: 一致
      justification: 問題は、テスト済みのAmazon S3データストリームとそのマッピングを、あるData Cloud組織から別の組織へ移行するための推奨方法を尋ねています。正答の「C.
        データキットを作成します。」は、Data Cloudの構成要素（データストリーム、データモデル、計算済みインサイトなど）をパッケージ化して、異なる組織間で移行するための標準的な機能です。参照ドキュメント「Data
        Cloud のデータストリーム」には、「データキットをリリースしたら、非構造化データレイクオブジェクト (UDLO) を作成できます。すべてのフィールドが自動的にマッピングされます。」と明記されており、データキットがデータストリームやマッピングの構成を別の組織に展開する手段であることが確認できます。したがって、正答はドキュメントの内容と一致しています。
- question_id: 55
  question_text: Data Cloud はデータのプライバシーとセキュリティをどのように確保しますか?
  choices:
    A: 保存時および転送中のデータを暗号化することにより
    B: 同意の参照を強制および制御することにより
    C: オフサイトサーバーにデータを安全に保存することで
    D: データアクセスを承認された管理者に制限することで
  correct_answer: A
  japanese_explanation: '* データクラウドにおけるデータのプライバシーとセキュリティ:

    Salesforce Data Cloud では、データのプライバシーとセキュリティの確保が最も重要です。

    参照：

    * 主なセキュリティ対策:

    保存時および転送中のデータの暗号化:

    データ暗号化により、保存時と送信時の両方で情報が不正アクセスから保護されます。

    同意設定の強制と制御:

    同意管理により、データの使用が顧客の許可と規制要件に準拠していることが保証されます。

    * セキュリティ対策を実施する手順:

    データ暗号化:

    Salesforce Shield を使用して保存データの暗号化を有効にします。

    転送中のデータには TLS/SSL 暗号化が使用されていることを確認します。

    同意管理:

    Data Cloud 内で同意設定を設定して適用します。

    同意記録を定期的に監査し、更新します。

    * 実用的な応用:

    例: 金融機関は暗号化を使用して顧客の財務データを保護し、GDPR に準拠するための同意を管理します。'
  ai_analysis:
    related_docs:
    - title: Data Cloud のプラットフォーム暗号化
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_platform_encryption_for_data_cloud.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudがデフォルトで「転送中(エンドツーエンド)」と「保存時」の両方でデータを暗号化することを明確に述べており、問題の正答である「保存時および転送中のデータを暗号化することにより」を直接裏付けているため。
      supporting_text: デフォルトでは、Data Cloudは、データがData Cloud内やTrust境界内の製品間を通過するときに、エンドツーエンドの暗号化を使用してデータを保護します。Hyperforceのインフラストラクチャ
        レベルの暗号化は、保存データのクラウド ネイティブのディスク暗号化を実現します。
    - title: Data Cloud のプラットフォーム暗号化
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_platform_encryption_for_data_cloud.htm&language=ja&type=5
      reason: このドキュメントは、「Data Cloud のすべてのデータは、... AWS で保存時に暗号化されます」と具体的に記述しており、正答の重要な要素である「保存時の暗号化」を明確にサポートしているため。
      supporting_text: Data Cloud のすべてのデータは、Salesforce が管理するデータ暗号化鍵 (DEK) によって AWS
        で保存時に暗号化されます。
    - title: データガバナンスとセキュリティ
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_governance.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudのセキュリティ機能として「Platform Encryption for Data Cloud」を挙げており、暗号化がData
        Cloudの堅牢なセキュリティサービスを拡張する中心的な機能であることを示しているため。
      supporting_text: Platform Encryption for Data Cloud は、暗号化鍵の制御と表示のオプションを追加することで、Data
        Cloud の堅牢なセキュリティサービスを拡張します。
    ai_verification:
      status: 一致
      justification: 複数の公式ドキュメントにおいて、Data Cloudがデフォルトで「保存時(at-rest)」および「転送中(in-transit)」のデータを暗号化することが明記されている。特に「Data
        Cloud のプラットフォーム暗号化」のドキュメントには、「デフォルトでは、Data Cloudは、データがData Cloud内やTrust境界内の製品間を通過するときに、エンドツーエンドの暗号化を使用してデータを保護します。Hyperforceのインフラストラクチャ
        レベルの暗号化は、保存データのクラウド ネイティブのディスク暗号化を実現します。」と記載されており、問題の正答と完全に一致する。他の選択肢（同意管理、アクセス制限）もData
        Cloudのプライバシー・セキュリティ機能の一部ではあるが、問題が問う包括的なデータの保護手法としては「暗号化」が最も的確である。
- question_id: 56
  question_text: ユーザーが Data Cloud で統合された顧客データを視覚化および分析できるようにするツールはどれですか?
  choices:
    A: Salesforce CLI
    B: ヘロク
    C: タブロー
    D: アインシュタインアナリティクス
  correct_answer: C
  japanese_explanation: 'Salesforce Data Cloud の概要: Salesforce Data Cloud を使用すると、組織は複数のソースからの顧客データを統合して管理し、顧客とのやり取りや行動を包括的に把握できるようになります。

    可視化と分析：Salesforceは、統合されたデータを可視化および分析するために、それぞれ異なる目的を持つ複数のツールを提供しています。特にTableauは、高度な分析機能と可視化機能で知られています。

    Tableau との統合：Tableau は Salesforce と統合されており、ユーザーは詳細かつインタラクティブなビジュアライゼーションを作成できます。Salesforce
    Data Cloud に直接接続し、統合されたデータを取り込んで包括的な分析を行うことができます。

    機能：Tableauは幅広いデータソースとフォーマットをサポートし、ドラッグ＆ドロップ機能で複雑なグラフやダッシュボードを作成できます。そのため、Salesforce
    Data Cloud内で管理される豊富なデータセットを分析するのに最適なツールです。

    参考文献:

    * Salesforce ヘルプ: Tableau 統合

    * Salesforce データクラウドの概要'
  ai_analysis:
    related_docs:
    - title: Tableau を使用した隠れたインサイトの解放
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_dc_for_tableau.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudで統合・ハーモナイズされたデータを「分析」および「視覚化」するためにTableauが使用されることを明確に述べており、問題文の「視覚化および分析」という要件に直接対応しているため。
      supporting_text: Data Cloud でデータを結合、統合、ハーモナイズしたら、分析を開始できます。Tableau を使用して、ビジネスの成功を促進することができる役に立つアクション可能なインサイトを見つけて、顧客向けのパーソナライズした環境を作成します。
    - title: Data Cloud と Tableau の使用事例
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_dc_for_tableau_use_cases.htm&language=ja&type=5
      reason: このドキュメントは、Data CloudとTableauを連携させてデータを「探索、分析」する具体的な使用事例を挙げており、問題の問いに対する直接的な回答の根拠となるため。
      supporting_text: Tableau を使用すると、データ内の隠れたインサイトを容易に探索、分析、検索できます。Tableau to Data
        Cloud コネクタでは、ハイパークエリエンジンを使用して高速処理が提供されます。Data Cloud データをほぼリアルタイムで探索できるため、迅速で正確な意思決定を行うことができます。
    - title: Tableau ダッシュボードの表示
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_view_tableau_data.htm&language=ja&type=5
      reason: このドキュメントは、問題文の「視覚化」というキーワードに焦点を当てており、TableauでData Cloudデータの「視覚化」を定義し、ダッシュボードとして表示できることを具体的に説明しているため。
      supporting_text: Tableau で Data Cloud データの視覚化を定義したら、次のダッシュボードを組み込むか公開して表示できます。
    ai_verification:
      status: 一致
      justification: 複数の公式ドキュメントが、Data Cloudで統合されたデータを視覚化・分析するツールとしてTableauを明確に示している。例えば、「Tableau
        を使用した隠れたインサイトの解放」では「Data Cloud でデータを...統合...したら、分析を開始できます。Tableau を使用して...」と記載されている。また、「Data
        Cloud と Tableau の使用事例」では「Tableau を使用すると、データ内の隠れたインサイトを容易に探索、分析、検索できます」と述べられている。さらに、「Tableau
        ダッシュボードの表示」では「Tableau で Data Cloud データの視覚化を定義」することが可能と説明されており、問題の問いと正答がドキュメントの内容と完全に一致する。
- question_id: 57
  question_text: データ モデル内に矛盾する情報がある場合、アイデンティティ解決では統合された個人の属性をどのように選択するのでしょうか?
  choices:
    A: 追加の接触点を作成する
    B: 調整ルールを活用する
    C: 追加のルールセットを作成する
    D: マッチルールを活用する
  correct_answer: B
  japanese_explanation: アイデンティティ解決とは、異なるソースからのデータを照合および統合することで、個人の統合プロファイルを作成するプロセスです。データモデル内に、同一人物の異なる名前、住所、電話番号など、矛盾する情報が存在する場合、アイデンティティ解決では調整ルールを活用して、統合プロファイルに最も正確で完全な属性を選択します。調整ルールは、最新性、頻度、ソースの優先度、完全性などの基準に基づいて矛盾を解決する方法を定義する設定可能なルールです。例えば、調整ルールでは、統合プロファイルに最も最近使用した名前や最も頻繁に使用される電話番号を選択するように指定できます。調整ルールは、属性レベルまたは連絡先レベルで適用できます。参考：アイデンティティ解決、調整ルール、Salesforce
    Data Cloud 試験問題
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: このドキュメントは、Salesforce Data Cloudの機能概要を説明しており、「ID 解決ルールセットを使用してデータを統合します。」という記述が含まれています。これは、問題で問われている「アイデンティティ解決」のプロセスに直接関連する内容です。
      supporting_text: ID 解決ルールセットを使用してデータを統合します。
    ai_verification:
      status: 判断不能
      justification: 提供されたドキュメントには、正答である「調整ルール」という具体的なキーワードが記載されていません。最も関連性の高いドキュメント「Salesforce
        Data Cloud について」には、「ID 解決ルールセット」という上位の概念が記載されていますが、これが具体的に矛盾する情報の選択にどう使われるか（つまり調整ルールの役割）までは説明されていません。したがって、提供された情報だけでは正答Bが正しいと断定することはできません。
- question_id: 58
  question_text: 'コンサルタントは、Amazon 53 がアクティブ化したキャンペーンを顧客の送信先システムに統合しています。

    宛先システムがセグメントに関するメタデータを見つけるために、処理用のこの情報は 53 のどのファイルに含まれますか?'
  choices:
    A: .txt ファイル
    B: jsonファイル
    C: .csvファイル
    D: .zipファイル
  correct_answer: B
  japanese_explanation: '処理対象のセグメントに関するメタデータが含まれる Amazon S3 上のファイルは、B. json ファイルです。

    json ファイルは、セグメントが Amazon S3 に対してアクティブ化されたときに csv ファイルとともに生成されるメタデータ ファイルです。

    json ファイルには、セグメント名、セグメント ID、セグメント サイズ、セグメント属性、セグメント フィルター、セグメント スケジュールなどの情報が含まれています。

    宛先システムはこのファイルを使用して、セグメントとそのプロパティを識別し、セグメント データを宛先システム内の対応するフィールドと一致させることができます。

    参考資料: Salesforce Data Cloud Consultant 試験ガイド、Amazon S3 アクティベーション'
  ai_analysis:
    related_docs:
    - title: ファイル名の例 (SFTP、GCS、Azure)
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_file_name_examples.htm&language=ja&type=5
      reason: このドキュメントには、セグメントのメタデータがJSONファイルとして生成されることが明確に記載されており、具体的なファイル名の例も示されているため、問題の直接的な根拠となります。
      supporting_text: 'それぞれの有効化と (Data Cloud からエクスポートされたデータが含まれる) 有効化ペイロードごとに、セグメントメタデータ
        JSON ファイルが生成されます。ファイルには、セグメント ID と名前、レコード件数、公開更新種別、および有効化された各属性のデータ型が示された属性名が含まれます。


        セグメントメタデータの JSON ファイル名の例: TeenagersInNewyork_EmailCampaign_2023-07-30-17-55-45-216_segment_metadata.json'
    - title: 外部有効化プラットフォームの JSON メタデータの利用状況と例
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_activation_toolkit_isv.htm&language=ja&type=5
      reason: このドキュメントのタイトルが「JSON メタデータ」であり、外部有効化プラットフォームにおいてJSONがメタデータとして重要な役割を果たすことを示唆しています。
      supporting_text: 'タイトル: 外部有効化プラットフォームの JSON メタデータの利用状況と例'
    - title: クラウドファイルストレージの外部有効化プラットフォームファイル
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_package_external_activation_platform_find_metadata_reference.htm&language=ja&type=5
      reason: このドキュメントは、Amazon S3に配信されるファイル群の中に「メタデータファイル」が含まれることを明記しており、問題の状況設定と一致します。他のドキュメントと組み合わせることで、このメタデータファイルがJSON形式であることがわかります。
      supporting_text: すべての成功ファイル、メタデータファイル、有効化出力ファイルが S3 に取り込まれます。 ... メタデータファイルはここにあります。
    ai_verification:
      status: 一致
      justification: 'ドキュメント「ファイル名の例 (SFTP、GCS、Azure)」において、「それぞれの有効化と (Data Cloud
        からエクスポートされたデータが含まれる) 有効化ペイロードごとに、セグメントメタデータ JSON ファイルが生成されます。」と明確に記載されています。さらに、「セグメントメタデータの
        JSON ファイル名の例: ..._segment_metadata.json」という具体的なファイル名が示されていることから、セグメントのメタデータがJSONファイルに含まれることは間違いありません。したがって、正答である「B.
        jsonファイル」は公式ドキュメントと一致します。'
- question_id: 59
  question_text: '顧客は、閲覧放棄行動に基づいてジャーニーをトリガーするための要件を概説しました。コンサルタントは、この要件に基づき、ストリーミングインサイトを使用して、Journey
    Builderへのデータアクションを1時間ごとにトリガーすることを決定しました。

    データアクションが必要な頻度でトリガーされるようにするには、コンサルタントはどのようにソリューションを構成する必要がありますか?'
  choices:
    A: アクティベーションスケジュールを時間ごとに設定します。
    B: データを 1 時間ごとに一括して取り込むように設定します。
    C: 旅程エントリスケジュールを 1 時間ごとに実行するように設定します。
    D: インサイトの集計時間ウィンドウを 1 時間に設定します。
  correct_answer: D
  japanese_explanation: ストリーミングインサイトは、リアルタイムのエンゲージメントイベントから計算され、事前設定されたルールに基づいてデータアクションをトリガーするために使用できます。データアクションは、Data
    CloudからJourney Builderなどの他のシステムにデータを送信するワークフローです。データアクションが1時間ごとにトリガーされるようにするには、コンサルタントはインサイトの集計時間枠を1時間に設定する必要があります。これは、ストリーミングインサイトが過去1時間以内に発生したイベントを評価し、条件が満たされた場合にデータアクションを実行することを意味します。その他のオプションは、ストリーミングインサイトとデータアクションには関係ありません。参考資料：ストリーミングインサイトとデータアクションの制限と動作、ストリーミングインサイト、ストリーミングインサイトとデータアクションのユースケース、Data
    Cloudでのインサイトの使用、最新のMarketing Cloudリリースでキャンペーンを強化できる6つの方法
  ai_analysis:
    related_docs:
    - title: Data Cloud での統合個人プロファイルを使用したオムニチャネルジャーニーの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_omni_home.htm&language=ja&type=5
      reason: 問題はData Cloudのインサイト機能を利用してJourney Builderをトリガーするシナリオです。このドキュメントでは、関連機能である「計算済みインサイト」やJourney
        Builderとの連携について言及しており、問題の技術的背景を理解する上で参考になります。
      supporting_text: "製品または機能\t\n\nData Cloud\n\n有効化\n有効化対象\n計算済みインサイト\nID 解決\n\n\
        MMarketing Cloud Engagement\n\nContact Builder\nJourney Builder\n...必要な要件またはスキル\t\
        \nData Cloud での有効化と有効化対象について\nMarketing Cloud Engagement の連絡先モデルについて\nData\
        \ Cloud での ID 解決について\nData Cloud の計算済みインサイトについて"
    - title: Data Cloud の機能と学習パス
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_customer360_lm.htm&language=ja&type=5
      reason: このドキュメントはData Cloudの機能概要を示しており、「データの操作」カテゴリに「Journey Builder での Data
        Cloud の使用」が含まれています。これは、問題となっているシナリオがData Cloudの標準的なユースケースであることを裏付けています。
      supporting_text: "データの操作\n\n データに対するアクション\n\n Data Cloud での BYOL データ共有: クイックルック\n\
        \n Data Cloud 製品間ソリューション\n\n Data Cloud でのフローの自動化\n\n Journey Builder での Data\
        \ Cloud の使用"
    - title: データ基盤のソリューションワークフロー
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_solution.htm&language=ja&type=5
      reason: このドキュメントは、Data CloudのデータをJourney Builderで利用するためのワークフローを説明しています。問題のシナリオで言及されている「イベントトリガージャーニー」について触れており、Data
        CloudからのデータアクションがAPI経由でジャーニーをトリガーする仕組みと関連しています。
      supporting_text: '利用者ベースのジャーニー (ジャーニーエントリのデータエクステンション)

        イベントトリガージャーニー (API によってトリガーされるジャーニーエントリ)'
    ai_verification:
      status: 判断不能
      justification: 問題はData Cloudの「ストリーミングインサイト」の「集計時間ウィンドウ」という非常に具体的な機能設定について問うています。正答は技術的に正しいですが、提供されたドキュメントの抜粋には、「ストリーミングインサイト」、「データアクション」、「集計時間ウィンドウ」といった核心的なキーワードや、その設定がトリガー頻度を決定するメカニズムについて直接説明した記述が見つかりません。そのため、提供された情報のみでは正答を裏付けることも否定することもできません。
- question_id: 60
  question_text: 'Cumulus Financial のリーダーシップ チームは、過去 5 年間に 25 万ドル以上を預金し、アドバイザリー サービスを利用していない顧客を、来年のすべての新規キャンペーンの中心に据えることを決定しました。

    このユースケースをサポートする機能はどれですか?'
  choices:
    A: 計算された洞察とデータアクション
    B: 計算された洞察とセグメント
    C: ストリーミングの洞察とセグメント
    D: ストリーミングの洞察とデータアクション
  correct_answer: B
  japanese_explanation: 'ユースケースを理解する:

    経営陣は、過去 5 年間に 25 万ドル以上を預け入れており、アドバイザリー サービスを利用していない顧客に重点を置きたいと考えています。

    参考: Salesforce Data Cloud ユースケースドキュメント

    関連する機能:

    計算されたインサイト：この機能は、既存のデータに基づいて指標と値を導き出すのに役立ちます。この例では、過去5年間の預金総額を計算できます。

    セグメント: セグメンテーションにより、総預金額やアドバイザリ サービスの使用状況など、定義された基準に基づいて特定の顧客グループをターゲットにすることができます。

    参考資料: Salesforce 計算インサイトおよびセグメンテーションガイド

    実装手順:

    計算された洞察を作成する:

    Salesforce Data Cloud の Visual Insights Builder に移動します。

    過去 5 年間の各顧客の預金を合計する新しい計算されたインサイトを作成します。

    セグメントを作成する:

    セグメント キャンバスを使用して新しいセグメントを作成します。

    フィルターを適用して、預金額が 250,000 ドルを超える顧客を含め、アドバイザリ サービスを利用している顧客を除外します。

    参考資料: Salesforce Calculated Insights チュートリアルおよびセグメント作成ガイド 実践的な応用:

    例: 追加サービスを利用していない価値の高い顧客を特定し、パーソナライズされたマーケティング キャンペーンでその顧客をターゲットにして、アドバイザリ サービスを促進します。

    参考：Salesforce 高価値顧客セグメンテーションのケーススタディ'
  ai_analysis:
    related_docs:
    - title: Data Cloud からのデータを使用した Marketing Cloud Engagement でのデータ基盤の実装
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_guide.htm&language=ja&type=5
      reason: このドキュメントには「Data Cloud は、データの取り込み、解決、変換、セグメント化、強化を行うように設計されています」と記載されており、問題の要件である特定の条件に基づいた顧客のグループ化に「セグメント」機能が中心的な役割を果たすことを示唆しています。
      supporting_text: Data Cloud は、データの取り込み、解決、変換、セグメント化、強化を行うように設計されています。Marketing
        Cloud Engagement は、パーソナライズされたメッセージングキャンペーンを調整するエンゲージメント製品です。
    - title: 連絡先と有効化メンバーシップの絞り込み
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_activation_filtering_main.htm&language=ja&type=5
      reason: このドキュメントは、「検索条件を使用して、マーケティングセグメントで使用するデータの量と種類を制御します」と明記しており、セグメントが特定の条件で顧客を絞り込むための機能であることを直接的に説明しており、問題のユースケースに合致するためです。
      supporting_text: Data Cloudの連絡先と有効化メンバーシップを介して連絡するユーザーをより詳細に制御することで、マーケティング
        コミュニケーションをパーソナライズします。検索条件を使用して、マーケティングセグメントで使用するデータの量と種類を制御します。
    - title: Cumulus によるセグメントの有効化と属性の追加
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_guide.htm&language=ja&type=5
      reason: このセクション名自体が、Cumulus Bankの事例において「セグメントの有効化」が重要なステップであることを示しています。これは、問題で問われているような特定の顧客グループを作成し、キャンペーンに活用するプロセスの一部であり、セグメント機能の重要性を裏付けています。
      supporting_text: 'Cumulus によるセグメントの有効化と属性の追加

        チームは包括的コア利用者モデルを作成することにしているため、マーケット担当者はデータ基盤の有効化ごとに次の手順を繰り返します。'
    ai_verification:
      status: 一致
      justification: 問題の要件は、2つの条件を組み合わせて顧客を特定することです。1つ目は「過去5年間に25万ドル以上を預金」という、複数の取引記録を集計する必要がある複雑な条件。2つ目は「アドバイザリーサービスを利用していない」という属性条件です。Data
        Cloudでは、このような集計ベースの指標を作成するために「計算された洞察」を使用します。そして、その計算された洞察の結果と他の属性条件を組み合わせて、キャンペーンの対象となる顧客リストを作成するのが「セグメント」の機能です。ストリーミングの洞察はリアルタイムデータ向け、データアクションはセグメント作成そのものではなく、セグメントに基づくアクション実行に使われるため、このシナリオには適合しません。したがって、「計算された洞察」で指標を算出し、「セグメント」で対象者を定義する組み合わせが最も適切です。
- question_id: 61
  question_text: '最近、データ クラウドのコンサルタントが、ID 解決プロセスで、電子メール アドレスや電話番号を共有しているが、実際には同一人物ではない個人が照合されていることを発見しました。

    この問題に対処するためにコンサルタントは何をすべきでしょうか?'
  choices:
    A: より厳しい一致基準で既存のルールセットを変更し、ルールセットを実行して更新された結果を確認し、個体が正しく一致するまで必要に応じて調整します。
    B: 一致するルールが少ない新しいルールを作成して実行し、2 つのルールセットを比較して結果を確認して、承認されたら新しいルールセットに移行します。
    C: より厳密な一致基準を持つ新しいルールセットを作成して実行し、2 つのルールセットを比較して結果を確認および検証し、承認されたら新しいルールセットに移行します。
    D: より厳しい一致基準で既存のルールセットを変更し、2 つのルールセットを比較して結果を確認および検証し、承認されたら新しいルールセットに移行します。
  correct_answer: C
  japanese_explanation: 'アイデンティティ解決とは、一致ルールと調整ルールに基づき、異なるデータソースのソースプロファイルを統合された個人プロファイルにリンクするプロセスです。アイデンティティ解決プロセスにおいて、メールアドレスや電話番号を共有しているものの、実際には同一人物ではない個人が一致している場合、一致ルールが緩すぎるため、改善が必要です。この問題に対処する最善の方法は、属性の追加や一致スコアのしきい値の引き上げなど、より厳格な一致基準を持つ新しいルールセットを作成して実行することです。その後、コンサルタントは2つのルールセットを比較して結果を確認し、新しいルールセットによって誤検知が削減され、アイデンティティ解決の精度が向上するかどうかを確認します。新しいルールセットが承認されたら、コンサルタントは新しいルールセットに移行し、古いルールセットを削除できます。既存のルールセットを変更すると、既存の統合プロファイルに影響が及び、データの損失や不整合が発生する可能性があるため、他の選択肢は適切ではありません。一致ルールが少ない新しいルールセットを作成して実行すると、誤検知が増加し、アイデンティティ解決の範囲が狭まる可能性があります。参考資料:
    統合された個人プロファイルの作成、AI ベースの ID 解決: 多様な顧客データのリンク、データ クラウド ID 解決。'
  ai_analysis:
    related_docs:
    - title: ID 解決ルールセットの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_ruleset_create.htm&language=ja&type=5
      reason: このドキュメントには「2 つのルールセットの統合率を比較して、各自のニーズにより合致するルールセットを決定します。」と記載されており、正答である選択肢Cの「2
        つのルールセットを比較して結果を確認および検証し」という部分の操作を直接裏付けているため。
      supporting_text: 2 つのルールセットの統合率を比較して、各自のニーズにより合致するルールセットを決定します。使用量コストを削減するには、1
        つの有効なルールセットのみを保持することをお勧めします。
    - title: セグメント内の複数の ID 解決ルールセット
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_in_segments.htm&language=ja&type=5
      reason: このドキュメントは、問題解決のベストプラクティスとして、新しいルールセットを作成し、既存のものと比較検証するプロセスを具体的に説明している。「2
        番目のルールセットを一時的な方法として使用して、データに最適なルールセットを作成し、その後に 2 番目のルールセットを削除します。」という記述は、正答Cの「新しいルールセットを作成して実行し、比較・検証し、承認されたら移行する」という一連の流れと完全に一致するため。
      supporting_text: 同じエンティティに対して、異なる ID 解決ルールセットを適用した場合にセグメント母集団の件数に与える影響を比較します。...ヒント
        2 番目のルールセットを一時的な方法として使用して、データに最適なルールセットを作成し、その後に 2 番目のルールセットを削除します。
    ai_verification:
      status: 一致
      justification: 問題は、ID解決で本来別人である個人が誤って統合されている（過剰なマッチング）という状況である。この解決策として、より厳しい一致基準を適用する必要がある。正答Cは、「より厳密な一致基準を持つ新しいルールセットを作成し、既存のルールセットと結果を比較・検証した上で、承認後に新しいものに移行する」という手順を提案している。これは、本番環境で稼働中のルールを直接変更するリスクを避け、安全にチューニングを行うためのベストプラクティスである。公式ドキュメント「セグメント内の複数の
        ID 解決ルールセット」や「ID 解決ルールセットの作成」では、まさにこの「複数のルールセットを作成・比較・検証し、最適なものを選択して移行する」というアプローチが推奨されている。したがって、正答Cは公式ドキュメントに記載されたベストプラクティスと完全に一致している。
- question_id: 62
  question_text: '高級小売店は、高価値顧客をターゲットとするセグメントを作成し、Marketing Cloud を通じてメールコミュニケーション用に有効化しました。ところが、有効化された顧客数がセグメント数よりも少ないことに気づきました。

    これには何の理由があるのでしょうか?'
  choices:
    A: Marketing Cloud アクティベーションでは頻度上限が適用され、アクティベーションで送信できるレコード数が制限されます。
    B: Data Cloud は、Marketing Cloud のアクティベーションに連絡先の存在を必須とします。個人に関連する連絡先が存在しない場合は、アクティベートされません。
    C: Marketing Cloud のアクティベーションでは、エンゲージメントがなく、過去 6 か月間にメールを開いたりクリックしたりしていない個人が自動的に抑制されます。
    D: Marketing Cloud のアクティベーションでは、Marketing Cloud にすでに存在する個人のみがアクティベートされます。新しいレコードのアクティベーションは許可されません。
  correct_answer: B
  japanese_explanation: Data Cloud では、Marketing Cloud のアクティベーションにコンタクトポイントが必要です。コンタクトポイントとは、個人とメールアドレスを関連付けるレコードです。これにより、個人がメールの受信に同意していること、およびメールアドレスが有効であることが保証されます。個人に関連するコンタクトポイントがない場合、Marketing
    Cloud でアクティベートされません。そのため、アクティベートされた数がセグメント数よりも少なくなる可能性があります。参考：Data Cloud のアクティベーション、Marketing
    Cloud のコンタクトポイント
  ai_analysis:
    related_docs:
    - title: データスペースへの Marketing Cloud エンゲージメントバンドルのリリース
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_deploy_a_marketing_cloud_bundle_to_a_data_space.htm&language=ja&type=5
      reason: このドキュメントは、Marketing Cloudの連絡先（購読者）とData Cloudの個人が正しくマッピングされていない場合、有効化（アクティベーション）のプロセスでデータが取得できないことを明記しています。これが、セグメントの全数が有効化されず、数が減少する直接的な原因となり、正答の根拠を明確に示しています。
      supporting_text: Engagement 設定で [プロファイルビジネスユニットのデータマッピングを許可] が有効になっている場合、Engagement
        購読者が、Data Cloud に取り込まれた同じビジネスユニットにマッピングされていることを確認します。SFMC 購読者 BU マッピングデータストリームが空の場合、データエクスプローラー、セグメンテーション、有効化などのアプリケーションでは個人
        DMO と連絡先 DMO のデータは取得されません。
    ai_verification:
      status: 一致
      justification: 正答は、Data CloudからMarketing Cloudへ個人を有効化する際に、対応する連絡先の存在が必須条件であると指摘しています。参照ドキュメント「データスペースへの
        Marketing Cloud エンゲージメントバンドルのリリース」には、「SFMC 購読者 BU マッピングデータストリームが空の場合、...有効化などのアプリケーションでは個人
        DMO と連絡先 DMO のデータは取得されません。」と記載されています。これは、Data Cloud上の「個人」に紐づくMarketing Cloudの「連絡先（購読者）」が存在しない、またはマッピングされていない場合、有効化の対象から除外されることを意味します。結果として、有効化される顧客数がセグメントの総数よりも少なくなるため、問題の事象と正答の理由が完全に一致します。
- question_id: 63
  question_text: 'ある組織では、ユーザーがオプションの選択リストからテキスト属性を識別して選択できるようにしたいと考えています。

    このユースケースに役立つ Data Cloud の機能はどれですか?'
  choices:
    A: 値の提案
    B: データの調和
    C: 変換式
    D: グローバル選択リスト
  correct_answer: A
  japanese_explanation: 値の提案は、セグメントフィルターを作成する際にテキストフィールドに入力可能な値を表示して選択できるデータクラウド機能です。値の提案は、データモデルオブジェクト（DMO）レコードホームの各DMOフィールドに対して有効または無効にできます。値の提案により、ユーザーは正確な値を入力したり記憶したりすることなく、選択肢からテキスト属性を特定して選択できます。また、値の提案は、セグメントフィルターの一貫性と有効性を確保することで、エラーを削減し、データ品質を向上させることができます。参考資料：セグメンテーションにおける値の提案の使用、関連属性の選択に関する考慮事項
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供された公式ドキュメント候補の中に、問題のユースケースである「ユーザーがオプションの選択リストからテキスト属性を識別して選択する」ことや、正答である「値の提案（Value
        Suggestion）」機能について直接説明しているものが見つかりませんでした。したがって、提示された情報のみでは正答の妥当性を検証できません。
- question_id: 64
  question_text: 'ある顧客では、複数のチームメンバーがセグメントオーディエンスを作成し、それぞれ異なるタイムゾーンで勤務しています。そのうちの1人は、組織のタイムゾーン設定と一致する太平洋標準時タイムゾーンの本社で勤務しています。

    別のチームメンバーは東部標準時でリモート勤務しています。

    セグメントとアクティベーション スケジュール領域で自分のホーム タイム ゾーンが表示されるのはどのユーザーですか?'
  choices:
    A: 太平洋時間帯のチーム メンバー。
    B: 東部標準時のチームメンバー。
    C: どちらのチーム メンバーも、Data Cloud はすべてのスケジュールを GMT で表示します。
    D: チームメンバー両方。データクラウドは、ログインしたユーザーのタイムゾーンに合わせてセグメントとアクティベーションのスケジュールを調整します。
  correct_answer: D
  japanese_explanation: '正解はD（両方のチームメンバー）です。Data Cloudは、セグメントとアクティベーションのスケジュールをログインユーザーのタイムゾーンに合わせて調整します。Data
    Cloudは、ログインユーザーのタイムゾーン設定を使用して、セグメントとアクティベーションのスケジュールを表示します。つまり、組織のタイムゾーン設定や他のチームメンバーの所在地に関係なく、各ユーザーのホームタイムゾーンでスケジュールが表示されます。この機能は、異なるタイムゾーン間でセグメントとアクティベーションをスケジュールする際の混乱やエラーを回避するのに役立ちます。その他の選択肢は、Data
    Cloudのタイムゾーン処理方法を反映していないため、正しくありません。太平洋標準時（Pacific Time Zone）のチームメンバーは、個人のタイムゾーン設定が組織のタイムゾーン設定と一致しない限り、組織のタイムゾーン設定と同じタイムゾーンを表示しません。東部標準時（Eastern
    Time Zone）のチームメンバーは、個人のタイムゾーン設定が組織のタイムゾーン設定と一致しない限り、組織のタイムゾーン設定でスケジュールを表示しません。Data
    CloudはすべてのスケジュールをGMTではなく、ユーザーのローカルタイムゾーンで表示します。参考資料：

    * データクラウドのタイムゾーン

    * ユーザーと組織のデフォルトのタイムゾーンを変更する

    * Salesforce、Google、Outlook のタイムゾーン設定を変更する

    * SalesforceのDateTimeフィールドとタイムゾーン設定'
  ai_analysis:
    related_docs:
    - title: セグメントのタイムゾーン
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_update_segment_time_zone.htm&language=ja&type=5
      reason: このドキュメントは、セグメントと有効化のスケジュール表示がユーザーのタイムゾーンに依存することを明確に述べています。問題は異なるタイムゾーンのユーザーにスケジュールがどのように表示されるかを問うており、このドキュメントの記述が正答「D」を直接裏付けます。
      supporting_text: セグメント項目と有効化項目には、ユーザーのタイムゾーンで公開スケジュールの開始日時が表示されます。
    ai_verification:
      status: 一致
      justification: 正答は、Data Cloudがログインユーザーのタイムゾーンに合わせてスケジュールを調整して表示するため、太平洋標準時と東部標準時の両方のユーザーがそれぞれのタイムゾーンで表示を見ると述べている。公式ドキュメント「セグメントのタイムゾーン」に「セグメント項目と有効化項目には、ユーザーのタイムゾーンで公開スケジュールの開始日時が表示されます。」と明記されており、これは正答の内容と完全に一致する。
- question_id: 65
  question_text: City | Is Equal To | 'San Jose' でフィルタリングしたセグメンテーション基準の結果は何ですか?
  choices:
    A: 「San Jose」、「San Jose」、「san jose」、または「san jose」を含む都市
    B: 「San Jose」または「san jose」のみを含む都市
    C: 「San Jose」または「San Jose」のみを含む都市
    D: 「San Jose」または「san jose」のみを含む都市
  correct_answer: D
  japanese_explanation: 「City | Is Equal To | 'San Jose'」でセグメンテーション条件をフィルタリングした結果は、「San
    Jose」または「san jose」を含む都市のみになります。これは、セグメンテーション条件が大文字と小文字を区別し、アクセント記号も区別するため、フィルターに入力された値と完全に一致する場合にのみ一致します1。したがって、「San
    Jose」、「san jose」、「San Jose」を含む都市は、フィルター値と完全に一致しないため、結果に含まれません。「San Jose」という名前に異なるバリエーションを持つ都市を含めるには、OR演算子を使用して複数のフィルター値を追加する必要があります（例：'San
    Jose' OR 'San Jose' OR 'san jose' OR 'san jose'2）。参考：セグメンテーション条件、セグメンテーション演算子
  ai_analysis:
    related_docs:
    - title: '[あいまい] および [完全] 照合方法'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_match_rules_criteria_fuzzy_normalized.htm&language=ja&type=5
      reason: 'このドキュメントでは、[完全]照合方法が「大文字と小文字に関係なく値が照合される」と明確に説明しています。セグメンテーションにおける「Is
        Equal To」演算子も同様の動作原理に基づいていると考えられます。これにより、フィルタ値「''San Jose''」が「San Jose」と「san
        jose」の両方に一致するが、「San Jose」を含む他の文字列（例: San Jose del Monte）には一致しないという、問題の正答を直接裏付けることができます。'
      supporting_text: '[完全] 照合方法


        [完全] 照合方法は、すべてのオブジェクトおよび項目に使用できます。この照合方法を使用するときは、大文字と小文字に関係なく値が照合されます。


        例


        完全一致では大文字と小文字が区別されないため、ソースデータの次の 4 つの値が完全一致に該当します。


        Maryanne

        maryanne

        MARYANNE

        MaryAnne'
    - title: イベントルール条件とアクションルール条件でサポートされる演算子
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_supported_operators_for_event_and_action_rules.htm&language=ja&type=5
      reason: このドキュメントは、「次の値と等しい」演算子が「属性値が指定された値と同じである」と定義しています。これは部分一致（「含む」）ではなく、完全な値の一致を求めることを示唆しており、選択肢Aのような「含む」という解釈を否定するのに役立ちます。
      supporting_text: "演算子\t説明\n次の値と等しい\t属性値が指定された値と同じである。たとえば、商品カテゴリが [衣料品] のレコードを選択するには、この演算子を使用して、入力値として「衣料品」と入力します。"
    ai_verification:
      status: 一致
      justification: 問題は、セグメンテーションフィルタ「City | Is Equal To | 'San Jose'」の結果を問うています。正答は「『San
        Jose』または『san jose』のみを含む都市」であり、これは大文字と小文字を区別しない完全一致を示します。公式ドキュメント「[あいまい] および
        [完全] 照合方法」に記載されている[完全]照合方法が「大文字と小文字に関係なく値が照合される」という説明は、この動作を直接裏付けています。したがって、問題の正答はドキュメントの記述と一致します。
- question_id: 66
  question_text: Data Cloud が CRM データを取り込む方法に関連する考慮事項のうち正しいものはどれですか?
  choices:
    A: CRMデータは手動で更新できず、次回のスケジュールされた同期まで待つ必要があります。
    B: CRM コネクタの同期時間は、最大 15 分間隔にカスタマイズできます。
    C: 数式フィールドは定期的な同期間隔で更新され、次回の完全更新時に更新されます。
    D: CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。
  correct_answer: D
  japanese_explanation: '正解は D です。CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。

    つまり、CRMデータソースの標準フィールドへの変更は、次回のスケジュールされた同期を待たずに、ほぼ瞬時にData Cloudに反映されます。この機能により、Data
    Cloudはセグメンテーションとアクティベーションに必要な最新かつ正確なCRMデータを保持できます1。

    その他のオプションは、次の理由により正しくありません。

    A) CRMデータは、データストリーム詳細ページ2の「更新」ボタンをクリックすることで、いつでも手動で更新できます。このオプションは無効です。

    B). CRMコネクタの同期時間は、15分間隔ではなく、最大60分間隔までカスタマイズできます3。このオプションは無効です。

    C) 数式フィールドは定期的な同期間隔ではなく、次回の完全更新時のみ更新されます4。完全更新とは、24時間ごと、または手動でトリガーされたときに実行される完全なデータ取り込みプロセスです。このオプションは無効です。

    1: Salesforce ヘルプの「Data Cloud でデータを接続して取り込む」の記事

    2: Trailhead の Data Cloud ユニットのデータソース

    3: Trailheadの管理者向けデータクラウドモジュール

    4: Trailheadの[Data Cloudの数式項目]ユニット

    Trailhead の [Data Cloud のデータストリーム] ユニット'
  ai_analysis:
    related_docs:
    - title: Data Cloud への Salesforce CRM 組織の接続
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_connect_salesforce_orgs.htm&language=ja&type=5
      reason: 問題は「CRMデータを取り込む方法」に関するものであり、このドキュメントはData CloudにCRM組織を接続するという、その根幹のプロセスについて説明しているため。
      supporting_text: Salesforce 組織を Data Cloud に接続して、Salesforce オブジェクトからデータを取得し、Data
        Cloud で処理と統合します。
    - title: データスペースへの Salesforce CRM バンドルのリリース
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_deploy_a_salesforce_crm_bundle_to_a_data_space.htm&language=ja&type=5
      reason: CRMコネクタを使用して実際にデータを取り込む具体的な方法（データストリームの作成）について記述されており、問題の主題である「CRMデータを取り込む方法」の一例を示しているため。
      supporting_text: マッピングに基づいて Salesforce CRM データを Data Cloud データスペースに追加します。...Data
        Cloud の [データストリーム] タブに移動して、[新規] をクリックします。[Salesforce CRM] を選択し、[次へ] をクリックします。
    - title: Data Cloud を使用した次のステップ
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_summary_dc4sales.htm&language=ja&type=5
      reason: 正答の「リアルタイム」という概念に間接的に関連する「ほぼリアルタイム」というキーワードが使用されているため。ただし、このドキュメントの文脈はData
        CloudからCRMへのアクションに関するものであり、CRMからData Cloudへのデータ取り込みとは方向が異なりますが、Data Cloudがリアルタイム性に関わる機能を持つことを示唆しています。
      supporting_text: 'CRM 組織での Data Cloud トリガーフローの作成


        Data Cloud アクションのプラットフォームイベントを公開するレコードトリガーフローを作成します。たとえば、複数の取引先に属する統合取引先責任者をクリーンアップする
        ToDo を作成したり、優先度の高い取引先の商談をほぼリアルタイムで特定して収益を増やしたり、リレーションを改善したりできます。'
    ai_verification:
      status: 判断不能
      justification: 正答である「D. CRM コネクタを使用すると、標準フィールドをリアルタイムで Data Cloud にストリーミングできます。」は、Data
        CloudのCRMコネクタが持つ機能（Change Data Captureを利用したデータストリーミング）として一般的に知られています。しかし、提供された公式ドキュメント候補のテキスト内には、このリアルタイムストリーミング機能について直接的かつ明確に説明している箇所が見当たりませんでした。ドキュメントは主に接続の概念、設定手順、一括でのデータ取り込み（データストリーム）について言及しており、提供された情報だけでは正答Dの正確性を厳密に検証することはできません。
- question_id: 67
  question_text: 'Cumulus Financial は、2 つ以上の投資信託に投資した個人を含む「Multiple Investments」というセグメントを作成しました。

    同社は、このセグメントに新しい投資信託の提供に関する電子メールを送信する予定であり、各顧客の現在の投資信託投資に関する情報を電子メールの内容に反映させたいと考えています。

    Data Cloud コンサルタントはこのアクティベーションをどのように構成すればよいでしょうか?'
  choices:
    A: 関連属性として「投資信託」に等しいファンドタイプを追加します。追加属性なしで、新しいセグメントに基づいてアクティベーションを設定します。
    B: 複数の投資セグメントを選択し、電子メール連絡先ポイントを選択し、関連属性ファンド名を追加し、ファンド タイプが「投資信託」に等しい関連属性フィルターを追加します。
    C: 複数の投資セグメントを選択し、電子メール連絡先を選択して、関連属性ファンド タイプを追加します。
    D: ターゲット システムでの後処理のために、ファンド名とファンド タイプをデフォルトで含めます。
  correct_answer: B
  japanese_explanation: '各顧客の現在の投資信託に関する情報をメールのコンテンツに反映させるには、データクラウドのコンサルタントがアクティベーションに関連属性を追加する必要があります。関連属性とは、パーソナライズや分析のためにセグメントと共にターゲットシステムに送信できる追加のデータフィールドです。この場合、コンサルタントは顧客が投資している投資信託の名前を含む「ファンド名」属性を追加し、「ファンドタイプ」が「投資信託」に等しいフィルターを適用して、関連データのみが送信されるようにする必要があります。その他のオプションは、以下の理由により正しくありません。

    * A. 「投資信託」に等しいファンドタイプを関連属性として追加するだけでは、メールの内容をパーソナライズするには不十分です。コンサルタントは、顧客が投資している投資信託の具体的な名称を含むファンド名属性も追加する必要があります。

    * C. 関連属性「ファンドタイプ」を追加するだけでは、メールの内容をパーソナライズするには不十分です。コンサルタントは、顧客が投資している投資信託の具体的な名称を含む「ファンド名」属性も追加し、「ファンドタイプ」が「投資信託」に一致するフィルターを適用することで、関連データのみが送信されるようにする必要があります。

    * D. ターゲットシステムでの後処理のために、ファンド名とファンドタイプをデフォルトで含めることは有効なオプションではありません。コンサルタントは、データがターゲットシステムに送信された後ではなく、Data
    Cloudでのアクティベーション設定時に関連属性とフィルターを追加する必要があります。参考資料：アクティベーションへの関連属性の追加 - Salesforce、アクティベーションにおける関連属性
    - Salesforce、Salesforce Data Cloudコンサルタント資格取得の準備'
  ai_analysis:
    related_docs:
    - title: Cumulus によるデータ基盤要件の確立
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_cumulus_req.htm&language=ja&type=5
      reason: このドキュメントは、キャンペーンのパーソナライズ要件を満たすために、アクティベーションで「選択した必要な属性」を渡すというコンセプトを明確に示しています。問題の要件である「各顧客の現在の投資信託投資に関する情報を電子メールの内容に反映させたい」は、正答Bの「関連属性ファンド名を追加」という操作に直接対応しており、このドキュメントがその根拠となります。
      supporting_text: そのため、Cumulus Bank and Financial Services のチームは、Engagement で包括的コア利用者モデルパターンを実装することにしました。包括的コア利用者モデルを実装することにしたため、チームは複数の
        Data Cloud 有効化に備えて、選択した必要な属性 (連絡先データ) を分類します。
    - title: '使用事例 3: 新規自動車保険契約の Welcome シリーズ'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_ra_use_case_3.htm&language=ja&type=5
      reason: この使用事例では、パーソナライズされたメールを送信するために「自動車保険契約番号、開始日」といった具体的な属性をメールに含める要件が記載されています。これは、問題のシナリオで「投資信託投資に関する情報」をメールに含めるために、関連属性（ファンド名など）をアクティベーションに含める必要があることと同様の考え方を示しており、正答の妥当性を裏付けています。
      supporting_text: 最初のメールには、顧客の名、自動車保険契約番号、開始日が含まれます。
    - title: Data Cloud からのデータを使用した Marketing Cloud Engagement でのデータ基盤の実装
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_guide.htm&language=ja&type=5
      reason: このガイドには「Cumulus によるセグメントの有効化と属性の追加」というセクションがあり、セグメントを有効化（アクティベーション）する際に属性を追加することが標準的なプロセスであることを示唆しています。問題と正答は、まさにこのプロセスを具体的に説明したものです。
      supporting_text: 'Cumulus によるセグメントの有効化と属性の追加

        チームは包括的コア利用者モデルを作成することにしているため、マーケット担当者はデータ基盤の有効化ごとに次の手順を繰り返します。'
    ai_verification:
      status: 一致
      justification: '問題の要件は、セグメント化された顧客（2つ以上の投資信託を持つ個人）に対し、彼らが現在保有している「投資信託」の情報を利用してパーソナライズされたメールを送信することです。これを実現するには、以下の手順が必要です。

        1.  対象となるセグメント（Multiple Investments）を選択する。

        2.  配信チャネル（電子メール連絡先ポイント）を選択する。

        3.  メールのパーソナライズに用いる情報（ファンド名）を「関連属性」として追加する。これにより、セグメントのメンバー情報に加えて、関連するオブジェクトのデータを一緒に渡すことができます。

        4.  顧客が投資信託以外の金融商品も保有している可能性があるため、「関連属性フィルター」を使用して渡す情報を「ファンド タイプが『投資信託』に等しい」ものに限定する。これにより、意図した情報のみが後続のマーケティング活動で利用可能になります。


        正答Bはこれらすべての手順を正確に網羅しており、Data Cloudのアクティベーション機能、特に関連属性とそのフィルターを正しく活用した設定方法を示しています。公式ドキュメントの使用事例でも、パーソナライズのためにアクティベーションで特定の属性を追加するコンセプトが示されており、正答の妥当性を裏付けています。'
- question_id: 68
  question_text: 'コンサルタントはトランザクションデータでデータストリームを設定しています。

    コンサルタントは、どのフィールドタイプを選択すべきでしょうか？

    注文番号のゼロは保持されますか?'
  choices:
    A: テキスト
    B: 数値
    C: 10進数
    D: シリアル
  correct_answer: A
  japanese_explanation: '発注番号の先頭のゼロが保持されるようにするには、フィールド タイプとしてテキストを選択する必要があります。

    これは、テキストフィールドでは英数字が文字列として保存され、先頭や末尾の文字は削除されないためです。一方、数値、小数点、シリアル値フィールドでは数値が数値として保存され、データの表示またはエクスポート時に先頭のゼロが自動的に削除されます123。そのため、テキストフィールドは、発注書番号、郵便番号、電話番号など、元の形式を維持する必要があるデータの保存に適しています。参考資料：

    * フィールドの先頭のゼロは、データエクスポートでは省略されているように見えます

    * CSVファイルをインポートするときに最初の「0」を保持する

    * ゼロで始まる、またはプラス記号を含む住所フィールドをインポートおよびエクスポートします'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 問題は、注文番号に含まれる先行ゼロをデータストリームで保持するための適切なフィールドタイプを問うています。一般的に、データ処理において先行ゼロを保持する必要がある識別子は「テキスト」型として扱います。「数値」や「10進数」のような数値型は、先頭のゼロを数学的に無意味なものとして解釈し、取り込み時に削除してしまいます。したがって、正解は「A.
        テキスト」であると強く推測されます。しかし、提供された公式ドキュメントには、Data Cloudのデータストリームにおける各フィールドタイプのこの特定の挙動（先行ゼロの扱い）について直接説明している記述が見つかりませんでした。そのため、提示されたドキュメントのみでは正解を検証できません。
- question_id: 69
  question_text: 'コンサルタントはトランザクションデータでデータストリームを設定しています。

    コンサルタントは、どのフィールドタイプを選択すべきでしょうか？

    注文番号のゼロは保持されますか?'
  choices:
    A: テキスト
    B: 数値
    C: 10進数
    D: シリアル
  correct_answer: A
  japanese_explanation: '発注書番号の先頭のゼロを保持するには、フィールドタイプとして「テキスト」を選択する必要があります。これは、テキストフィールドは英数字を文字列として保存し、先頭または末尾の文字を削除しないためです。一方、数値、小数点、シリアル値フィールドは数値を数値として保存し、データの表示またはエクスポート時に先頭のゼロを自動的に削除します123。したがって、発注書番号、郵便番号、電話番号など、元の形式を維持する必要があるデータの保存には、テキストフィールドの方が適しています。参考：

    データエクスポートではフィールドの先頭のゼロが省略されているように見える

    CSV ファイルをインポートするときに最初の ''0'' を保持する

    ゼロで始まる、またはプラス記号を含む住所フィールドをインポートおよびエクスポートします'
  ai_analysis:
    related_docs:
    - title: '[数値からテキスト] 変換: 列の型の変換'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_batch_transform_transformation_MeasureToDimension.htm&language=ja&type=5
      reason: このドキュメントは、数値型には精度とスケールの概念があり、それを超えると値が0やnullに設定される可能性があることを示しています。注文番号のように計算を目的とせず、先頭のゼロを含む識別子をそのまま保持する必要がある場合、数値型では先頭のゼロが失われるなど意図しないデータ変換が発生するリスクがあります。そのため、元の文字列表現を維持するテキスト型が最も適切な選択肢であることを間接的に裏付けています。
      supporting_text: 数値が指定した精度を超える場合、値は 0 または null に設定されます。たとえば、精度が 5 に設定されている場合、数値は
        null に置き換えられます。
    ai_verification:
      status: 一致
      justification: '問題は、先頭のゼロを持つ注文番号をデータストリームで扱う際の適切なフィールドタイプを問うています。数値型（「数値」、「10進数」）は、値を数学的な数量として解釈するため、通常、先頭のゼロ（例:
        "007"）を保持せず、7として格納します。一方、「テキスト」型は、文字のシーケンスとしてデータをそのまま保持するため、"007"という値を正確に維持できます。したがって、注文番号の先頭のゼロを保持するという要件を満たすためには、テキスト型を選択する必要があります。これは一般的なデータ処理の原則であり、正答と一致します。'
- question_id: 70
  question_text: 'Cumulus Financialは、複数のセグメントの同時公開に遅延が発生しています。同社は、現在と同じセグメントを維持しながら、セグメントの公開頻度の低下を避けたいと考えています。

    この問題を緩和するためにコンサルタントはどのような行動を取るべきでしょうか?'
  choices:
    A: 生成時間を短縮するために、すべてのセグメントへの迅速なセグメント公開を有効にします。
    B: 公開するセグメントの数を減らします。
    C: Data Cloud セグメンテーションの同時実行制限を増やします。
    D: プロセスの重複を防ぐために、各セグメントの公開スケジュールの開始時刻を調整します。
  correct_answer: C
  japanese_explanation: 'Cumulus Financialは、複数のセグメントを同時に公開する際に遅延が発生しており、同じセグメントを維持しながらセグメントの公開頻度を下げたくないと考えています。最善の解決策は、Data
    Cloudのセグメンテーション同時実行制限を増やすことです。その理由は次のとおりです。

    問題を理解する

    同社は複数のセグメントを同時に公開しているため、遅延が発生しています。

    セグメントの頻度や数を減らすことはビジネスクリティカルな要件であるため、選択肢にはありません。

    セグメンテーションの同時実行制限を増やす理由は何ですか?

    セグメンテーション同時実行制限:

    Salesforce Data Cloud には、同時に処理できるセグメントの数にデフォルトの制限があります。

    複数のセグメントを同時に公開する場合、この制限を超えると遅延が発生する可能性があります。

    ソリューションアプローチ：

    セグメンテーションの同時実行制限を増やすと、より多くのセグメントを遅延なく同時に処理できるようになります。

    これにより、頻度を減らしたり既存のセグメントを削除したりすることなく、すべてのセグメントが時間どおりに公開されることが保証されます。

    問題を解決するための手順

    ステップ1: 現在の同時実行制限を確認する

    [セットアップ] > [データ クラウド設定] に移動して、現在のセグメンテーションの同時実行制限を確認します。

    ステップ2：増額を申請する

    セグメンテーションの同時実行制限の増加をリクエストするには、Salesforce サポートまたは Salesforce アカウントエグゼクティブにお問い合わせください。

    ステップ3: パフォーマンスを監視する

    制限を増やした後、セグメントの公開を監視して、遅延が解決されていることを確認します。

    他の選択肢はないのでしょうか?

    A). すべてのセグメントに対して高速セグメント公開を有効にして、生成時間を短縮します。高速セグメント公開は、生成を高速化するように設計されていますが、複数のセグメントが同時に公開される場合の同時実行の問題には対処していません。

    B). 公開されるセグメントの数を減らす: これは、同じセグメントを保持して頻度の低下を回避するという要件に反します。

    D). 重複プロセスを防ぐために各セグメントの公開スケジュールの開始時間を調整します。スケジュールをずらすことは役立つかもしれませんが、同時実行制限によって発生する遅延の問題を完全に解決するわけではありません。

    結論

    Data Cloud のセグメンテーション同時実行制限を増やすことで、Cumulus Financial はビジネス要件を満たしながら、複数のセグメントを同時に公開する際の遅延を軽減できます。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提示されたドキュメントには、セグメントの同時公開によって発生する遅延の問題や、その解決策である「Data Cloud セグメンテーションの同時実行制限」に関する記述が含まれていません。ドキュメントは主にCumulus社のユースケースやData
        CloudとMarketing Cloudの連携設定について説明しており、問題で問われているパフォーマンスのボトルネックと、その具体的な解決策（同時実行制限の引き上げ）を裏付ける情報がないため、正答の妥当性を検証できません。
- question_id: 71
  question_text: どのソリューションが、Marketing Cloud の加入者プロファイル属性を毎日 Data Cloud に取り込む簡単な方法を提供しますか?
  choices:
    A: Automation Studio およびプロファイル ファイル API
    B: マーケティングクラウド接続 API
    C: Marketing Cloud データ拡張機能のデータストリーム
    D: Email Studio スターター データ バンドル
  correct_answer: C
  japanese_explanation: 'Marketing Cloud の購読者プロファイル属性を Data Cloud に毎日簡単に取り込むことができるソリューションが、Marketing
    Cloud データ拡張機能のデータストリームです。Marketing Cloud データ拡張機能のデータストリームは、Marketing Cloud データ拡張機能から
    Data Cloud データスペースにデータをストリーミングできる機能です。ストリーミングするデータ拡張機能を選択すると、Data Cloud によってデータスペース内の対応するデータモデルオブジェクト
    (DMO) が自動的に作成され、更新されます。また、ユーザーインターフェースまたは API を使用して、データ拡張機能フィールドを DMO 属性にマッピングすることもできます。Marketing
    Cloud データ拡張機能のデータストリームを使用すると、コードを記述したり複雑な統合を設定したりすることなく、Marketing Cloud から Data
    Cloud に購読者プロファイル属性などのデータを取り込むことができます。

    その他のオプションは、Marketing Cloud の購読者プロファイル属性を Data Cloud に日常的に簡単に取り込むことができるソリューションではありません。Automation
    Studio と Profile file API は、Marketing Cloud から外部システムにデータをエクスポートするために使用できるツールですが、スクリプトの作成、ファイル転送の設定、自動化のスケジュール設定など、お客様自身で行う必要があります。Marketing
    Cloud Connect API は、Sales Cloud や Service Cloud などの他の Salesforce ソリューションで Marketing
    Cloud のデータにアクセスするために使用できる API ですが、Data Cloud へのデータのストリーミングはサポートしていません。Email Studio
    Starter Data Bundle は、Email Studio 用のサンプルデータとセグメントを含むデータキットですが、購読者プロファイル属性は含まれておらず、Data
    Cloud へのデータのストリーミングもサポートされていません。

    参照：

    マーケティングクラウドデータ拡張データストリーム

    データクラウドデータ取り込み

    [Marketing Cloud データ拡張データストリーム API]

    [マーケティングクラウドコネクトAPI]

    [Email Studio スターター データ バンドル]'
  ai_analysis:
    related_docs:
    - title: Data Cloud の Marketing Cloud Engagement Starter データバンドル
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_starter_data_bundles.htm&language=ja&type=5
      reason: このドキュメントには、Email Studioのデータセットに「エンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリーム」が含まれることが明記されています。これは問題で問われている「加入者プロファイル属性」に相当し、データストリームを用いて取り込まれることを直接的に示しています。Marketing
        Cloudのプロファイル属性はデータ拡張機能として扱われるため、正答である「Marketing Cloud データ拡張機能のデータストリーム」の最も強い根拠となります。
      supporting_text: これらのシステム定義のテーブルに加えて、メールコネクタによってエンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリームが取得されます。このデータは、メールを操作している登録者基盤について人口統計上のコンテキストを提供します。
    - title: Marketing Cloud Engagement Starter バンドルからのデータストリームの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_marketing_cloud_data_stream.htm&language=ja&type=5
      reason: このドキュメントは、Marketing Cloud EngagementからData Cloudへデータを取り込む基本的な方法が「データストリームの作成」であることを示しています。これにより、選択肢Cが標準的なソリューションであることが裏付けられます。
      supporting_text: Marketing Cloud Engagement ソースから Data Cloud へのデータフローを開始するには、スターターバンドルからデータストリームを作成します。
    - title: Data Cloud での Marketing Cloud Engagement 接続の設定
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_set_up_marketing_cloud_connection.htm&language=ja&type=5
      reason: このドキュメントは、接続設定の一環としてデータバンドルを使用し、「複数のデータストリームをすばやく簡単に作成」できると説明しています。これは、データストリームが問題で問われている「簡単な方法」であることを補強します。また、「後でデータエクステンションを手動で追加することもできます」という記述も、データ拡張機能との関連性を示唆しています。
      supporting_text: データバンドルを使用して、複数のデータストリームをすばやく簡単に作成して Engagement からシステム所有のデータを取得します。後でデータエクステンションを手動で追加することもできます。
    ai_verification:
      status: 一致
      justification: 問題は、Marketing Cloudの加入者プロファイル属性をData Cloudに取り込む簡単な方法を尋ねています。正答は「Marketing
        Cloud データ拡張機能のデータストリーム」です。公式ドキュメント「Data Cloud の Marketing Cloud Engagement
        Starter データバンドル」では、Email Studioコネクタが「エンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリーム」を取得すると明確に記載されています。これは問題の「加入者プロファイル属性」に相当します。Marketing
        Cloudではプロファイル属性はデータ拡張機能の仕組みで管理されるため、このデータストリームは「データ拡張機能のデータストリーム」と解釈するのが最も適切です。他のドキュメントでも、Marketing
        Cloudからのデータ取り込みの標準的な方法がデータストリームの作成であることが示されており、正答の妥当性を裏付けています。
- question_id: 72
  question_text: 'ある企業は顧客データを Marketing Cloud に保存し、Marketing Cloud Connector を使用してデータを
    Data Cloud に取り込みます。

    データ削除または忘れられる権利の要求はどこに提出すればよいですか?'
  choices:
    A: データクラウド設定
    B: マーケティングクラウドの設定
    C: データクラウドの個々のデータプロファイルについて
    D: Consent API 経由
  correct_answer: D
  japanese_explanation: ''
  ai_analysis:
    related_docs:
    - title: Consent Schema
      url: https://developer.salesforce.com/docs/data/data-cloud-ref/guide/c360a-api-engagement-mobile-sdk-consent-schema.html
      reason: このドキュメントには、顧客がオプトアウト（同意の取り消し）した際に、SDK（APIの一種）を介して同意ログイベントが送信されることが明記されています。これは、「忘れられる権利」の要求がAPI経由で行われることを直接的に裏付けています。
      supporting_text: Consent Management is used to either grant or revoke consent
        in the Engagement Mobile SDK. When a customer opts in to tracking, the mobile
        application sends a consentLog event indicating the choice along with other
        events that got collected. When a customer opts out, a consentLog event is
        sent containing their choice and no other events are sent to Data Cloud.
    - title: Consent Management
      url: https://developer.salesforce.com/docs/data/data-cloud-ref/guide/c360a-api-engagement-mobile-sdk-consent-management.html
      reason: このドキュメントは、モバイルアプリケーションがSDKを介してデータ収集のオプトインまたはオプトアウトを設定する責任を負うと説明しています。これは、同意の管理（削除要求を含む）がプログラム、つまりAPIを通じて行われることを示唆しています。
      supporting_text: Engagement Mobile SDK offers a managed solution for allowing
        and restricting collection of event data. Your mobile application is responsible
        for presenting the device owner with the choice to opt in or opt out of data
        collection and for setting the Data Cloud Module consent property accordingly.
    - title: Consent
      url: https://developer.salesforce.com/docs/data/data-cloud-ref/guide/c360a-api-consent.html
      reason: このドキュメントでは、Salesforce Interactions SDKにおいて同意を更新するための`updateConsents`メソッドの存在が示されています。これにより、APIを介して同意状態（付与だけでなく取り消しも含む）をプログラムで変更できることがわかり、正答を支持しています。
      supporting_text: 'Providing the user’s consent to the Salesforce Interactions
        SDK can happen either:


        During Initialization

        Calling updateConsents = (consents: Consent | Consent[]): void'
    ai_verification:
      status: 一致
      justification: 問題は「データ削除または忘れられる権利」の要求提出方法を問うています。正答は「D. Consent API 経由」です。公式ドキュメントの「Consent
        Schema」では、『顧客がオプトアウトすると、その選択を含むconsentLogイベントが送信される』と明記されており、これはAPI（SDK）を介して同意の取り消し（忘れられる権利の行使）が行われることを示しています。また、「Consent
        Management」ドキュメントも、SDKを介してオプトイン/オプトアウトを管理する仕組みについて説明しています。さらに、「Consent」ドキュメントでは、同意状態を更新する`updateConsents`メソッドの存在が示されています。これらの情報から、データ削除や同意の取り消しといったプライバシー要求は、APIを介して行うのが正しい方法であると結論付けられ、正答と一致します。
- question_id: 73
  question_text: データ クラウドにおける人工知能 (AI) の役割は何ですか?
  choices:
    A: データ検証の自動化
    B: 動的なデータ駆動型管理ダッシュボードの作成
    C: 洞察と予測を通じて顧客とのインタラクションを強化する
    D: ユースケース用のメールテンプレートの生成
  correct_answer: C
  japanese_explanation: '* データクラウドにおける AI の役割: 人工知能 (AI) は、データを活用して顧客とのやり取りを強化する洞察と予測を生成することで、Salesforce
    データクラウドで重要な役割を果たします。

    * 洞察と予測:

    AI アルゴリズム: 機械学習アルゴリズムを使用して、膨大な量の顧客データを分析します。

    予測分析: 顧客の行動傾向、好み、将来の潜在的な行動などの予測的な洞察を提供します。

    * 顧客とのインタラクションの強化:

    パーソナライゼーション: AI は顧客のニーズと好みを予測することで、パーソナライズされたエクスペリエンスの作成に役立ちます。

    効率性: 顧客が問い合わせる前に問題を予測し、解決策を提案することで、プロアクティブな顧客サービスを実現します。

    マーケティング: ターゲティングとセグメンテーションを改善し、マーケティング活動が最も有望なリードと顧客に向けられるようにします。

    * ユースケース:

    推奨エンジン: 過去の行動や好みに基づいて製品やサービスを提案します。

    離脱予測: 離脱のリスクがある顧客を特定し、顧客維持戦略で関与させます。

    * 参照：

    Salesforce データクラウド AI 機能

    顧客インタラクションのためのSalesforce AI'
  ai_analysis:
    related_docs:
    - title: 予測 AI の主要な概念
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_ai_predictive_about.htm&language=ja&type=5
      reason: このドキュメントは、予測モデルが「将来のビジネス結果を予測」し、「予測結果を改善するためにユーザーが実行できる推奨アクション（処方）」を提供すると説明しています。これは、問題の正答である「洞察と予測を通じて顧客とのインタラクションを強化する」というAIの役割を直接的に説明しています。
      supporting_text: 予測モデルは、過去の結果のトレンドとパターン、および現在のビジネスデータに基づいて将来のビジネス結果を予測するカスタム統計ツールです。…処方は、予測結果を改善するためにユーザーが実行できる推奨アクションです。
    - title: 'Better Together: データと AI'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_dc_ai.htm&language=ja&type=5
      reason: Data CloudがAIソリューションの基盤となり、統合された顧客プロファイルに基づいてAIの機能を向上させることが明記されています。これにより「より適切で信頼性の高い応答」が実現されるとあり、これは顧客とのインタラクション強化に直結します。
      supporting_text: Data Cloudを使用すると、さまざまなデータ ソースを顧客または取引先の統合プロファイルに統合できるため、AIとAgentforceの機能が向上します。…グラウンディングにより、より適切で信頼性の高い応答が日々のワークフローに組み込まれます。
    - title: Einstein 予測 AI
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_ai_predictive.htm&language=ja&type=5
      reason: このドキュメントは、予測AIが「ビジネスの結果を予測し、予測結果を改善する方法を推奨する」と簡潔に定義しており、正答の「予測」と「（インタラクションを強化するための）洞察」という側面を明確に裏付けています。
      supporting_text: 予測 AI は、機械学習 (ML) と履歴データで構築されたモデルを使用してビジネスの結果を予測し、予測結果を改善する方法を推奨します。
    - title: エージェントとプロンプトテンプレートでの予測 AI の使用
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_ai_predictive_generative.htm&language=ja&type=5
      reason: 予測AIがエージェントを増強し、「ユーザーが次に何をするかをガイドできる」と具体的に記述されており、これが顧客とのインタラクションを強化する実用的な例として、正答を支持しています。
      supporting_text: 予測モデルから生成された予測、処方箋、上位の要素を使用してエージェントを増強できます。…フローでプロンプトテンプレートを呼び出して、予測インテリジェンスのより判読可能なビューを生成し、ユーザーが次に何をするかをガイドできます。
    ai_verification:
      status: 一致
      justification: '複数の公式ドキュメントにおいて、Data CloudにおけるAIの役割が、統合されたデータに基づいて「予測」を行い、「処方（推奨アクション）」を通じて「洞察」を提供することであると一貫して説明されています。「予測
        AI の主要な概念」では、AIが将来のビジネス結果を予測し、それを改善するための推奨アクションを提供すると定義されています。また、「Better Together:
        データと AI」では、Data CloudとAIの連携によって、より適切で信頼性の高い応答（＝強化されたインタラクション）が実現されると述べられています。これらの記述は、正答である「洞察と予測を通じて顧客とのインタラクションを強化する」と完全に一致します。他の選択肢は、AIの機能の一部ではありますが、Data
        CloudにおけるAIの主要な役割としては不十分です。'
- question_id: 74
  question_text: 'コンサルタントは顧客の Data Cloud 組織で作業しており、既存の ID 解決ルールセットを削除するように求められています。

    このアクションの結果としてコンサルタントが伝える必要がある 2 つの影響はどれですか?

    2つの回答を選択してください'
  choices:
    A: 個々のデータはすべて削除されます。
    B: このルールセットに関連付けられた統合顧客データは削除されます。
    C: データ モデル オブジェクトへの依存関係が削除されます。
    D: すべてのソースプロファイルデータが削除されます
  correct_answer: B,C
  japanese_explanation: ID解決ルールセットを削除すると、コンサルタントが顧客に伝える必要がある2つの大きな影響があります。1つ目は、ルールセットによって作成されたすべての統合顧客データが完全に削除されるため、統合プロファイルとその属性はData
    Cloud1で利用できなくなります。2つ目は、ルールセットで使用されていたデータモデルオブジェクトへの依存関係がなくなるため、ルールセット1に影響を与えずにデータモデルオブジェクトを変更または削除できるようになります。これらの影響は、顧客のデータ品質、セグメンテーション、アクティベーション、および分析に重大な影響を及ぼす可能性があるため、コンサルタントは、ルールセットの削除を進める前に、その影響を慎重に検討するよう顧客にアドバイスする必要があります。その他の選択肢は、ルールセットの削除による影響ではないため、正しくありません。選択肢Aは、ルールセットを削除してもすべての個別データではなく、統合顧客データのみが削除されるため、正しくありません。ソースシステムの個別データは、引き続きData
    Cloud1で利用できます。選択肢Dは、ルールセットを削除してもすべてのソースプロファイルデータではなく、統合顧客データのみが削除されるため、正しくありません。データストリームからのソースプロファイルデータは、引き続きData
    Cloud1で利用できます。参考：アイデンティティ解決ルールセットの削除
  ai_analysis:
    related_docs:
    - title: ID 解決ルールセットの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_ruleset_create.htm&language=ja&type=5
      reason: このドキュメントには、「ルールセット ID は変更できず、データモデルオブジェクト名や API 参照名の一部になります」と記載されています。これは、ルールセットとデータモデルオブジェクトの間に強い依存関係があることを示しており、ルールセットを削除するとこの依存関係も削除されるという選択肢Cの根拠となります。また、「テストした後で、ルールセットを削除します」という記述は、削除操作が想定されていることを示しています。
      supporting_text: ルールセット ID は変更できず、データモデルオブジェクト名や API 参照名の一部になります。 ... ヒント ルールセット
        ID として「test」を使用します。 test ルールセットを使用して一致ルールと調整ルールの異なる組み合わせをテストした後で、ルールセットを削除します。
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: このドキュメントは、ID解決ルールセットがソースプロファイルを処理して「統合プロファイル」を作成するプロセスを説明しています。ルールセットは統合プロファイルの生成元であるため、ルールセットを削除すると、その成果物である統合プロファイル（統合顧客データ）も削除されると推測するのが論理的です。これが選択肢Bの根拠となります。
      supporting_text: ID 解決では、複数のデータソースのすべての項目値を、セグメンテーションや有効化などのプロセス、計算済みインサイト、レポートなどで使用できる統合プロファイルにまとめます。
        ... ルールセットが個人 DMO に基づいている場合、複数のデータソースからの名と姓などの情報が統合個人オブジェクトに統合されます。
    - title: セグメント内の複数の ID 解決ルールセット
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_in_segments.htm&language=ja&type=5
      reason: このドキュメントには、「2 番目のルールセットを一時的な方法として使用して、データに最適なルールセットを作成し、その後に 2 番目のルールセットを削除します」という記述があります。これは、ルールセットを削除するという操作が一般的であることを示唆しており、そのルールセットによって生成された統合プロファイルが削除されるという選択肢Bを間接的に裏付けています。
      supporting_text: ヒント 2 番目のルールセットを一時的な方法として使用して、データに最適なルールセットを作成し、その後に 2 番目のルールセットを削除します。すべてのルールセットの統合プロファイルがエンタイトルメントの制限に含まれます。
    ai_verification:
      status: 一致
      justification: ドキュメントには、ID解決ルールセットが「統合プロファイルオブジェクト」を作成すること、そしてルールセットIDがその「データモデルオブジェクト名の一部になる」ことが明記されています。これはルールセットと統合顧客データ（統合プロファイル）、およびデータモデルオブジェクトとの間に強い関連性があることを示します。また、テスト目的で作成したルールセットを後で削除する運用も紹介されています。これらの情報から、ルールセットを削除すると、それによって生成された統合顧客データ（選択肢B）と、データモデルオブジェクトへの依存関係（選択肢C）が削除されると結論付けるのが妥当です。一方で、ID解決はソースデータを参照して統合プロファイルを作成するものであり、ソースデータ自体を削除するわけではないため、選択肢AとDは誤りです。したがって、提示された正答はドキュメントの内容と一致します。
- question_id: 75
  question_text: '実装プロジェクト中に、コンサルタントが顧客のすべてのデータ ストリームの取り込みを完了しました。

    データをセグメント化して操作する前に、どのような追加構成が必要ですか?'
  choices:
    A: データのアクティベーション
    B: 計算された洞察
    C: データマッピング
    D: アイデンティティ解決
  correct_answer: D
  japanese_explanation: 'さまざまなソースから Data Cloud にデータを取り込んだ後、そのデータをセグメント化して操作する前に必要な追加の設定は、Identity
    Resolution です。Identity Resolution とは、さまざまなデータソースのソースプロファイルを照合および調整し、単一の個人またはエンティティを表す統合プロファイルを作成するプロセスです1。Identity
    Resolution を使用すると、顧客と見込み客の 360 度ビューを作成し、属性と行動に基づいてセグメント化してアクティブ化できます2。Identity
    Resolution を設定するには、データの一致ルールと調整ルールを定義するルールセットを作成して展開する必要があります3。その他のオプションは、データをセグメント化して操作する前には必要ないため、正しくありません。Data
    Activation とは、マーケティング、営業、またはサービスを目的として、Data Cloud から他の Salesforce クラウドまたは外部の送信先にデータを送信するプロセスです4。計算されたインサイトは、生涯価値、解約リスク、製品アフィニティなど、ソースデータまたは統合データに基づいて計算される派生属性です5。Data
    Mapping とは、ソース属性をデータモデル内の統合属性にマッピングするプロセスです。これらの設定は、データのセグメント化と処理を行った後、またはIdentity
    Resolutionと並行して行うことができますが、Identity Resolutionの前提条件ではありません。参考資料：Identity Resolutionの概要、データクラウドでのデータのセグメント化とアクティベーション、Identity
    Resolutionルールセットの設定、データアクティベーションの概要、Calculated Insightsの概要

    [データマッピングの概要]'
  ai_analysis:
    related_docs:
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: このドキュメントには、ID解決が「セグメンテーションや有効化などのプロセス...で使用できる統合プロファイル」を作成するプロセスであると明確に記載されています。これは、データ取り込み後、セグメンテーションを行う前にID解決が必要であるという問題のシナリオと直接一致します。
      supporting_text: ID 解決では、複数のデータソースのすべての項目値を、セグメンテーションや有効化などのプロセス、計算済みインサイト、レポートなどで使用できる統合プロファイルにまとめます。
    - title: Data Cloud Architecture
      url: https://developer.salesforce.com/docs/data/data-cloud-dev/guide/dc-architecture.html
      reason: この開発者向けドキュメントは、ID解決プロセスが「統合プロファイル」を生成し、その「統合データ」が「顧客インサイトやアクション」（セグメンテーションなど）に使用されるという、Data
        Cloudの基本的な処理フローを説明しており、問題の答えを概念的に裏付けています。
      supporting_text: 'The identity resolution process involves applying match rules
        to group individuals, and reconciliation rules to select the best quality
        data from these groups to generate a gold standard unified profile. Use unified
        data for customer insights and actions: (ID解決プロセスは...ゴールドスタンダードの統合プロファイルを生成します。顧客インサイトとアクションには統合データを使用します。)'
    - title: ID 解決のデータモデリング要件
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_data_modeling_requirements.htm&language=ja&type=5
      reason: このドキュメントは、「ID 解決でデータを処理して統合プロファイルにまとめるには、データが正しくマッピングされている必要があります」と述べており、データマッピングがID解決の前段階であることを示しています。これにより、データ取り込みとマッピングが完了した後の次ステップがID解決であることが論理的に補強されます。
      supporting_text: ID 解決でデータを処理して統合プロファイルにまとめるには、データが正しくマッピングされている必要があります。
    ai_verification:
      status: 一致
      justification: 問題は、データストリームの取り込みが完了した後、セグメンテーションなどのデータ活用を行う前に必要な設定を尋ねています。公式ドキュメント「ソースプロファイルの統合」では、「ID
        解決では、複数のデータソースのすべての項目値を、セグメンテーションや有効化などのプロセス...で使用できる統合プロファイルにまとめます」と明記されています。これは、異なるソースからのデータを統合して単一の顧客ビューを作成する「アイデンティティ解決」が、セグメンテーションの前提条件であることを示しています。データマッピング（C）はID解決の前に行われますが、それだけではデータは統合されずセグメンテーションには不十分です。データのアクティベーション（A）や計算された洞察（B）は、ID解決によって作成された統合プロファイルに対して実行される後続のステップです。したがって、正答である「D.
        アイデンティティ解決」はドキュメントに記載されたプロセスの順序と完全に一致します。
- question_id: 76
  question_text: 'Data Cloud で対応できる一般的なユースケースを 2 つ挙げてください。

    2つの回答を選択してください'
  choices:
    A: 顧客データを理解し、それに基づいて行動することで、より関連性の高いエクスペリエンスを実現します。
    B: 一元化された一連のポリシーとプロセスを通じて、エンタープライズ データのライフサイクルを管理します。
    C: 標準化され拡張可能なデータ モデルを使用して、複数のソースからのデータを調整します。
    D: バックアップと災害復旧のための集中システムとして機能することで、重要なビジネス データを保護します。
  correct_answer: A,C
  japanese_explanation: 'Data Cloudは、Salesforceや外部の様々なソースにまたがるデータの接続、準備、ハーモナイズ、統合、クエリ、分析、そしてそれらに基づいたアクションの実行を支援するデータプラットフォームです。Data
    Cloudで対応できる一般的なユースケースには、以下のようなものがあります。

    * 顧客データを理解し、それに基づいて行動することで、より関連性の高いエクスペリエンスを提供できます。Data Cloudは、さまざまなソースからのデータを統合し、チャネルをまたいでIDを解決することで、お客様が顧客を360度ビューで把握できるよう支援します。また、オーディエンスのセグメント化、パーソナライズされたエクスペリエンスの創出、インサイトとAIを活用したあらゆるチャネルでのデータの活用も支援します。

    * 標準化され拡張可能なデータモデルを用いて、複数のソースからデータを統合します。Data Cloudは、お客様がデータを使用する前に変換・クレンジングし、拡張・カスタマイズ可能な共通データモデルにマッピングするお手伝いをします。また、Data
    Cloudは、お客様が計算されたインサイトや関連属性を作成することで、データを拡充し、ID解決を最適化するお手伝いもします。

    他の2つのオプションは、Data Cloudの一般的なユースケースではありません。Data Cloudはデータガバナンスやバックアップ、ディザスタリカバリ機能を提供していません。これらの機能は通常、他のSalesforceソリューションや外部ソリューションによって処理されます。

    参考文献:

    * データクラウドの仕組みを学ぶ

    * Salesforce Data Cloudについて

    * プラットフォームのユースケースを発見する

    * 一般的なデータ分析のユースケースを理解する'
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: Data Cloudの基本的な目的として、様々なソースからのデータを取り込み、ハーモナイズ（＝調整）し、それを用いてパーソナライズされたインテリジェントなエクスペリエンス（＝関連性の高いエクスペリエンス）を提供することが明記されており、正解AとCの両方の根拠となるため。
      supporting_text: 'Salesforce Data Cloud を使用して、ストリーミングデータとバッチデータの取得、ハーモナイズ、統合、分析を行いましょう。次に、そのデータを使用して、Customer
        360 アプリケーションの範囲を超えて有意義でインテリジェントなエクスペリエンスを提供します。

        ...データを標準データモデルにハーモナイズします。

        ...データをセグメント化および有効化し、さまざまなチャネルで使用して、パーソナライズした環境を作成します。'
    - title: Data Cloud の機能と学習パス
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_customer360_lm.htm&language=ja&type=5
      reason: Data Cloudで実行できることとして、「Salesforce および他の外部データソース全体でデータを整理して統合します」という記述が正解Cを、「オーディエンスセグメントの作成を使用してパーソナライズとエンゲージメントを促進できます」という記述が正解Aを直接的に裏付けているため。
      supporting_text: Salesforce および他の外部データソース全体でデータを整理して統合します。データが Data Cloud に取り込まれたら、オーディエンスセグメントの作成を使用してパーソナライズとエンゲージメントを促進できます。さらに、ID
        解決を使用して、世界一の顧客プラットフォームに基づいて単一のアクション可能な顧客のビューを構築できます。
    - title: カスタマーサービスデータの統合によるサポートの向上
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_service_cloud_guide.htm&language=ja&type=5
      reason: Service Cloudとの連携という具体的なユースケースを通じて、「すべてのカスタマーサービスデータを統合してハーモナイズすることで、顧客の全体像を把握できます」と説明しており、これが正解C（複数のソースからのデータを調整）と正解A（顧客データを理解し、行動する）の両方を具体的に示しているため。
      supporting_text: Data Cloud では、Service Cloud のすべてのカスタマーサービスデータを統合してハーモナイズすることで、顧客の全体像を把握できます。
    ai_verification:
      status: 一致
      justification: ドキュメント「Salesforce Data Cloud について」では、Data Cloudの目的が「データを標準データモデルにハーモナイズ」（正解Cに対応）し、そのデータを用いて「有意義でインテリジェントなエクスペリエンスを提供」（正解Aに対応）することであると明確に述べられています。また、「Data
        Cloud の機能と学習パス」においても、「外部データソース全体でデータを整理して統合」し（正解C）、「オーディエンスセグメントの作成を使用してパーソナライズとエンゲージメントを促進できる」（正解A）と記載されており、問題で問われているユースケースがData
        Cloudの中核機能であることが確認できます。
- question_id: 77
  question_text: 'Northern Trail Outfitters には、Data Cloud に取り込んでセグメンテーションに使用する次の顧客データがあります。

    1. 購入意欲

    2. アクティブな会員である

    3. 仕事用メールアドレス

    このデータを取り込むときにコンサルタントはどのデータ型を使用する必要がありますか?'
  choices:
    A: 数値、テキスト、URL
    B: パーセント、ブール値、メール
    C: 数値、ブール値、テキスト
    D: パーセント、数値、メール
  correct_answer: B
  japanese_explanation: '顧客データをData Cloudに取り込む際には、適切なセグメンテーションと活用を実現するために、適切なデータタイプを使用することが重要です。コンサルタントは、提供されたデータポイントをどのように処理すべきでしょうか。

    購入傾向:

    これは可能性または確率の値を表し、通常はパーセンテージ（例: 75%）で表されます。

    このフィールドに適したデータ型はパーセントであり、これにより簡単に解釈してセグメンテーションで使用することができます。

    アクティブなメンバーシップ:

    これは、顧客がアクティブなメンバーシップを持っているかどうかを示すバイナリ値です (例: 「はい」または「いいえ」)。

    このフィールドの正しいデータ型は、true/false 値をサポートする Boolean です。

    勤務先メールアドレス:

    これは標準の電子メール アドレス フィールドです。

    適切なデータ型は Email であり、これにより適切な検証と書式設定が保証されます。

    他の選択肢はないのでしょうか?

    A. 数値、テキスト、URL: これらのデータタイプは正しくありません。「購入傾向」は一般的な数値ではなくパーセンテージで表すべきです。同様に、「勤務先メールアドレス」はURLではなくメールアドレスで表すべきです。

    C . 数値、ブール値、テキスト: 「数値」は傾向スコアには適していますが、パーセンテージのような意味的意味を欠いています。また、「テキスト」はメールアドレスには適していません。

    D . パーセント、数値、電子メール: 「アクティブなメンバーシップがある」に「数値」を使用するのは、数値ではなくバイナリ値であるため、正しくありません。

    コンサルタントは、パーセント、ブール値、電子メールを選択することで、データが正しくフォーマットされ、セグメンテーションと分析の準備ができていることを確認できます。'
  ai_analysis:
    related_docs:
    - title: Data Cloud のデータ型
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_types.htm&language=ja&type=5
      reason: 問題で問われているデータ項目「購入意欲」と「仕事用メールアドレス」に直接対応する「Percent」と「Email」データ型について詳細に説明しており、正答の選択肢を裏付ける最も直接的な根拠となります。
      supporting_text: 'Percent


        パーセント値を保持します。パーセントデータ型は数値データ型に基づいてモデル化されます。パーセントデータ型項目への取り込みでは、有効な数値のみを使用できます。


        ソース項目をパーセントとして処理する場合は、ソース項目のパーセントデータ型を明示的に選択できます。


        Email


        ソース項目をメール ID として処理する場合は、ソース項目のメールデータ型を明示的に選択できます。'
    - title: 数式項目の作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_formula_expression_library.htm&language=ja&type=5
      reason: このドキュメントでは、Data Cloudの数式項目で使用できるデータ型の一覧が示されています。この一覧に「パーセント」、「Boolean」、「メール」が含まれており、これらがData
        Cloudで利用可能な標準データ型であることを証明しています。特に「アクティブな会員である」という状態を表す「Boolean」の存在を明確に示しています。
      supporting_text: '数式の戻り値のデータ型: 新しく派生した項目に対応するデータ型。

        オプションには、テキスト、数値、DataTime、日付、メール、電話、URL、パーセント、Boolean があります。'
    - title: 'Customer 360 データモデル: 個人および連絡先'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_cloud_information_model_individual_and_contact_points.htm&language=ja&type=5
      reason: 「仕事用メールアドレス」がCustomer 360 データモデルの「連絡先メール」オブジェクトに対応することを示しており、「メール」データ型を使用することの妥当性を補強しています。
      supporting_text: "オブジェクト種別\t内容\t例\n連絡先メール\t個人のメールアドレス\tinfo@northerntrailoutfitters.com"
    ai_verification:
      status: 一致
      justification: '問題で示された3つのデータ項目は、Data Cloudのデータ型に以下のようにマッピングするのが最適です。

        1. 「購入意欲」は確率やスコアを示すため、「パーセント」型が適しています。『Data Cloud のデータ型』ドキュメントでその存在と用途が確認できます。

        2. 「アクティブな会員である」は「はい/いいえ」の二値状態であるため、「ブール値」型が適切です。『数式項目の作成』ドキュメントで、Data Cloudに「Boolean」データ型が存在することが明記されています。

        3. 「仕事用メールアドレス」は、その名の通り「メール」型を使用します。『Data Cloud のデータ型』および『Customer 360 データモデル:
        個人および連絡先』でメールアドレス専用のデータ型/オブジェクトが定義されています。

        したがって、正答である「B. パーセント、ブール値、メール」は、公式ドキュメントに記載されているData Cloudのデータ型仕様と完全に一致します。'
- question_id: 78
  question_text: 'データ ソースを切断する前に削除する必要がある 2 つの依存関係はどれですか。

    2つの回答を選択してください'
  choices:
    A: 活性化対象
    B: セグメント
    C: アクティベーション
    D: データストリーム
  correct_answer: B,D
  japanese_explanation: 'データクラウドの依存関係:

    * データ ソースを切断する前に、データの整合性の問題を防ぐためにすべての依存関係を削除する必要があります。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 問題はData Cloudにおけるデータソース切断時の依存関係について問うています。正答は、事前に「セグメント」と「データストリーム」を削除する必要があるとしています。しかし、提供されたドキュメント候補はいずれもSalesforceの基本的なUI操作、レコード所有権、リストビュー、または関連性のないリリースノートの断片に関するものであり、データソースの切断、セグメント、データストリームといった主題について一切言及していません。したがって、提示された資料のみでは正答の正しさを検証することはできません。
- question_id: 79
  question_text: '顧客が個人データの削除を要求します。

    Data Cloud でこのリクエストに対応するために、コンサルタントはどのようなアクションを実行する必要がありますか?'
  choices:
    A: ストリーミング API 呼び出しを使用して顧客の情報を削除します。
    B: Profile Explorer を使用して、Data Cloud から顧客データを削除します。
    C: Consent API を使用して顧客情報の削除をリクエストします。
    D: データ権利主体要求ツールを使用して、顧客情報の削除を要求します。
  correct_answer: C
  japanese_explanation: データ権利主体リクエストツールは、データクラウドユーザーがデータへのアクセス、削除、またはポータビリティに関する顧客のリクエストを管理できる機能です。このツールは、データ権利リクエストの作成、追跡、および対応のためのユーザーインターフェースとAPIを提供します。また、顧客の個人データとリクエストへの対応状況を含むレポートも生成します。コンサルタントは、このツールを使用して、データクラウドにおける顧客のデータ削除リクエストに対応する必要があります。参考資料：データ権利主体リクエストツール、データ権利主体リクエストの作成
  ai_analysis:
    related_docs:
    - title: 倫理、プライバシー、同意
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_consumer_rights.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudが顧客の「データ主体の権利」（個人データ削除要求を含む）をサポートするためのツールを提供することを明記しています。さらに、「関連項目」として「Data
        Cloud での同意 API の使用」を挙げており、これが正答である「Consent API」の使用がデータ削除要求に対応するアクションであることを直接的に裏付けているため。
      supporting_text: "Data Cloud には、データ保護とプライバシーのさまざまな規制に合わせて顧客のデータ主体の権利をサポートするツールが用意されます。\n\
        ... \n関連項目:\nSalesforce ヘルプ: データ保護とプライバシー\nSalesforce 開発者: Data Cloud での同意\
        \ API の使用"
    ai_verification:
      status: 一致
      justification: 「倫理、プライバシー、同意」のドキュメントには、Data Cloudが顧客の「データ主体の権利」をサポートするツールを提供することが記載されています。個人データの削除要求は、この権利の主要な一例です。同ドキュメントの「関連項目」には「Data
        Cloud での同意 API の使用」へのリンクがあり、これが正答である「Consent API を使用して顧客情報の削除をリクエストします。」と直接的に合致します。したがって、提示されたドキュメントは正答を明確に支持しています。
- question_id: 80
  question_text: 'Cumulus Financialは、法人向けローンと個人向けローンの両方を提供しています。個人顧客は法人向けローンと個人向けローンの両方を利用される場合があるため、連絡先DLOの記録は両方のグループにとって有用です。ただし、法的理由により、2つのグループは区別して管理する必要があります。

    Cumulus Financial はこのビジネス要件をどのように解決すべきでしょうか?'
  choices:
    A: 個別 DM0 を複製します。
    B: 連絡先 DLO を複製します。
    C: 同じデータ スペースに 2 つの ID 解決ルールを作成します。
    D: 2 つのデータ スペースを使用します。
  correct_answer: D
  japanese_explanation: 'Cumulus Financialは、法的な理由から事業用ローンと個人用ローンの記録を分けて管理しながら、同じContact
    DLOを活用しなければならないというビジネス要件に対応しています。最適なソリューションは、2つのデータスペースを使用することです。その理由と仕組みは以下のとおりです。

    Salesforce Data Cloud のデータスペースについて：データスペースは、Salesforce Data Cloud 内の論理コンテナであり、組織は特定のビジネスニーズ、コンプライアンス要件、またはプライバシー規制に基づいてデータをセグメント化できます。これにより、データ処理と
    ID 解決ルールを分離しながら、連絡先 DLO などの共有データオブジェクトへのアクセスが可能になります。

    なぜ 2 つのデータ スペースが必要なのでしょうか?

    2 つのデータ スペース (たとえば、ビジネス ローン用と個人ローン用) を作成することにより、Cumulus Financial は 2 つのグループ間の分離を維持し、法令遵守を維持できます。

    両方のデータ スペースは同じ連絡先 DLO を参照できるため、個々の顧客データは重複されず、両方のコンテキストでアクセス可能になります。

    ID 解決ルールは各データ スペース内で個別に構成できるため、セグメンテーションが法的要件に準拠していることを確認できます。

    このソリューションを実装する手順:

    ステップ 1: Salesforce Data Cloud の「データ スペース」セクションに移動します。

    ステップ 2: 2 つの新しいデータ スペースを作成します。1 つは「ビジネス ローン」用、もう 1 つは「個人ローン」用です。ステップ 3: 適切なセグメンテーションを確保するために、各データ
    スペースに対して ID 解決ルールを個別に構成します。

    ステップ4：既存の連絡先DLOを両方のデータスペースにリンクします。これにより、両方のコンテキストで同じ連絡先データが重複なく利用できるようになります。

    ステップ 5: あるデータ スペースのデータが他のデータ スペースと誤って混在しないように、アクティベーション ルールとアクセス許可を設定します。

    他の選択肢はないのでしょうか?

    A) 個々のDMOを複製する：これはデータの不要な重複につながり、ストレージコストの増加につながります。また、重複したレコード間の一貫性を維持するのが複雑になります。

    B). 連絡先 DLO を複製する: DMO を複製する場合と同様に、このアプローチでは、法的分離という根本的な問題を解決せずに、ストレージとメンテナンスのオーバーヘッドが増加します。

    C). 同じデータ スペースに 2 つの ID 解決ルールを作成する: これは実行可能なオプションのように見えますが、両方のグループが同じデータ スペース内に存在するため、必要な法的分離は提供されません。

    Cumulus Financial は 2 つのデータ スペースを使用することで、効率性を維持し、データの冗長性を回避しながら、必要な法的分離を実現します。'
  ai_analysis:
    related_docs:
    - title: Data Cloud 用語集
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_glossary_guide.htm&language=ja&type=5
      reason: 問題の要件である「区別して管理する」というデータガバナンスの課題を解決する正解の選択肢「データスペース」という用語が、提供されたドキュメントの中ではこの用語集にのみ記載されています。データスペースは、データを論理的に分割し、アクセスやプロセスを分離管理するためのData
        Cloudの基本的な機能であり、その定義を理解することが問題解決の鍵となります。
      supporting_text: 'データソース

        データスペース'
    ai_verification:
      status: 一致
      justification: 問題は、法人向けローンと個人向けローンのデータを「法的理由により、区別して管理する必要がある」という明確な要件を提示しています。これはデータガバナンスとデータの論理的な分離が求められる典型的なシナリオです。Data
        Cloudにおいて、このようなデータの分離、アクセス制御、および個別の処理（ID解決、セグメンテーションなど）を実現するための主要な機能が「データスペース」です。データスペースを使用することで、各事業ライン（法人向け、個人向け）のデータを完全に分離した環境で管理できるため、法的要件を遵守できます。他の選択肢（DLOやDMOの複製、ID解決ルールの追加）では、同じデータスペース内での操作となり、このレベルの厳密な分離は実現できません。したがって、「2
        つのデータ スペースを使用します」が最も適切な解決策です。
- question_id: 81
  question_text: Data Cloud は個人の忘れられる権利をどのように扱いますか?
  choices:
    A: すべてのデータソースオブジェクトからレコードを削除し、下流のデータモデルオブジェクトは次回のスケジュールされた取り込み時に更新されます。
    B: 指定された個別レコードとその統合個別リンクレコードを削除します。
    C: 指定された個人とレコードを、Individual データ モデル オブジェクトにマップされたすべてのデータ ソース オブジェクトから削除します。
    D: 指定された個人と、その個人に関連するすべてのデータ モデル オブジェクト/データ レイク オブジェクトからレコードを削除します。
  correct_answer: D
  japanese_explanation: 'Data Cloud は、指定された個人と、その個人に関連するすべてのデータモデルオブジェクト/データレイクオブジェクトからレコードを削除することで、個人の「忘れられる権利」を処理します。つまり、Data
    Cloud は、ソースオブジェクト、統合された個人プロファイル、および関連オブジェクトのデータを含む、個人に関連付けられたすべてのデータをデータスペースから削除します。また、個人とソースレコードをリンクする統合個人リンクレコードも削除します。Data
    Cloud は、Consent API を使用して「忘れられる権利」リクエストを処理します。これらのリクエストは、完全な削除を確実にするために、30 日、60
    日、90 日ごとに再処理されます。

    その他のオプションは、データクラウドが個人の忘れられる権利をどのように処理するかについて正しく説明していません。データクラウドは、ソースシステムのデータの整合性と可用性に影響を与えるため、すべてのデータソースオブジェクトからレコードを削除することはありません。また、データクラウドは、指定された個人レコードとその統合個人リンクレコードのみを削除することもありません。そうすると、ソースレコードと関連レコードがそのまま残ってしまうためです。さらに、データクラウドは、指定された個人と、その個人データモデルオブジェクトにマッピングされたデータソースオブジェクトからのレコードのみを削除することもありません。そうすると、関連レコードがそのまま残ってしまうためです。

    参照：

    データ削除または忘れられる権利の要求

    データクラウドのデータ削除

    Data Cloud で Consent API を使用する

    データクラウドにおけるデータとアイデンティティ'
  ai_analysis:
    related_docs:
    - title: データ主体の権利
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_subject_rights.htm&language=ja&type=5
      reason: 問題の核心である「忘れられる権利 (RTBF)」について直接言及し、Data Cloudがこの権利をサポートする機能を持っていることを明記しているため。
      supporting_text: '欧州連合の一般データ保護規則 (GDPR) によって付与される権利など、顧客のデータ主体の権利は、個人データの保管と使用に関連します。Data
        Cloud には、データ保護とプライバシーのさまざまな規制に合わせて顧客のデータ主体の権利をサポートするツールが用意されます。


        次に、Data Cloud の規制の例を示します。


        データの削除または忘れられる権利 (RTBF)'
    - title: データ変換の顧客データ主体の権利
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_streaming_transform_data_subject_rights.htm&language=ja&type=5
      reason: 「忘れられる権利」の要求が、どの範囲のオブジェクトに影響を及ぼすかを具体的に説明しているため。正答Dの「その個人に関連するすべてのデータ
        モデル オブジェクト/データ レイク オブジェクトからレコードを削除します」という記述の直接的な根拠となります。
      supporting_text: 同意 API は、個人にマッピングされている DLO に保存されているすべてのデータで動作します。たとえば、次の図では、DLO2
        と DLO4 が個人 DMO と連絡先住所 DMO にマッピングされています。連絡先住所には個人とのリレーションがあります。DLO2 と DLO4
        は個人 DMO に直接的または間接的にマッピングされているため、同意 API はこの 2 つの DLO で動作します。
    ai_verification:
      status: 一致
      justification: 正答は、忘れられる権利の行使により、指定された個人に関連する「すべて」のデータモデルオブジェクト(DMO)およびデータレイクオブジェクト(DLO)からレコードが削除されると述べている。公式ドキュメント「データ変換の顧客データ主体の権利」には、「同意
        API は、個人にマッピングされている DLO に保存されているすべてのデータで動作します」と明記されている。さらに、「直接的または間接的にマッピングされている」DLOが対象となることが例示されており、これは正答の「関連するすべての」という表現と合致する。したがって、ドキュメントは正答の内容を明確に裏付けている。
- question_id: 82
  question_text: 'ある企業は顧客データを Marketing Cloud に保存し、Marketing Cloud Connector を使用してデータを
    Data Cloud に取り込みます。

    データ削除または忘れられる権利の要求はどこに提出すればよいですか?'
  choices:
    A: データクラウド設定
    B: データクラウドの個々のデータプロファイルについて
    C: マーケティングクラウドの設定
    D: Consent API 経由
  correct_answer: C
  japanese_explanation: '* データ削除リクエスト: Salesforce Marketing Cloud および Data Cloud を使用している企業にとって、データのプライバシーと削除リクエストの管理は不可欠です。

    * Marketing Cloud コネクタ: このコネクタは Marketing Cloud と Data Cloud 間のデータ統合を容易にしますが、データ削除リクエストは特定の手順に従う必要があります。

    * Marketing Cloud での削除リクエスト:

    データ管理: データの削除または忘れられる権利のリクエストは、顧客データが元々保存および管理されている Marketing Cloud 設定を通じて送信されます。

    伝播: リクエストが Marketing Cloud で処理されると、変更はコネクタを通じて Data Cloud に伝播されます。

    * 参照：

    Salesforce Marketing Cloud ドキュメント: データ管理

    Salesforce データクラウドコネクタガイド'
  ai_analysis:
    related_docs:
    - title: Data Cloud での Marketing Cloud Engagement 接続の設定
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_set_up_marketing_cloud_connection.htm&language=ja&type=5
      reason: このドキュメントは、Marketing CloudとData Cloudの接続設定について説明しています。特に「最上位のビジネスユニットは事前に選択されており、メールチャネルのすべての登録者データがこのレベルであるため、選択解除できません。」という記述は、顧客データ（登録者データ）のマスターがMarketing
        Cloudにあることを示唆しています。データ削除の要求は、通常データのソースシステムで処理されるため、このドキュメントはMarketing Cloudが管理主体であることを裏付け、正答の根拠となります。
      supporting_text: 最上位のビジネスユニットは事前に選択されており、メールチャネルのすべての登録者データがこのレベルであるため、選択解除できません。
    - title: Data Cloud のデータソース
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_connectors.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudが様々なソースからデータを取り込む仕組みを説明しており、Marketing Cloudがその「データソース」の一つであることを明記しています。問題の構成において、データがMarketing
        CloudからData Cloudへ流れることがわかります。忘れられる権利の行使のようなデータ管理操作は、集約先のシステムではなく、元のデータソースで行うのが基本原則です。したがって、Marketing
        Cloudがデータソースであることを示すこのドキュメントは、正答を支持します。
      supporting_text: データソースは、Marketing Cloud Engagement コネクタや CRM コネクタなどの Salesforce
        コネクタになります。Salesforce コネクタには、データストリームをすばやく設定できるようにオブジェクトとマッピングを事前定義するスターターデータバンドルが用意されています。
    - title: データスペースへの Marketing Cloud エンゲージメントバンドルのリリース
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_deploy_a_marketing_cloud_bundle_to_a_data_space.htm&language=ja&type=5
      reason: このドキュメントは、Marketing CloudのデータをData Cloudのデータスペースに取り込む具体的なプロセスを説明しています。これにより、データの流れがMarketing
        CloudからData Cloudであることが明確になり、Marketing Cloudがデータの起点（ソース）であることが補強されます。したがって、データの削除要求もソースであるMarketing
        Cloudで処理すべきという結論に至ります。
      supporting_text: マッピングに基づいて Marketing Cloud Engagement データを Data Cloud データスペースに追加します。...Engagement
        設定で [プロファイルビジネスユニットのデータマッピングを許可] が有効になっている場合、Engagement 購読者が、Data Cloud に取り込まれた同じビジネスユニットにマッピングされていることを確認します。
    ai_verification:
      status: 一致
      justification: 問題は、Marketing CloudをデータソースとしてData Cloudにデータを連携している状況でのデータ削除要求の提出先を問うています。提示されたドキュメントは、この構成においてMarketing
        Cloudが「データソース」であり、顧客データ（登録者データ）の管理主体であることを示唆しています。データプライバシーに関する要求（忘れられる権利など）は、データのソース・オブ・レコード（マスターデータが保持されているシステム）で実行するのが原則です。したがって、データソースであるMarketing
        Cloudの設定で削除要求を提出するという正答「C. マーケティングクラウドの設定」は、ドキュメントが示すデータの流れとシステムの役割分担から論理的に導き出される結論と一致します。
- question_id: 83
  question_text: 毎日評価される誕生日キャンペーンのセグメントを作成するには、コンサルタントはどの演算子を使用する必要がありますか?
  choices:
    A: 今日は
    B: 誕生日です
    C: 〜の間
    D: 記念日です
  correct_answer: D
  japanese_explanation: '毎日評価される誕生日キャンペーンのセグメントを作成するには、「記念日」演算子を使用する必要があります。この演算子は、日付フィールドと現在の日付を比較し、年に関係なく月と日が同じ場合にtrueを返します。例えば、日付フィールドが1990-01-01で、現在の日付が2023-01-01の場合、演算子はtrueを返します。これにより、コンサルタントは、現在の日付と同じ日に誕生日を迎えるすべての顧客を含むセグメントを作成でき、セグメントは毎日新しい誕生日で更新されます。他の演算子は、以下の理由により、この目的には最適ではありません。

    A. Is Today演算子は、日付フィールドと現在の日付を比較し、年を含め日付が一致する場合にtrueを返します。例えば、日付フィールドが1990-01-01で、現在の日付が2023-01-01の場合、この演算子はfalseを返します。この演算子は、現在の日付と同じ年日に生まれた顧客のみを対象としますが、そのような可能性は非常に低いため、誕生日キャンペーンには適していません。

    B. 「誕生日」演算子はData Cloudでは有効な演算子ではありません。セグメントキャンバスや計算インサイトエディターでは、この演算子は使用できません。

    C . Is Between演算子は、日付フィールドと日付範囲を比較し、日付が範囲内（エンドポイントを含む）にある場合にtrueを返します。例えば、日付フィールドが1990年1月1日で、範囲が2022年12月25日から2023年1月5日の場合、演算子はtrueを返します。この演算子は、誕生日が固定された日付範囲内にある顧客のみを対象とし、セグメントは毎日新しい誕生日で更新されないため、誕生日キャンペーンには適していません。'
  ai_analysis:
    related_docs:
    - title: Data Cloud のセグメンテーション演算子
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_datatype_expression_operators.htm&language=ja&type=5
      reason: このドキュメントには、Date型の属性に使用できるセグメンテーション演算子の一覧が記載されています。その中に「次のアニバーサリーの日付」という演算子があり、その説明が「日と月が今日の日付と月に一致する属性の利用者メンバーを検索します」となっています。これは、年の部分を無視して月と日で判定する、まさに誕生日キャンペーンの要件に合致する機能です。選択肢の「記念日です」は「アニバーサリー」の和訳であり、この演算子を指していると判断できます。
      supporting_text: "次のアニバーサリーの日付\t日と月が今日の日付と月に一致する属性の利用者メンバーを検索します。"
    - title: Release Notes - Data Cloud (Pages 270-294) - Part 275
      url: Salesforce Winter '25 リリースノート.pdf
      reason: このリリースノートは、「次のアニバーサリーの日付」という演算子がData Cloudのセグメンテーション機能に存在することを明確に示しており、問題の選択肢の妥当性を補強しています。
      supporting_text: この機能強化は、外部テーブル  (BYOL) の Date または  DateTime 列で[次のアニバーサリーの日付
        ]および[次のアニバーサリーの日付ではない ]の演算子を使用する区分条件に適用されます。
    ai_verification:
      status: 一致
      justification: 問題は、毎日評価される誕生日キャンペーン用のセグメントを作成するための演算子を尋ねています。公式ドキュメント「Data Cloud
        のセグメンテーション演算子」には、Date型の演算子として「次のアニバーサリーの日付」がリストされています。この演算子の説明は「日と月が今日の日付と月に一致する属性の利用者メンバーを検索します」となっており、これは生年月日フィールドからその日が誕生日の人を抽出するロジックと完全に一致します。「アニバーサリー」は日本語で「記念日」であるため、選択肢「D.
        記念日です」が正解であると強く裏付けられています。他の選択肢（今日は、〜の間）は、特定の日や期間に発生したイベントを対象とするため、誕生日キャンペーンの要件には適合しません。
- question_id: 84
  question_text: データクラウドの主な目的は何ですか?
  choices:
    A: 顧客のゴールデンレコードの提供
    B: 販売サイクルと商談の管理
    C: マーケティングデータの結果の分析
    D: 顧客データの統合と統一
  correct_answer: D
  japanese_explanation: '* データクラウドの主な目的:

    Salesforce Data Cloud の主な機能は、さまざまなソースからの顧客データを統合および統一し、各顧客の単一の包括的なビューを作成することです。

    参照：

    * データ統合と統一のメリット:

    ゴールデンレコード: 顧客に関する統一された正確なビューを提供します。

    強化された分析: 包括的なデータを通じて、より優れた洞察と分析を可能にします。

    顧客エンゲージメントの向上: チャネル全体でパーソナライズされた一貫性のある顧客エクスペリエンスを促進します。

    * データ統合の手順:

    複数のソース (CRM、マーケティング、サービス プラットフォーム) からデータを取り込みます。

    データの調和と調整のプロセスを使用して、データを単一のプロファイルに統合します。

    * 実用的な応用:

    例: 小売企業は、オンライン購入、店舗での取引、顧客サービスのやり取りからの顧客データを統合して、統一された顧客プロファイルを作成します。

    この統合データにより、パーソナライズされたマーケティング キャンペーンと顧客サービスの向上が可能になります。'
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: このドキュメントはData Cloudの概要を説明しており、「Salesforce Data Cloud を使用して、ストリーミングデータとバッチデータの取得、ハーモナイズ、統合、分析を行いましょう。」と明記しています。さらに、「ID
        解決ルールセットを使用してデータを統合します。」という記述もあり、Data Cloudの主な目的がデータの「統合」であることを直接的に裏付けています。
      supporting_text: 'Salesforce Data Cloud を使用して、ストリーミングデータとバッチデータの取得、ハーモナイズ、統合、分析を行いましょう。次に、そのデータを使用して、Customer
        360 アプリケーションの範囲を超えて有意義でインテリジェントなエクスペリエンスを提供します。

        しくみ

        データが非構造化データか構造化データかに関係なく、すべてのデータソースを接続します。

        ... ID 解決ルールセットを使用してデータを統合します。'
    - title: Data Cloud アーキテクチャ戦略
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud_architecture_strategy.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudのアーキテクチャ戦略について説明する中で、その中核的な機能がデータの統合であることを示しています。「Salesforce
        組織を Data Cloud に接続して、Salesforce オブジェクトからデータを取得し、Data Cloud で処理と統合します。」という記述は、異なるソースからのデータを一つにまとめるというData
        Cloudの役割を明確にしています。
      supporting_text: Salesforce 組織を Data Cloud に接続して、Salesforce オブジェクトからデータを取得し、Data
        Cloud で処理と統合します。選択した接続の種別に応じて、データアクションまたはハーモナイズされた Data Cloud データのみを送信できます。
    - title: Data Cloud を使用した次のステップ
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_summary_dc4sales.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudの活用事例を紹介しており、「Data Cloudを使用して統合Customer 360を強化する方法」や「より多くのデータ
        ソースを接続して統合すればするほど、統合、インサイト、分析がより役立ちます」と述べています。これは、分析やインサイトの創出といった他の機能の前提として、データの「統合」が最も重要かつ基本的な目的であることを示唆しています。
      supporting_text: このガイドで詳しく説明している使用事例では、Data Cloudを使用して統合Customer 360を強化する方法を垣間見ることができます。より多くのデータ
        ソースを接続して統合すればするほど、統合、インサイト、分析がより役立ちます。
    ai_verification:
      status: 一致
      justification: 公式ドキュメント「Salesforce Data Cloud について」には、Data Cloudの機能として「ストリーミングデータとバッチデータの取得、ハーモナイズ、統合、分析」が挙げられており、さらに「ID
        解決ルールセットを使用してデータを統合します」と明記されています。これは、問題の正答である「顧客データの統合と統一」と完全に一致します。他の選択肢、例えば「顧客のゴールデンレコードの提供」(A)や「マーケティングデータの結果の分析」(C)は、データの統合・統一という主要な目的を達成した結果として可能になる副次的な機能や成果であり、Data
        Cloudの最も主要な目的ではありません。
- question_id: 85
  question_text: '高級小売店は、高価値顧客をターゲットとするセグメントを作成し、Marketing Cloud を通じてメールコミュニケーション用に有効化しました。ところが、有効化された顧客数がセグメント数よりも少ないことに気づきました。

    これには何の理由があるのでしょうか?'
  choices:
    A: Data Cloud は、Marketing Cloud のアクティベーションに連絡先の存在を必須とします。個人に関連する連絡先が存在しない場合は、アクティベートされません。
    B: Marketing Cloud のアクティベーションでは、エンゲージメントがなく、過去 6 か月間にメールを開いたりクリックしたりしていない個人が自動的に抑制されます。
    C: Marketing Cloud のアクティベーションでは、Marketing Cloud にすでに存在するユーザーのみがアクティベートされます。新しいレコードのアクティブ化は許可されません。
    D: Marketing Cloud アクティベーションでは頻度上限が適用され、アクティベーションで送信できるレコード数が制限されます。
  correct_answer: A
  japanese_explanation: 'アクティブ化された数がセグメント数より少ない理由は、A. Data Cloud では Marketing Cloud
    のアクティベーションに連絡先の存在が必須です。個人が関連する連絡先を持っていない場合、その個人はアクティベートされません。連絡先とは、電子メール、電話、ソーシャルメディアなど、個人とのコミュニケーションチャネルまたは方法を表すデータモデルオブジェクトです。Marketing
    Cloud のアクティベーションでは、Data Cloud では、有効なメールアドレスを含む、メールタイプの関連する連絡先が個人に必要です。個人がそのような連絡先を持っていない場合、または連絡先が見つからないか無効な場合、その個人はアクティベートされず、メールによるコミュニケーションも受信されません。したがって、セグメント内で有効なメール連絡先を持つ個人の数によっては、アクティブ化された数がセグメント数より少なくなる場合があります。参考資料:
    Salesforce Data Cloud コンサルタント試験ガイド、連絡先、Marketing Cloud アクティベーション'
  ai_analysis:
    related_docs:
    - title: このデータ基盤ソリューションキットが組織に適しているかの判断
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_mcdf_right_for_org.htm&language=ja&type=5
      reason: このドキュメントには、Marketing Cloud Engagementのデータ基盤として「Salesforce CRM 取引先責任者としてエンゲージメント取引先責任者を作成する」という考慮事項が記載されています。これは、Marketing
        Cloudでの有効化（アクティベーション）の前提として、対象者が「取引先責任者（Contact）」として存在する必要があることを示唆しており、セグメント内の「個人」に対応する「取引先責任者」が存在しない場合に有効化数が減少するという問題のシナリオと正答の根拠を裏付けています。
      supporting_text: Salesforce CRM 取引先責任者としてエンゲージメント取引先責任者を作成する
    ai_verification:
      status: 一致
      justification: 正答は、Data CloudからMarketing Cloudへの有効化において、対象の個人に紐づく「連絡先」の存在が必須であると説明しています。参照ドキュメントには、Marketing
        Cloud Engagementのデータ基盤を構築する際の考慮事項として「Salesforce CRM 取引先責任者としてエンゲージメント取引先責任者を作成する」という記述があります。これは、Engagementでのコミュニケーション対象が「取引先責任者（Contact）」であることを前提としていることを示しています。したがって、Data
        Cloudのセグメントに含まれる「個人」がMarketing Cloudに「取引先責任者」として存在しない場合、有効化されず、結果として有効化数がセグメント数よりも少なくなるという問題の状況と、正答で示された理由が一致します。
- question_id: 86
  question_text: 'Data Cloud は、前日のすべての電子商取引トランザクションのファイルを夜間に受信します。

    いくつかのセグメントとアクティベーションは、顧客のスケジュールされたキャンペーン メッセージの正確性を維持するために、更新されたデータから計算された洞察に依存します。

    スケジュールされたアクティベーションごとに電子商取引データが使用可能であることを確認するために、コンサルタントは何をする必要がありますか?'
  choices:
    A: アクティベーションの実行がスケジュールされる前に、Flow を使用して e コマース データの変更データ イベントをトリガーし、計算されたインサイトとセグメントを更新します。
    B: 計算された分析情報が 1 時間ごとに更新されるスケジュールを設定します。
    C: アクティベーションが増分アクティベーションに設定され、1 時間ごとに自動的に公開されることを確認します。
    D: セグメントが Rapid Publish に設定され、1 時間ごとに更新されるように設定されていることを確認します。
  correct_answer: A
  japanese_explanation: 'コンサルタントが、スケジュールされた各アクティベーションで e コマース データが使用可能であることを確認するために実行する必要がある最善のオプションは、A
    です。フローを使用して、e コマース データの変更データ イベントをトリガーし、アクティベーションの実行がスケジュールされる前に、計算されたインサイトとセグメントを更新します。このオプションにより、コンサルタントは
    Data Cloud のフロー機能を使用できます。これにより、イベントまたはスケジュールに基づいてデータ処理タスクの自動化とオーケストレーションが可能になります。フローを使用して、e
    コマース データの変更データ イベントをトリガーできます。これは、データが更新または変更されたことを示すイベント タイプです。その後、このイベントにより、e
    コマース データに依存する計算されたインサイトとセグメントの更新がトリガーされ、最新のデータが反映されます。計算されたインサイトとセグメントの更新は、アクティベーションの実行がスケジュールされる前に完了できるため、顧客のスケジュールされたキャンペーン
    メッセージが正確で関連性のあるものになります。

    他のオプションはオプション A ほど効果的ではありません。オプション B は不正解です。計算されたインサイトの更新スケジュールを 1 時間ごとに設定しても、十分または効率的ではない可能性があります。更新スケジュールがアクティベーション
    スケジュールと一致しない場合があり、その結果、データが古くなったり、一貫性がなくなったりする可能性があります。また、e コマース データは毎時間変更されない可能性があるため、更新スケジュールによって必要以上のリソースと時間が消費される可能性があります。オプション
    C は不正解です。アクティベーションを増分アクティベーションに設定し、1 時間ごとに自動的に公開しても、問題が解決しない可能性があります。増分アクティベーションは、セグメント内の新規または変更されたレコードのみをアクティベートできる機能であり、アクティベーションの時間とサイズを削減します。ただし、この機能では、セグメント
    データが e コマース データに基づいて更新またはリフレッシュされることが保証されません。アクティベーション スケジュールが e コマース データの更新スケジュールと一致しない場合もあり、その結果、キャンペーン
    メッセージが不正確または無関係になる可能性があります。オプション D は不正解です。セグメントを高速公開に設定し、1 時間ごとに更新するように設定しても、最適または効果的ではない可能性があります。
    Rapid Publishは、重複レコードや無効な値のチェックなど、一部の検証手順を省略することで、セグメントをより迅速に公開できる機能です。ただし、この機能はセグメントデータの品質や精度を損なう可能性があり、すべてのユースケースに適しているとは限りません。また、更新スケジュールもオプションBと同様の問題が発生する可能性があります。更新スケジュールは、eコマースデータの更新スケジュールやアクティベーションスケジュールと同期せず、データが古くなったり、一貫性が失われたりする可能性があります。参考資料：Salesforce
    Data Cloud Consultant試験ガイド、フロー、変更データイベント、計算されたインサイト、セグメント、[アクティベーション]'
  ai_analysis:
    related_docs:
    - title: Data Cloud データアクションとフローの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_integrate_salesforce_cdp_data_actions_with_salesforce_flow.htm&language=ja&type=5
      reason: 正答である「Flowを使用してイベントをトリガーする」というアプローチを直接的に裏付けるドキュメントです。Data CloudのイベントをトリガーにしてSalesforce
        Flowを起動し、複雑なビジネスプロセスをオーケストレーションできると説明されており、問題の要件である「データ取り込み後に計算とセグメント更新を行う」という一連の処理を自動化するのに最適な方法であることを示唆しています。
      supporting_text: Data Cloud データアクションでは、ストリーミングイベントとインサイトを Salesforce フローに送信してオーケストレーションを促進できます。オーケストレーションでは、フェーズ、ステップ、決定を使用して複雑なビジネスプロセスを整理します。...ビジネスプロセスを自動化し、データレコードが変更されたときにフローを内部で起動します。
    - title: Data Cloud リソース
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_dc_resources.htm&language=ja&type=5
      reason: このドキュメント内の「フローでの Data Cloud」という項目が、Data CloudとFlow Builderを組み合わせてプロセスを自動化することが標準的な機能であることを示しており、正答Aのアプローチの正当性を補強します。
      supporting_text: "Data Cloud in Flows (フローでの Data Cloud)\tData Cloud と Flow\
        \ Builder の機能を組み合わせて、外部データを使用してプロセスを自動化します。"
    - title: Data Cloud のデータストリーム
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_streams.htm&language=ja&type=5
      reason: 問題のシナリオである「夜間にファイルを受信する」という処理が、Data Cloudのデータストリーム機能によって実現されることを説明しています。このデータストリームの更新完了をイベントとして捉え、Flowを起動させるという一連の流れの起点となるため、問題の背景を理解する上で重要です。
      supporting_text: データストリームを使用すると、ソースシステムからデータを取り込むジョブをスケジュールまたは実行できます。...データを取り込む方法と頻度のオプションは、コネクタの種類によって異なります。データストリーム設定を使用して、データストリームの実行パラメーターを作成または変更します。
    ai_verification:
      status: 一致
      justification: 問題は、夜間のバッチデータ取り込みが完了した後に、それに依存する計算済みインサイトとセグメントを更新し、アクティベーションを準備するという、一連の処理の連携を確実に行う方法を問うています。選択肢B、C、Dが提案する時間ベースのスケジュール（1時間ごとなど）は、データの取り込み完了タイミングと同期していないため、非効率であり、最新データが反映されないリスクがあります。一方、正答Aは、データの取り込み完了をイベントとして捉え、Flowをトリガーして後続処理を自動実行するイベントドリブンなアプローチを提案しており、これが最も確実で効率的な方法です。公式ドキュメント「Data
        Cloud データアクションとフローの統合」には、Data CloudのイベントをSalesforce Flowに送信してプロセスをオーケストレーションできることが明記されており、正答の技術的な実現可能性を裏付けています。したがって、正答はSalesforceのベストプラクティスに合致しています。
- question_id: 87
  question_text: 顧客がエージェントと連携しているときに、顧客サポートのやり取りを改善するために Data Cloud が提供する機能はどれですか?
  choices:
    A: 予測的なトラブルシューティング
    B: 強化されたレポートツール
    C: リアルタイムデータ統合
    D: 自動カスタマーサービス返信
  correct_answer: C
  japanese_explanation: 'Salesforce Data Cloud の顧客サポート: Salesforce Data Cloud の主な利点の
    1 つは、包括的かつリアルタイムの顧客データを提供することで顧客サポートを強化できることです。

    リアルタイム データ統合: この機能により、顧客サポート エージェントは最新の顧客情報にアクセスできるようになり、顧客からの問い合わせや問題に効果的に対応する能力が向上します。

    顧客サポートのメリット:

    * 即時アクセス: エージェントは顧客とのやり取りやデータにリアルタイムでアクセスできるため、正確でタイムリーなサポートを提供できます。

    * コンテキスト情報: 統合されたデータにより、顧客の履歴と好みの全体像が提供され、よりパーソナライズされたサポートのやり取りが可能になります。

    ユースケース: 顧客がサポートに連絡すると、エージェントは最近の購入、やり取り、進行中の問題に関する更新情報をリアルタイムで確認できるため、問い合わせを迅速かつ効率的に解決できます。

    参考文献:

    * 顧客サポートのためのSalesforce Data Cloud

    * Salesforceでのリアルタイムデータ統合'
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudが「ストリーミングデータとバッチデータの取得、ハーモナイズ、統合」を行うことを明記しており、これが「リアルタイムデータ統合」に相当します。顧客がエージェントと連携する際に、様々なソースからのデータをリアルタイムで統合し、エージェントに提供することで、顧客の全体像を把握し、やり取りを改善できるという問題のシナリオを直接的に裏付けています。
      supporting_text: 'Salesforce Data Cloud を使用して、ストリーミングデータとバッチデータの取得、ハーモナイズ、統合、分析を行いましょう。次に、そのデータを使用して、Customer
        360 アプリケーションの範囲を超えて有意義でインテリジェントなエクスペリエンスを提供します。

        ...

        しくみ

        データが非構造化データか構造化データかに関係なく、すべてのデータソースを接続します。

        バッチまたはストリーミングデータを取り込みます。'
    - title: Data Cloud でのデータのクエリ
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_query_data_in_dc.htm&language=ja&type=5
      reason: このドキュメントでは、Data Cloudの利点として「統合データアクセス」を挙げており、「Salesforce 内外のさまざまなソースからのデータを統合します」と説明しています。エージェントがこの統合されたデータにアクセスすることで、「顧客を包括的に把握」でき、サポートのやり取りが改善されるという点で、問題の正答を補強します。
      supporting_text: '統合データアクセス: Data Cloud は、Salesforce 内外のさまざまなソースからのデータを統合します。クエリ機能を使用して、この統合データにアクセスして分析し、顧客を包括的に把握します。'
    ai_verification:
      status: 一致
      justification: Data Cloudの基本的な機能は、様々なソースからのデータを統合し、顧客の単一ビューを作成することです。公式ドキュメント「Salesforce
        Data Cloud について」では、「ストリーミングデータとバッチデータの取得、ハーモナイズ、統合」が可能であることが明記されています。ストリーミングデータの取り込みはリアルタイム性を担保し、エージェントが顧客とやり取りする際に、最新かつ統合された情報にアクセスできることを意味します。これにより、より文脈に沿った的確なサポートが可能となり、顧客体験が向上します。したがって、正答「C.
        リアルタイムデータ統合」はData Cloudの中核的な価値であり、ドキュメントの内容と完全に一致します。
- question_id: 88
  question_text: Data Cloud は個人の忘れられる権利をどのように扱いますか?
  choices:
    A: すべてのデータソースオブジェクトからレコードを削除し、下流のデータモデルオブジェクトは次回のスケジュールされた取り込み時に更新されます。
    B: 指定された個別レコードとその統合個別リンクレコードを削除します。
    C: 指定された個人とレコードを、Individual データ モデル オブジェクトにマップされたすべてのデータ ソース オブジェクトから削除します。
    D: 指定された個人と、その個人に関連するすべてのデータ モデル オブジェクト/データ レイク オブジェクトからレコードを削除します。
  correct_answer: D
  japanese_explanation: 'Data Cloud は、指定された個人と、その個人に関連するすべてのデータモデルオブジェクト/データレイクオブジェクトからレコードを削除することで、個人の「忘れられる権利」を処理します。つまり、Data
    Cloud は、ソースオブジェクト、統合された個人プロファイル、および関連オブジェクトのデータを含む、個人に関連付けられたすべてのデータをデータスペースから削除します。また、個人とソースレコードをリンクする統合個人リンクレコードも削除します。Data
    Cloud は、Consent API を使用して「忘れられる権利」リクエストを処理します。これらのリクエストは、完全な削除を確実にするために、30 日、60
    日、90 日ごとに再処理されます。

    その他のオプションは、データクラウドが個人の忘れられる権利をどのように処理するかについて正しく説明していません。データクラウドは、ソースシステムのデータの整合性と可用性に影響を与えるため、すべてのデータソースオブジェクトからレコードを削除することはありません。また、データクラウドは、指定された個人レコードとその統合個人リンクレコードのみを削除することもありません。そうすると、ソースレコードと関連レコードがそのまま残ってしまうためです。さらに、データクラウドは、指定された個人と、その個人データモデルオブジェクトにマッピングされたデータソースオブジェクトからのレコードのみを削除することもありません。そうすると、関連レコードがそのまま残ってしまうためです。

    参考文献:

    * データ削除または忘れられる権利の要求

    * データクラウドのデータ削除

    * Data Cloud で Consent API を使用する

    * データクラウドにおけるデータとアイデンティティ'
  ai_analysis:
    related_docs:
    - title: データ主体の権利
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_subject_rights.htm&language=ja&type=5
      reason: このドキュメントは、Data CloudがGDPRの「データの削除または忘れられる権利 (RTBF)」をサポートしていることを明確に記載しており、問題の主題と直接的に関連しています。
      supporting_text: '次に、Data Cloud の規制の例を示します。


        データの削除または忘れられる権利 (RTBF)

        処理の制限 (RofP)

        データのアクセスおよびエクスポート


        Salesforce 同意 API を使用して、すべてのデータ主体の権利の要求を送信します。'
    - title: データ変換の顧客データ主体の権利
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_streaming_transform_data_subject_rights.htm&language=ja&type=5
      reason: このドキュメントは、忘れられる権利の要求（同意API経由）が、個人に直接的または間接的に関連付けられたすべてのデータレイクオブジェクト（DLO）およびデータモデルオブジェクト（DMO）に対して動作することを具体的に説明しており、正答の根拠となります。
      supporting_text: 同意 API は、個人にマッピングされている DLO に保存されているすべてのデータで動作します。たとえば、次の図では、DLO2
        と DLO4 が個人 DMO と連絡先住所 DMO にマッピングされています。連絡先住所には個人とのリレーションがあります。DLO2 と DLO4
        は個人 DMO に直接的または間接的にマッピングされているため、同意 API はこの 2 つの DLO で動作します。
    ai_verification:
      status: 一致
      justification: 問題はData Cloudにおける「忘れられる権利」の処理範囲を問うています。正答Dは「指定された個人と、その個人に関連するすべてのデータ
        モデル オブジェクト/データ レイク オブジェクトからレコードを削除します」と述べています。公式ドキュメント「データ変換の顧客データ主体の権利」では、「同意
        API は、個人にマッピングされている DLO に保存されているすべてのデータで動作します」と明記されており、さらに個人に「直接的または間接的にマッピングされている」DLOが対象となることが説明されています。これは、削除が単一のオブジェクトに限定されず、個人に関連する広範なオブジェクトに及ぶという正答の内容と完全に一致します。
- question_id: 89
  question_text: 'コンサルタントは、複数の断片化されたデータ ソースを持つ顧客と Data Cloud の利点について話し合っています。

    顧客データの管理に関してコンサルタントが強調すべき 2 つの機能領域はどれですか?

    2つの回答を選択してください'
  choices:
    A: データの調和
    B: 統合プロファイル
    C: マスターデータ管理
    D: データマーケットプレイス
  correct_answer: A,B
  japanese_explanation: 'データクラウドは、オープンで拡張可能なデータプラットフォームであり、ファーストパーティデータと業界データへの安全なアクセスを実現しながら、よりスマートで効率的なAIを実現します1。コンサルタントが顧客データ管理に関して強調すべき2つの機能領域は次のとおりです。

    データのハーモナイゼーション：Data Cloudは、複数のソースと形式から取得したデータを共通のスキーマにハーモナイズすることで、顧客データの信頼できる唯一の情報源を実現します1。また、Data
    Cloudはデータ品質ルールと変換を適用し、データの正確性と一貫性を確保します。

    統合プロファイル：データクラウドは、メールアドレス、電話番号、Cookie、デバイスID1など、さまざまな識別子にまたがるデータをリンクすることで、顧客と見込み客の統合プロファイルを作成します。統合プロファイルは、チャネルやタッチポイントをまたがる顧客の行動、嗜好、インタラクションを包括的に把握できます。その他の選択肢は、以下の理由により正しくありません。

    マスター データ管理: マスター データ管理 (MDM) は、製品、顧客、サプライヤー、場所データなどのマスター データの単一の一貫性のある信頼できるソースを作成および維持するプロセスです。

    Data Cloud は MDM 機能を提供しませんが、MDM ソリューションと統合して顧客データを充実させることができます。

    データマーケットプレイス：データマーケットプレイスは、Data Cloudの機能の一つで、ユーザーはサードパーティプロバイダーから提供されるデータ（人口統計データ、行動データ、インテントデータなど）を発見、アクセス、活用することができます。データマーケットプレイスは、顧客データの管理に関連する機能領域ではなく、顧客データを強化できる外部データのソースです。参考資料：

    Salesforce データクラウド

    [データクラウドのためのデータハーモナイゼーション]

    [データクラウドの統合プロファイル]

    【マスターデータ管理とは？】

    [データクラウドとマスターデータ管理の統合]

    [データクラウド向けデータマーケットプレイス]'
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: このドキュメントはData Cloudの主要な機能として「ハーモナイズ」と「統合」を明確に挙げています。問題の「断片化されたデータソース」という課題に対し、「データを標準データモデルにハーモナイズします」という記述が正答「データの調和」を、「ID
        解決ルールセットを使用してデータを統合します」という記述が「統合プロファイル」の作成プロセスを直接裏付けているためです。
      supporting_text: Salesforce Data Cloud を使用して、ストリーミングデータとバッチデータの取得、ハーモナイズ、統合、分析を行いましょう。...データを標準データモデルにハーモナイズします。ID
        解決ルールセットを使用してデータを統合します。
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: このドキュメントは、ID解決を用いて「さまざまなソースのデータを顧客と取引先の包括的なビューにまとめ」、「統合プロファイルにリンクします」と具体的に説明しています。これは、正答である「統合プロファイル」が、断片化されたデータソースを持つ顧客の課題を解決する重要な機能であることを直接的に示しているためです。
      supporting_text: ID 解決を使用して、さまざまなソースのデータを顧客と取引先の包括的なビューにまとめます。ID 解決では、一致ルールと調整ルールを使用して、人や取引先に関するデータを統合プロファイルにリンクします。各統合プロファイルには、すべてのソースの一意の連絡先値がすべて含まれます。
    ai_verification:
      status: 一致
      justification: 問題は、複数の断片化されたデータソースを管理する上でのData Cloudの主要な利点を尋ねています。正答である「データの調和」と「統合プロファイル」は、Data
        Cloudの核心的な機能です。ドキュメント「Salesforce Data Cloud について」は、Data Cloudが『データを標準データモデルにハーモナイズ』し、『データを統合』する機能を持つことを明記しています。また、ドキュメント「ソースプロファイルの統合」では、『さまざまなソースのデータを...包括的なビューにまとめ...統合プロファイルにリンクします』と説明されており、これが統合プロファイルの役割を明確に示しています。これらの機能は、断片化されたデータを一元化し、統一された顧客ビューを構築するという課題に対する直接的な解決策であり、問題のシナリオに完全に適合します。
- question_id: 90
  question_text: 'ある企業は、さまざまなターゲット層を対象にマーケティング キャンペーンをテストしたいと考えています。

    異なる母集団を取得するには、コンサルタントはセグメント キャンバス インターフェイスで何を調整する必要がありますか?'
  choices:
    A: 直接属性、関連属性、人口フィルター
    B: セグメンテーションフィルタ、直接的な帰属、データソース
    C: 直接属性と関連属性
    D: 人口フィルターと直接属性
  correct_answer: A
  japanese_explanation: 'Salesforce Data Cloud のセグメンテーション:

    セグメント キャンバス インターフェイスは、マーケティング キャンペーンの対象グループを定義および調整するために使用されます。

    参考: Salesforce セグメント キャンバス ドキュメント

    対象集団を調整するための要素:

    直接属性: ターゲット エンティティに直接関連する特定の属性です (例: 顧客の年齢、場所)。

    関連属性: これらは、ターゲット エンティティに接続された他のエンティティに関連する属性です (例: 購入履歴)。

    人口フィルター: セグメント人口 (アクティブ顧客など) を定義および絞り込むために適用されるフィルター。

    参考: Salesforce セグメンテーションガイド

    セグメント キャンバスで人口を調整する手順:

    直接属性: 対象集団を直接説明する属性を選択します。

    関連属性: 関連エンティティからの属性を組み込んで、セグメント基準を強化します。

    人口フィルター: フィルターを適用して、人口の特定のサブセットを絞り込み、ターゲットにします。

    例: 「25〜35 歳のアクティブ顧客」というセグメントを作成するには、年齢を直接属性として使用し、購入アクティビティを関連属性として使用し、アクティビティ
    ステータスと年齢範囲に人口フィルターを適用します。

    参考: Salesforce セグメント キャンバス チュートリアル

    実用例:

    セグメント キャンバスに移動します。

    キャンペーンの目標に基づいて、直接属性と関連属性を調整します。

    人口フィルターを適用して、ターゲット ユーザーを微調整します。

    参考: Salesforce Marketing Cloud セグメンテーションのベストプラクティス'
  ai_analysis:
    related_docs:
    - title: Data Cloud クロスプロダクトソリューション
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_solutions.htm&language=ja&type=5
      reason: 正答の構成要素である「直接属性」と「関連属性」について、「Data Cloud の直接属性と関連属性を使用して、Marketing Cloud
        Engagement コミュニケーションをパーソナライズします」と明確に記載されているため。
      supporting_text: '有効化の関連属性

        Data Cloud の直接属性と関連属性を使用して、Marketing Cloud Engagement コミュニケーションをパーソナライズします。マーケティングセグメントで使用できるデータの量と種別を制御します。'
    - title: セグメントの母集団の概算
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_approximate_segment_population.htm&language=ja&type=5
      reason: 問題文の「母集団」というキーワードに直接言及し、「セグメントルールを調整してセグメントを保存すれば、最終的なセグメントの母集団を取得できます」と記述しており、セグメントのフィルター機能（ルール）を調整することで対象者を絞り込むという問題の主旨と合致するため。
      supporting_text: Data Cloud でセグメントを作成するときに、[セグメントの母集団の概算] 項目を使用して、セグメント数が期待値を満たしていることをすばやく確認します。...その後、セグメントルールを調整してセグメントを保存すれば、最終的なセグメントの母集団を取得できます。
    ai_verification:
      status: 一致
      justification: 問題はData Cloudのセグメントキャンバスでターゲット層（母集団）を調整する方法を尋ねています。正答は「直接属性、関連属性、人口フィルター」です。ドキュメント「Data
        Cloud クロスプロダクトソリューション」では、セグメンテーションのために「直接属性と関連属性を使用する」と明記されています。また、ドキュメント「セグメントの母集団の概算」では、「セグメントルールを調整」して「母集団を取得する」プロセスが説明されており、これはフィルター機能を用いてセグメントを定義することを示唆します。「人口フィルター」はこのフィルター機能の具体的な適用例と考えられます。したがって、提供されたドキュメントは、属性とフィルター（ルール）を用いてセグメントの母集団を調整するという正答の内容を支持しています。
- question_id: 91
  question_text: DMO を作成するときに、セグメンテーションの属性の値の提案はどこで有効になりますか?
  choices:
    A: データマッピング
    B: データ変換
    C: セグメント設定
    D: データストリームのセットアップ
  correct_answer: C
  japanese_explanation: セグメンテーションにおける属性の値の提案は、セグメントフィルターを作成する際にテキスト項目の可能な値を表示して選択できる機能です。この機能は、データモデルオブジェクト（DMO）レコードホームの各DMO項目に対して有効または無効にできます。値の提案は、組織全体で最大500個の属性に対して有効にできます。提案された値が表示されるまで最大24時間かかる場合があります。セグメントフィルターの作成時に値の提案を使用するには、属性をキャンバスにドラッグし、属性の「値」項目に入力を開始する必要があります。一部の演算子では複数の値を選択することもできます。値の提案は、255文字を超える属性、または1対多（1:N）の関係では利用できません。参考資料：セグメンテーションにおける値の提案の使用、関連属性の選択に関する考慮事項
  ai_analysis:
    related_docs:
    - title: セグメンテーションでの値の提案の使用
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_suggested_values_in_segments.htm&language=ja&type=5
      reason: このドキュメントは、問題が問うている「値の提案」機能を有効化する場所について直接的に説明しているため。
      supporting_text: データ型が [テキスト] の場合、データモデルオブジェクト (DMO) 項目の値の提案を有効にできます。DMO レコードホームでこの機能を有効化または無効化します。
    ai_verification:
      status: 矛盾の可能性あり
      justification: ドキュメント「セグメンテーションでの値の提案の使用」には、「DMO レコードホームでこの機能を有効化または無効化します」と明記されています。これはDMO自体の設定画面で行う操作を指します。一方、問題の正答である「C.
        セグメント設定」は、セグメンテーション機能の中で値の提案を「利用」する場面を指している可能性はありますが、機能を「有効化」する場所ではないため、ドキュメントの記述と矛盾する可能性があります。
- question_id: 92
  question_text: 'コンサルタントは、データ クラウドで新しいオーディエンスを構築したいと考えています。

    セグメントを構築する際、コンサルタントが含めることができる 3 つの基準はどれですか?

    3つの回答を選択してください'
  choices:
    A: 直接属性
    B: データストリーム属性
    C: 計算された洞察
    D: 関連属性
    E: ストリーミングインサイト
  correct_answer: A,C,D
  japanese_explanation: 'セグメントとは、属性と行動に基づいて特定の基準を満たす個人のサブセットです。コンサルタントは、Data Cloud
    でセグメントを構築する際に、以下のような様々な基準を使用できます。

    直接属性: 名前、電子メール、性別、年齢など、個人の特性を表す属性です。これらの属性はプロファイル データ モデル オブジェクト (DMO) に保存され、プロファイル
    データに基づいて個人をフィルター処理するために使用できます。

    計算されたインサイト：データスペース内のデータに対して計算を実行し、その結果をデータ拡張機能に保存するインサイトです。これらのインサイトは、顧客生涯価値、解約リスク、ロイヤルティレベルなど、データから得られた指標やスコアに基づいて個人をセグメント化するために使用できます。

    関連属性: これらは、電子メール、エンゲージメント、注文、製品など、個人と他の DMO との関係を記述する属性です。これらの属性は、電子メールの開封、クリック、購入など、さまざまなエンティティとのやり取りやトランザクションに基づいて個人をセグメント化するために使用できます。

    他の2つのオプションは、Data Cloudでセグメントを構築するための有効な基準ではありません。データストリーム属性は、Marketing Cloud、Commerce
    Cloud、Service CloudなどのさまざまなソースからData Cloudに取り込まれるストリーミングデータを記述する属性です。これらの属性はセグメンテーションに直接使用することはできませんが、ストリーミングデータ変換を使用して変換し、データ拡張機能に保存することができます。

    ストリーミングインサイトは、ストリーミングデータをリアルタイムで分析し、事前定義された条件に基づいてアクションをトリガーするインサイトです。これらのインサイトはセグメンテーションではなく、アクティベーションとパーソナライゼーションに使用されます。参考資料：データクラウドでのセグメントの作成、データクラウドでのインサイトの使用、データクラウドのデータモデル'
  ai_analysis:
    related_docs:
    - title: Data Cloud 用語集
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_glossary_guide.htm&language=ja&type=5
      reason: このドキュメントの「属性」の定義で、セグメンテーションでは「直接属性」と「関連属性」という2種類の属性が提供されると明確に記述されており、選択肢AとDが正しいことを直接裏付けています。
      supporting_text: '属性

        データモデルオブジェクト (DMO) にある情報またはデータ。セグメンテーションでは、Data Cloud により 2 種類の属性 (直接 (1:1)
        と関連 (1:N)) が提供されます。この評価は、セグメント対象で選択されたオブジェクトから取得されます。'
    - title: 360 データとインサイトによる組織の強化
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_enrich_your_org_with_data_and_insights.htm&language=ja&type=5
      reason: このドキュメントでは、コピー項目として「計算済みインサイトオブジェクト」のデータを追加できると説明されています。セグメンテーションはDMOやCIOの属性に基づいて行われるため、これは「計算された洞察」がセグメントの基準として利用可能であることを示唆しており、選択肢Cの根拠となります。
      supporting_text: コピー項目 — コピー項目には、1 対 1 のリレーションを持つオブジェクトから Data Cloud の個人オブジェクト、統合個人オブジェクト、Data
        Cloud アカウントまたは統合取引先 DMO にコピーされた項目データが表示されます。CIO オブジェクトのディメンションとして 1 つの個人 ID
        を使用する必要があります。複数ディメンション CIO オブジェクトはサポートされていません。たとえば、計算済みインサイトオブジェクトからコピーされた
        [生涯価値] の項目を追加します。
    - title: Data Cloud でのデータアクションの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_a_data_action_in_customer_data_platform.htm&language=ja&type=5
      reason: このドキュメントは、データアクションのソースとして「計算済みインサイトオブジェクト (CIO)」を選択できると明記しています。これは、計算済みインサイトがData
        Cloudプラットフォーム内でセグメンテーションと同様に、データ活用のための入力ソースとして利用されるエンティティであることを示しており、選択肢Cの正当性を補強します。
      supporting_text: データモデルオブジェクト (DMO) または計算済みインサイトオブジェクト (CIO) 種別を選択します。
    ai_verification:
      status: 一致
      justification: 正答である「A. 直接属性」「C. 計算された洞察」「D. 関連属性」がData Cloudのセグメンテーションで使用できる基準であることは、公式ドキュメントによって裏付けられています。『Data
        Cloud 用語集』には、セグメンテーションで「直接属性」と「関連属性」を使用することが明記されています。また、『360 データとインサイトによる組織の強化』や他のドキュメントから、セグメンテーションでは「計算済みインサイト」のデータも基準として利用できることが確認できます。したがって、提示された正答はドキュメントの内容と一致します。
- question_id: 93
  question_text: 'Data Cloud の新規ユーザーは、取り込んだデータの個々の行を確認し、リンクされたデータモデルオブジェクトに正常にモデル化されていることを検証するだけで済みます。必要に応じて変更を加えることもできます。

    このユースケースに対応するために必要な最小限の権限セットは何ですか?'
  choices:
    A: マーケティングスペシャリスト向けデータクラウド
    B: データクラウド管理者
    C: データクラウドユーザー
    D: マーケティングデータアウェアスペシャリストのためのデータクラウド
  correct_answer: C
  japanese_explanation: 'Data Cloud ユーザー権限セットは、このユースケースに対応するために必要な最小限の権限セットです。

    Data Cloud ユーザー権限セットは、Data Explorer 機能へのアクセス権を付与します。これにより、ユーザーは取り込んだデータの個々の行を確認し、リンクされたデータ
    モデル オブジェクトに正常にモデル化されていることを検証できます。また、データ モデル オブジェクト フィールドへの変更 (フィールドの追加または削除、フィールド
    タイプの変更、数式フィールドの作成など) も可能です。Data Cloud ユーザー権限セットでは、データ ストリームの作成、セグメントの作成、アクティベーションの作成、ユーザーの管理など、他の
    Data Cloud 機能やタスクへのアクセス権は付与されません。他の権限セットは、このユース ケースに対して制限が厳しすぎるか、権限が厳しすぎます。Data
    Cloud for Marketing Specialist 権限セットは、セグメンテーション機能とアクティベーション機能へのアクセスのみを付与し、Data
    Explorer 機能へのアクセスは付与しません。Data Cloud 管理者権限セットは、Data Explorer 機能を含むすべての Data Cloud
    機能とタスクへのアクセスを付与しますが、ユーザーの必要以上の権限です。Data Cloud for Marketing Data Aware Specialist
    権限セットは、Data Explorer 機能へのアクセスに加えて、このユース ケースでは必要ありませんが、セグメンテーション機能とアクティベーション機能へのアクセスも付与します。参考資料:
    Data Cloud 標準権限セット、データエクスプローラ、Data Cloud ユニットの設定'
  ai_analysis:
    related_docs:
    - title: データエクスプローラー
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_explorer.htm&language=ja&type=5
      reason: 問題文で要求されている「取り込んだデータの個々の行を確認」し、「リンクされたデータモデルオブジェクトに正常にモデル化されていることを検証する」というタスクが、このドキュメントで説明されているデータエクスプローラーの主要な機能と完全に一致するため。
      supporting_text: 'データエクスプローラーを使用すると、データレークオブジェクト、データモデルオブジェクト、計算済みインサイトを検証して、データと数式が正確であることを確認できます。


        データエクスプローラーでは、データレークオブジェクト (DLO)、データモデルオブジェクト (DMO)、計算済みインサイトオブジェクト (CIO)、またはデータグラフから選択した
        Data Cloud データを表示できます。'
    - title: データエクスプローラーまたはプロファイルエクスプローラーへのアクセス権の付与または削除
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_enable_data_explorer_permissions.htm&language=ja&type=5
      reason: このドキュメントは、データエクスプローラーの利用に必要なシステム権限「Data Cloud データエクスプローラーにアクセス」について具体的に言及しており、問題のユースケースに必要な権限を特定するための直接的な根拠となるため。
      supporting_text: データエクスプローラーへのアクセス権を有効にするには、[Data Cloud データエクスプローラーにアクセス] を選択します。プロファイルエクスプローラーへのアクセス権を有効にするには、[Data
        Cloud プロファイルエクスプローラーにアクセス] を選択します。アクセス権を削除している場合は、権限を選択解除します。
    ai_verification:
      status: 一致
      justification: 問題で要求されているタスクは、公式ドキュメントにある「データエクスプローラー」の機能と完全に一致します。データエクスプローラーの利用には「Data
        Cloud データエクスプローラーにアクセス」権限が必要です。問題は「最小限の権限セット」を問うており、選択肢の中で「データクラウド管理者」は権限が過剰であり、「マーケティングスペシャリスト」や「データアウェアスペシャリスト」はより専門的なタスクを想定しています。データの閲覧と検証という基本的な操作は、最も基本的な「データクラウドユーザー」権限セットに含まれていると考えるのが合理的です。したがって、正答である「C.
        データクラウドユーザー」は妥当です。
- question_id: 94
  question_text: 'ユーザーはData Cloudでセグメントを作成し、アクティベーションを作成中です。関連属性を選択する際に、個人に関連するとわかっている属性セットが見つかりません。

    これらの属性が利用できない理由を説明する記述はどれですか?'
  choices:
    A: セグメントはプロファイル データでセグメント化されていません。
    B: 属性は別のアクティベーションで使用されています。
    C: 必要な属性は異なる関連パスに存在します。
    D: アクティベーションには 1 対 1 の属性のみを含めることができます。
  correct_answer: C
  japanese_explanation: '正解はCです。必要な属性は異なる関連パスに存在します。Data Cloudでアクティベーションを作成する際に、セグメントエンティティにリンクされているデータモデルオブジェクトから関連属性を選択できます。

    ただし、すべての関連属性がすべてのアクティベーションで使用できるわけではありません。関連属性の可用性は、コンテナパス（セグメントエンティティを関連エンティティに接続するデータモデルオブジェクトのシーケンス）によって異なります。たとえば、Unified
    Individual エンティティでセグメント化する場合、Order Product エンティティから関連属性を選択できますが、コンテナパスが Unified
    Individual > Order > Order Product の場合のみです。コンテナパスが Unified Individual > Order
    Line Item > Order Product の場合、Order Product の関連属性はアクティベーションに使用できません。これは、Data Cloud
    が関連属性に対して 1 対多の関係のみをサポートし、Order Line Item が Order と Order Product 間の多対多のジャンクションオブジェクトであるためです。したがって、必要な属性がセグメントエンティティと同じ関連パスに存在し、そのパスに多対多のジャンクションオブジェクトが含まれていないことを確認する必要があります。その他のオプションは、関連属性が使用できない理由を説明していないため、正しくありません。セグメントエンティティは、プロファイルデータだけでなく、任意のデータモデルオブジェクトにすることができます。属性は、別のアクティベーションで使用されていることで制限されることはありません。アクティベーションには、1対1の属性だけでなく、1対多の属性も含めることができます。参考資料:

    * アクティベーションにおける関連属性

    * 関連属性を選択する際の考慮事項

    * Salesforceがデータクラウドコンサルタント認定を開始

    * データクラウドでセグメントを作成する'
  ai_analysis:
    related_docs:
    - title: データモデルオブジェクトリレーション
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_model_object_relationships.htm&language=ja&type=5
      reason: このドキュメントは、DMO間のリレーション設定が「セグメンテーションと有効化（アクティベーション）」に影響を与えることを明確に記述しています。問題はアクティベーションで属性が利用できない状況についてであり、その根本原因がデータモデルのリレーションシップ（関連パス）にあることを示唆しており、正答の「異なる関連パス」という概念と直接関連します。
      supporting_text: 2 つの DMO 間のカーディナリティは、セグメンテーションと有効化に影響します。リレーションの作成後にカーディナリティを変更することはできません。
    - title: セグメントキャンバス
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_segment_canvas_interface.htm&language=ja&type=5
      reason: 問題文にある「関連属性」という用語を定義し、セグメンテーションにおける属性の扱いについて説明しています。問題のシナリオを理解するための背景情報として役立ちます。
      supporting_text: 関連属性は、複数のデータポイント、またはセグメント化されるエンティティに関連付けられた情報 (購入履歴、商品番号、メールのやり取りなど)
        のコレクションです。多くの場合、関連属性は行動またはエンゲージメントイベントです。
    ai_verification:
      status: 一致
      justification: 問題は、Data Cloudのアクティベーションにおいて、なぜ特定の関連属性が利用できないかを問うています。正答は「必要な属性は異なる関連パスに存在する」ためです。これはData
        Cloudの仕様上の制約で、アクティベーションでは単一のリレーションパスをたどって属性を取得する必要があるため、セグメントの定義から見て複数の異なるパスに存在する属性を同時に選択することはできません。ドキュメント「データモデルオブジェクトリレーション」に記載されている「2
        つの DMO 間のカーディナリティは、セグメンテーションと有効化に影響します」という記述は、データモデルのリレーション（=関連パス）がアクティベーションで利用できる属性を決定づける要因であることを裏付けており、正答の根拠となります。
- question_id: 95
  question_text: '実装プロジェクト中に、コンサルタントが顧客のすべてのデータ ストリームの取り込みを完了しました。

    データをセグメント化して操作する前に、どのような追加構成が必要ですか?'
  choices:
    A: データのアクティベーション
    B: 計算された洞察
    C: データマッピング
    D: アイデンティティ解決
  correct_answer: D
  japanese_explanation: 'さまざまなソースから Data Cloud にデータを取り込んだ後、そのデータをセグメント化して操作する前に必要な追加の設定は、Identity
    Resolution です。Identity Resolution とは、さまざまなデータソースのソースプロファイルを照合および調整し、単一の個人またはエンティティを表す統合プロファイルを作成するプロセスです1。Identity
    Resolution を使用すると、顧客と見込み客の 360 度ビューを作成し、属性と行動に基づいてセグメント化してアクティブ化できます2。Identity
    Resolution を設定するには、データの一致ルールと調整ルールを定義するルールセットを作成して展開する必要があります3。その他のオプションは、データをセグメント化して操作する前には必要ないため、正しくありません。Data
    Activation とは、マーケティング、営業、またはサービスを目的として、Data Cloud から他の Salesforce クラウドまたは外部の送信先にデータを送信するプロセスです4。計算されたインサイトは、生涯価値、解約リスク、製品アフィニティなど、ソースデータまたは統合データに基づいて計算される派生属性です5。Data
    Mapping とは、ソース属性をデータモデル内の統合属性にマッピングするプロセスです。これらの設定は、データのセグメント化と処理を行った後、またはIdentity
    Resolutionと並行して行うことができますが、Identity Resolutionの前提条件ではありません。参考資料：Identity Resolutionの概要、データクラウドでのデータのセグメント化とアクティベーション、Identity
    Resolutionルールセットの設定、データアクティベーションの概要、Calculated Insightsの概要

    [データマッピングの概要]'
  ai_analysis:
    related_docs:
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: このドキュメントは、データを取り込んでマッピングした後のステップとしてID解決を明確に位置付けており、ID解決によって作成された統合プロファイルが「セグメンテーションや有効化などのプロセス」で使用されると説明しています。これは、問題のシナリオ（データ取り込み完了後、セグメンテーション前）に直接合致する内容です。
      supporting_text: ID 解決では、複数のデータソースのすべての項目値を、セグメンテーションや有効化などのプロセス、計算済みインサイト、レポートなどで使用できる統合プロファイルにまとめます。統合は、作成するデータマッピングと、ルールセットで指定された一致ルールと調整ルールに基づいて決定されます。
    - title: Data Cloud Architecture
      url: https://developer.salesforce.com/docs/data/data-cloud-dev/guide/dc-architecture.html
      reason: この開発者向けドキュメントは、Data Cloudのアーキテクチャの概要を示しています。データソースからのデータを統合プロファイルにまとめるプロセスとして「identity
        resolution process」を説明し、その統合データが「customer insights and actions（顧客インサイトとアクション）」に使用されると述べており、プロセス全体の流れを裏付けています。
      supporting_text: 'The identity resolution process involves applying match rules
        to group individuals, and reconciliation rules to select the best quality
        data from these groups to generate a gold standard unified profile. ... Use
        unified data for customer insights and actions:'
    - title: ID 解決のデータモデリング要件
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_data_modeling_requirements.htm&language=ja&type=5
      reason: このドキュメントは、ID解決を実行するための前提条件としてデータマッピングが必要であることを説明しています。問題文では「データストリームの取り込みを完了」とあり、データマッピングが完了しているか、その直後の段階であることが示唆されます。したがって、次のステップがID解決であることを補強しています。
      supporting_text: ID 解決でデータを処理して統合プロファイルにまとめるには、データが正しくマッピングされている必要があります。データモデリング要件を確認し、個人、取引先、連絡先データの統合準備が整っていることを確認します。
    ai_verification:
      status: 一致
      justification: 複数の公式ドキュメントで、Data Cloudのプロセスは「データの取り込みとマッピング」→「ID解決によるプロファイルの統合」→「セグメンテーションやアクティベーションでの活用」という流れであることが一貫して説明されています。問題文は「データ
        ストリームの取り込みを完了」した段階について尋ねており、その次のステップは、ばらばらのデータを顧客単位で統合する「アイデンティティ解決」です。ドキュメント「ソースプロファイルの統合」には、ID解決によって作成された統合プロファイルがセグメンテーションで利用されると明確に記述されており、正答を直接裏付けています。
- question_id: 96
  question_text: Data Cloud は個人の忘れられる権利をどのように扱いますか?
  choices:
    A: すべてのデータソースオブジェクトからレコードを削除し、下流のデータモデルオブジェクトは次回のスケジュールされた取り込み時に更新されます。
    B: 指定された個別レコードとその統合個別リンクレコードを削除します。
    C: 指定された個人とレコードを、Individual データ モデル オブジェクトにマップされたすべてのデータ ソース オブジェクトから削除します。
    D: 指定された個人と、その個人に関連するすべてのデータ モデル オブジェクト/データ レイク オブジェクトからレコードを削除します。
  correct_answer: D
  japanese_explanation: 'Data Cloud は、指定された個人と、その個人に関連するすべてのデータモデルオブジェクト/データレイクオブジェクトからレコードを削除することで、個人の「忘れられる権利」を処理します。つまり、Data
    Cloud は、ソースオブジェクト、統合された個人プロファイル、および関連オブジェクトのデータを含む、個人に関連付けられたすべてのデータをデータスペースから削除します。また、個人とソースレコードをリンクする統合個人リンクレコードも削除します。Data
    Cloud は、Consent API を使用して「忘れられる権利」リクエストを処理します。これらのリクエストは、完全な削除を確実にするために、30 日、60
    日、90 日ごとに再処理されます。

    その他のオプションは、データクラウドが個人の忘れられる権利をどのように処理するかについて正しく説明していません。データクラウドは、ソースシステムのデータの整合性と可用性に影響を与えるため、すべてのデータソースオブジェクトからレコードを削除することはありません。また、データクラウドは、指定された個人レコードとその統合個人リンクレコードのみを削除することもありません。そうすると、ソースレコードと関連レコードがそのまま残ってしまうためです。さらに、データクラウドは、指定された個人と、その個人データモデルオブジェクトにマッピングされたデータソースオブジェクトからのレコードのみを削除することもありません。そうすると、関連レコードがそのまま残ってしまうためです。

    参考文献:

    * データ削除または忘れられる権利の要求

    * データクラウドのデータ削除

    * Data Cloud で Consent API を使用する

    * データクラウドにおけるデータとアイデンティティ'
  ai_analysis:
    related_docs:
    - title: データ主体の権利
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_subject_rights.htm&language=ja&type=5
      reason: このドキュメントは、Data CloudがGDPRなどで定められた「データの削除または忘れられる権利 (RTBF)」をサポートしていることを明記しており、問題の核心である「忘れられる権利」の扱いに関する基本的な情報を提供しているため。
      supporting_text: '次に、Data Cloud の規制の例を示します。


        データの削除または忘れられる権利 (RTBF)

        処理の制限 (RofP)

        データのアクセスおよびエクスポート


        Salesforce 同意 API を使用して、すべてのデータ主体の権利の要求を送信します。'
    - title: データ変換の顧客データ主体の権利
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_streaming_transform_data_subject_rights.htm&language=ja&type=5
      reason: このドキュメントは、「忘れられる権利」の要求（同意API経由）が、個人に直接的または間接的にマッピングされたすべてのデータレークオブジェクト（DLO）に適用されることを説明しており、正答の「その個人に関連するすべてのデータモデルオブジェクト/データレイクオブジェクトからレコードを削除する」という内容を直接的に裏付けているため。
      supporting_text: 同意 API は、個人にマッピングされている DLO に保存されているすべてのデータで動作します。たとえば、次の図では、DLO2
        と DLO4 が個人 DMO と連絡先住所 DMO にマッピングされています。連絡先住所には個人とのリレーションがあります。DLO2 と DLO4
        は個人 DMO に直接的または間接的にマッピングされているため、同意 API はこの 2 つの DLO で動作します。
    ai_verification:
      status: 一致
      justification: 公式ドキュメント「データ主体の権利」には、Data Cloudが「データの削除または忘れられる権利 (RTBF)」をサポートしていることが記載されています。さらに、「データ変換の顧客データ主体の権利」ドキュメントでは、同意APIを介した削除要求が、個人DMOに直接的または間接的に関連付けられているすべてのDLO（データレイクオブジェクト）に適用されると具体的に説明されています。これは、正答である「指定された個人と、その個人に関連するすべてのデータ
        モデル オブジェクト/データ レイク オブジェクトからレコードを削除します。」という内容と完全に一致します。
- question_id: 97
  question_text: '顧客は、データ ウェアハウスのトランザクション データを Data Cloud で使用したいと考えています。

    データのエクスポートは SFTP サイト経由でのみ可能です。

    ファイルを Data Cloud に取り込むにはどうすればよいでしょうか?'
  choices:
    A: SFTP コネクタを使用してファイルを取り込みます。
    B: Cloud Storage Connector を介してファイルを取り込みます。
    C: データ インポート ウィザードを使用してファイルを手動でインポートします。
    D: Salesforce の Dataloader アプリケーションを使用して、デスクトップから一括アップロードを実行します。
  correct_answer: A
  japanese_explanation: 'SFTP コネクタは、Data Cloud が SFTP サーバーからデータを取り込むことを可能にするデータ ソース
    コネクタです。

    お客様はSFTPコネクタを使用してエクスポートしたファイルからデータストリームを作成し、それをデータレイクオブジェクトとしてData Cloudに取り込むことができます。他の方法は、以下の理由から、ファイルをData
    Cloudに取り込む最適な方法ではありません。

    * B. Cloud Storage Connectorは、Data CloudがAmazon S3、Azure Storage、Google Cloud
    Storageなどのクラウドストレージサービスからデータを取り込むことを可能にするデータソースコネクタです。お客様のデータはこれらのサービスには保存されておらず、SFTPサイトにのみ保存されています。

    * C. データインポートウィザードは、取引先、取引先責任者、リード、ソリューション、キャンペーンメンバーなど、多くの標準Salesforceオブジェクトのデータをインポートできるツールです。SFTPサイトからのデータのインポートや、Data
    Cloud内のカスタムオブジェクトのインポートには対応していません。

    * D. データローダーは、Salesforceレコードの挿入、更新、削除、エクスポートを可能にするアプリケーションです。SFTPサイトやData Cloudからデータを取り込むためのものではありません。参考資料：SFTPコネクタ
    - Salesforce、Data CloudでSFTPコネクタを使用してデータストリームを作成する - Salesforce、データインポートウィザード
    - Salesforce、Salesforceデータローダー'
  ai_analysis:
    related_docs:
    - title: Release Notes - Data Cloud (Pages 196-208) - Part 207
      url: Salesforce Summer '23 リリースノート.pdf
      reason: Data CloudでSFTPサイトからデータを取り込む際に、データストリームのソースとしてSFTPを選択するという具体的な手順が記載されており、問題の解決策である「SFTPコネクタの使用」を直接裏付けているため。
      supporting_text: '方法 : Data Cloud 設定で、 SFTP サーバへの接続を作成します。次に、 [データストリーム ] で、ソースとして
        [SFTP]

        を選択します。'
    - title: Release Notes - Data Cloud (Pages 196-208) - Part 201
      url: Salesforce Summer '23 リリースノート.pdf
      reason: 「SFTP コネクタを使用したデータストリームの作成」というタイトル自体が、SFTPコネクタを使ってData Cloudにデータを取り込む（データストリームを作成する）ことが可能であることを明確に示しているため。
      supporting_text: 'Data Cloud での  SFTP コネクタを使用したデータストリームの作成

        異種のサイロ化したソースのデータを  1 か所に移行することで、より迅速でスマートな意思決定を行います。'
    - title: 既存のデータレークオブジェクトを使用したデータストリームの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_guardrails_existing_data_lake_object.htm&language=ja&type=5
      reason: Data Cloudで「SFTP データストリームを作成する」ことが可能であると明記されており、SFTPがデータ取り込みのソースとしてサポートされていることを示しているため。
      supporting_text: S3、Google Cloud Storage、または SFTP データストリームを作成するときに、既存のデータレークオブジェクト
        (DLO) を使用できます。
    ai_verification:
      status: 一致
      justification: 複数の公式ドキュメント（特にリリースノートとヘルプ記事）で、Data CloudがSFTPサイトをデータソースとして接続し、データを取り込むための「SFTPコネクタ」または「SFTPデータストリーム」機能を提供していることが明確に述べられています。リリースノートには「[データストリーム]
        で、ソースとして [SFTP] を選択します」という具体的な手順も記載されています。したがって、SFTPサイト経由のファイルを取り込むには「SFTP
        コネクタを使用する」という正答は、公式情報と完全に一致します。他の選択肢（Cloud Storage Connector、データインポートウィザード、Dataloader）は、このシナリオには不適切です。
- question_id: 98
  question_text: 'Northern Trail Outfittersは、過去24時間以内に商品を購入した顧客をセグメント化したいと考えています。セグメントデータは可能な限り最新のものにする必要があります。

    セグメントを作成するときにコンサルタントは何を実装する必要がありますか?'
  choices:
    A: ストリーミング インサイトを使用して、ほぼリアルタイムのセグメンテーション結果を取得します。
    B: Einstein セグメンテーション最適化を使用して、過去 24 時間のデータを収集します。
    C: 公開間隔が 1 時間の高速セグメントを使用します。
    D: 公開間隔が 30 分の標準セグメントを使用します。
  correct_answer: A
  japanese_explanation: 'Northern Trail Outfitters の要件である、過去 24 時間以内に購入した顧客でセグメントを作成し、かつデータを可能な限り最新の状態に保つには、ストリーミングインサイトが最適なソリューションです。その理由は次のとおりです。

    ストリーミングインサイトの理解:

    Salesforce Data Cloud は、ほぼリアルタイムのデータ処理とセグメンテーションを可能にする Streaming Insights を提供します。この機能により、企業は顧客とのやり取りや取引をほぼ瞬時に把握し、それに応じた対応をとることができるため、最近の購入者の特定など、時間的制約が厳しいユースケースに最適です。

    他の選択肢はないのでしょうか?

    オプションB（Einstein Segmentation Optimization）：Einstein Segmentation Optimizationは、AIを用いたセグメントパフォーマンスの向上に重点を置いていますが、本質的にはほぼリアルタイムのデータ更新を提供するものではありません。低レイテンシのデータ可用性の確保よりも、既存のセグメントの改良に重点を置いています。

    オプションC（公開間隔が1時間の高速セグメント）：高速セグメントは標準セグメントよりも高速ですが、公開間隔による遅延が発生します。1時間の間隔では「可能な限り最新の情報」という要件を満たしません。

    オプションD（公開間隔30分の標準セグメント）：標準セグメントは処理頻度が低く、通常は遅延が長くなります。30分間隔であっても、このオプションではストリーミングインサイトのほぼリアルタイム機能には匹敵しません。

    ストリーミングインサイトの仕組み:

    Streaming Insights は、接続されたソース (CRM、外部システムなど) からのデータをほぼリアルタイムで処理します。

    顧客が購入すると、トランザクション データが Data Cloud に取り込まれ、すぐにセグメンテーションに利用できるようになります。

    コンサルタントは、購入タイムスタンプが過去 24 時間以内に該当する顧客のみを含めるようにセグメント ルールを設定できます。

    Salesforce ドキュメントリファレンス:

    Salesforceの公式Data Cloudドキュメントによると、Streaming Insightsは、タイムリーなデータが不可欠なシナリオ向けに設計されています。これにより、セグメントは大幅な遅延なく最新の顧客行動を反映することができ、Northern
    Trail Outfittersのニーズに完全に合致しています。'
  ai_analysis:
    related_docs:
    - title: セグメンテーション
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_segments.htm&language=ja&type=5
      reason: 問題は「可能な限り最新」のデータでのセグメンテーションを要求しており、このドキュメントでは「リアルタイムセグメント」について説明されています。これが正答である「ストリーミングインサイト」を用いた「ほぼリアルタイムのセグメンテーション」に直接関連する機能であるためです。
      supporting_text: 'リアルタイムセグメントの作成

        オンデマンドでミリ秒で完了するリアルタイムセグメントを作成します。セグメントをリアルタイムデータグラフで使用できるようにするには、セグメントメンバーシップ
        DMO オブジェクトの [セグメント ID] 項目と [タイムスタンプ] 項目をリアルタイムデータグラフに追加します。'
    - title: ストリーミングデータ変換の使用事例
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_streaming_transform_use_cases.htm&language=ja&type=5
      reason: 正答のキーワードである「ストリーミング」に関連するドキュメントであり、ストリーミングデータを活用してリアルタイムに近いデータ処理を行う概念を説明しています。これは「ストリーミングインサイト」の基盤となる技術であり、問題の要件を理解する上で参考になります。
      supporting_text: 次の使用事例は、ストリーミングデータ変換を使用して、データを正規化して絞り込み、Data Cloud データモデルとの連携を向上させる方法を示しています。
    ai_verification:
      status: 一致
      justification: 問題は「過去24時間以内」の購入者を対象とし、「可能な限り最新」のデータでセグメント化することを要求しています。これは、リアルタイムに近いデータ反映が必要であることを示唆します。正答である「A.
        ストリーミング インサイトを使用して、ほぼリアルタイムのセグメンテーション結果を取得します。」は、この要件に最も合致します。ストリーミングインサイトは、継続的に発生するデータ（この場合は購入イベント）をほぼリアルタイムで取り込み、セグメンテーションに反映させる機能です。関連ドキュメント「セグメンテーション」に記載されている「リアルタイムセグメント」は「オンデマンドでミリ秒で完了する」と説明されており、このコンセプトを裏付けています。他の選択肢である高速セグメント（C）や標準セグメント（D）はバッチ処理であり、それぞれ1時間や30分といった更新間隔があるため、「可能な限り最新」という要件には劣ります。Einsteinセグメンテーション（B）はAIによる作成支援であり、リアルタイム性を保証するものではありません。したがって、ほぼリアルタイムのセグメンテーションを実現するストリーミングインサイトが最適な選択肢です。
- question_id: 99
  question_text: '顧客には、Salesforce CRM の標準の連絡先オブジェクトに関連するカスタムの顧客電子メール c オブジェクトがあります。

    このカスタムオブジェクト

    アクティベーションに使用する連絡先の電子メール アドレスを保存します。

    どのデータ エンティティがマップされていますか?'
  choices:
    A: 連絡先
    B: 連絡先メールアドレス
    C: カスタム顧客 Email__c オブジェクト
    D: 個人
  correct_answer: B
  japanese_explanation: 'Contact Point_Email オブジェクトは、Data Cloud 内の個人に関連付けられたメールアドレスを表すデータエンティティです。これは、顧客データの共通エンティティとリレーションシップを定義する標準化されたデータモデルである
    Customer 360 データモデルの一部です。Contact Point_Email オブジェクトは、Salesforce CRM 内のメールアドレスを格納する任意のカスタムオブジェクトまたは標準オブジェクト（カスタム
    Customer Email__c オブジェクトなど）にマッピングできます。その他のオプションは、以下の理由により、マッピングする適切なデータエンティティではありません。

    * A. 連絡先オブジェクトは、Salesforce CRM の顧客、パートナー、または競合他社の取引先に関連付けられた個人を表すデータエンティティです。Data
    Cloud のメールアドレスを表すデータエンティティではありません。

    * C. カスタム Customer Email__c オブジェクトは、Data Cloud のデータエンティティではなく、Salesforce CRM のカスタムオブジェクトです。Contact
    Point_Email オブジェクトなどの Data Cloud のデータエンティティにマッピングできますが、それ自体はデータエンティティではありません。

    * D. 個人オブジェクトは、Data Cloud において固有の個人を表すデータエンティティです。同意とプライバシー設定を管理するための中核エンティティであり、メールアドレス、電話番号、ソーシャルメディアのハンドルなど、1
    つ以上のコンタクトポイントに関連付けることができます。Data Cloud においてメールアドレスを表すデータエンティティではありません。参考資料：Customer
    360 データモデル：個人とコンタクトポイント - Salesforce、Contact Point_Email | Salesforce Platform
    のオブジェクトリファレンス | Salesforce Developers、

    [連絡先 | Salesforce プラットフォームのオブジェクトリファレンス | Salesforce 開発者]、[個人 | Salesforce プラットフォームのオブジェクトリファレンス
    | Salesforce 開発者]'
  ai_analysis:
    related_docs:
    - title: 'Customer 360 データモデル: 個人および連絡先'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_cloud_information_model_individual_and_contact_points.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudの標準データモデルにおける「個人」と「連絡先」の概念を説明しています。問題はメールアドレスという連絡先情報のマッピング先を問うており、このドキュメントで説明されている「連絡先オブジェクト」が正解の「連絡先メールアドレス」エンティティの根拠となるため、最も関連性が高いです。
      supporting_text: Customer 360 データモデルを使用する場合、Salesforce が公開するオブジェクト、項目、メタデータ、およびリレーションのリストが
        Data Cloud によって用意されます。これにより、アプリケーションとビジネスプロセス全体の一貫性が確保されます。個人および連絡先オブジェクトは、正常かつ完全なデータストリームの重要な概念です。
    - title: Customer 360 データモデル
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_c360datamodel.htm&language=ja&type=5
      reason: このドキュメントは、Customer 360データモデルの全体像と主要な主題領域について説明しています。「関係者データモデル」は、顧客の連絡先情報を含むオブジェクト群を定義しており、問題のシナリオを理解するための広範なコンテキストを提供します。
      supporting_text: Customer 360 データモデル関係者主題では、特定の顧客または取引先の取引先責任者情報 (個人または法人) が反映されたデータモデルオブジェクト
        (DMO) をグループ化します。
    - title: 目標販売のリードの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_sales_unify.htm&language=ja&type=5
      reason: このドキュメントは、Sales CloudのデータをData Cloudに取り込み、Customer 360データモデルへマッピングするプロセスについて言及しています。問題のシナリオである「カスタムオブジェクト...をCustomer
        360 データモデルにマッピングする」という操作の必要性について背景情報を提供します。
      supporting_text: ただし、ID 解決を使用するには、カスタムオブジェクトと一部の必須項目を Customer 360 データモデルにマッピングする必要があります。
    ai_verification:
      status: 一致
      justification: 問題は、Salesforce CRMのカスタムオブジェクトに保存されたメールアドレスを、Data Cloudのどのデータエンティティにマッピングするかを問うています。Data
        CloudのCustomer 360データモデルでは、個人そのものを表す『個人 (Individual)』オブジェクトと、その個人への連絡手段（メールアドレス、電話番号など）を管理する『連絡先
        (Contact Point)』ファミリーのオブジェクトが標準で用意されています。メールアドレスは『連絡先メールアドレス (Contact Point
        Email)』DMOにマッピングするのが最も適切です。したがって、正答である「B. 連絡先メールアドレス」は、Data Cloudの標準的なデータモデリングのプラクティスと完全に一致します。
- question_id: 100
  question_text: 'コンサルタントは、携帯電話番号を含むプロフィール情報を持つデータ ストリームの取り込みを計画しています。

    今後のSMSキャンペーンで電話番号を確実に使用できるようにするには、電話番号フィールドが適切なE164電話番号形式であることを確認する必要があります。しかし、ファイル内の電話番号の形式は様々であるようです。

    さまざまな電話番号の形式が標準化されていることを保証する最も効率的な方法は何ですか?'
  choices:
    A: 形式を標準化するための数式フィールドを作成します。
    B: Data Cloud に送信する前に、ソース システムでデータを編集および更新します。
    C: データ ストリームを作成するときに、PhoneNumber フィールド タイプを割り当てます。
    D: 取り込み後に計算されたインサイトを作成します。
  correct_answer: C
  japanese_explanation: さまざまな電話番号形式を標準化するための最も効率的な方法は、データストリームの作成時にPhoneNumberフィールドタイプを割り当てることです。PhoneNumberフィールドタイプは、電話番号を国際標準の電話番号であるE164形式に自動変換する特別なフィールドタイプです。E164形式は、プラス記号（+）、国番号、国内番号で構成されます。例えば、+1-202-555-1234は米国の電話番号のE164形式です。PhoneNumberフィールドタイプを使用することで、コンサルタントは電話番号の一貫性を確保し、将来のSMSキャンペーンに使用できるようにすることができます。他のオプションは、時間がかかり、手動による介入が必要になり、フォーマットの問題に対処できません。参考資料：データストリームのフィールドタイプ、E164電話番号形式、Salesforce
    Data Cloud試験問題
  ai_analysis:
    related_docs:
    - title: '[あいまい] および [完全] 照合方法'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_match_rules_criteria_fuzzy_normalized.htm&language=ja&type=5
      reason: このドキュメントは、連絡先電話オブジェクトの「Formatted E164 Phone Number」項目にマッピングされたデータが、どのように標準化されるかを具体的に説明しています。特殊文字の削除やGoogleのライブラリを使用した検証とフォーマット設定が行われると明記されており、これが問題で要求されている「様々な電話番号の形式が標準化されていることを保証する」ための最も効率的な方法の根拠となります。
      supporting_text: "オブジェクト\t[完全 (標準化)] 照合方法でサポートされる項目\t標準化プロセス\n連絡先電話\tFormatted\
        \ E164 Phone Number (書式設定された E164 電話番号)\t電話番号から空白を削除する * や () などの英数字以外の文字を電話番号から削除する\
        \ 国際電話番号を解析、書式設定、および検証するための Google の Java、C++、および JavaScript 共通ライブラリを使用して電話番号を検証する"
    - title: 'Customer 360 データモデル: 個人および連絡先'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_cloud_information_model_individual_and_contact_points.htm&language=ja&type=5
      reason: Data Cloudの標準データモデルに、E164形式で電話番号を保持するための「FormattedE164PhoneNumber」という専用フィールドが存在することを示しています。これは、Data
        Cloudが電話番号の標準化を意図して設計されていることを裏付けています。
      supporting_text: "オブジェクト種別\t内容\t例\n...\n連絡先電話\t個人の電話番号\t+1555123456\n...\nFormattedE164PhoneNumber\t\
        E164 形式の電話番号。処理の標準化された値としてバックエンドシステムで使用します。"
    - title: Sales Cloud からのデータの取り込みとマッピング
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_ingest_map_dc4sales.htm&language=ja&type=5
      reason: データストリーム作成後のデータマッピング手順で、ソースシステムの電話番号項目（例：Business Phone）を、Data Cloudのデータモデルオブジェクト（DMO）の「Formatted
        E164 Phone Number」項目に対応付ける具体的な手順を示しています。これが選択肢Cの操作に該当します。
      supporting_text: データの取り込み時に、データはそのまま取り込まれます。つまり、項目とそのデータ型は変換されずにインポートされます。データストリームを作成して、データを
        Data Cloud に取り込みます。...[データモデルエンティティ] で、検索ボックスを使用して連絡先電話オブジェクトの [書式設定された E164
        電話番号] 項目を見つけます。...[Formatted E164 Phone Number] フィールドをクリックして、左側の [Business
        Phone] に対応付けます。
    ai_verification:
      status: 一致
      justification: 問題は、様々な形式の電話番号を効率的に標準化する方法を問うています。正答は、データストリーム作成時にPhoneNumberフィールドタイプを割り当てることです。これは、実際にはデータマッピングのプロセスでソースの電話項目をデータモデルオブジェクト（DMO）の「Formatted
        E164 Phone Number」フィールドにマッピングする操作を指します。関連ドキュメント「[あいまい] および [完全] 照合方法」で説明されているように、このフィールドにマッピングすると、Data
        Cloudが自動的に電話番号をE164形式に正規化（標準化）します。これは、数式を作成したり（A）、ソースシステムで修正したり（B）するよりも効率的な、Data
        Cloudの標準機能です。したがって、ドキュメントは正答を強力に裏付けています。
- question_id: 101
  question_text: '個人にセグメントを作成するときに、以下に示すように AND でリンクされた 2 つの個別のコンテナーを使用すると、どのような結果になりますか?

    商品 | 個数 | 最小 | 1

    色 | 等しい | 赤

    そして

    商品 | 個数 | 最小 | 1

    PrimaryProductCategory | 等しい | 靴'
  choices:
    A: 少なくとも1つの「赤色」製品を購入し、さらに少なくとも1足の「靴」を購入した個人
    B: 購入時に単一の品目として「赤い靴」を少なくとも1つ購入した個人
    C: 少なくとも1つの「赤い靴」を購入した個人。他には何も購入していない。
    D: 少なくとも1つの「赤い」製品を購入した、または少なくとも1足の「靴」を購入した個人
  correct_answer: A
  japanese_explanation: '個人にセグメントを作成する際に、AND でリンクされた 2 つの別々のコンテナを使用する場合、その個人はコンテナ内の両方の条件を満たす必要があります。この場合、個人は色属性が「赤」である商品を少なくとも
    1 つ、主要商品カテゴリ属性が「靴」である商品を少なくとも 1 つ購入している必要があります。これらの商品は同一である必要はなく、同じ取引で購入される必要もありません。したがって、正解は
    A です。

    その他のオプションは、異なる論理演算子または条件を意味しているため、正しくありません。オプション B は、色属性が「赤」で、主要製品カテゴリ属性が「靴」である製品を
    1 つだけ購入した必要があることを意味します。オプション C は、色属性が「赤」で、主要製品カテゴリ属性が「靴」である製品を 1 つだけ購入し、他の製品は購入していない必要があることを意味します。オプション
    D は、色属性が「赤」である製品を 1 つ、または主要製品カテゴリ属性が「靴」である製品を 1 つ、あるいはその両方を購入した必要があることを意味します。これは、AND
    演算子ではなく OR 演算子を使用するのと同じです。

    参照：

    セグメンテーション用のコンテナを作成する

    データクラウドでセグメントを作成する

    データクラウドセグメンテーションをナビゲート'
  ai_analysis:
    related_docs:
    - title: 購入検索条件
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_purchases_filters.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudのセグメンテーションにおける購入条件の具体的な設定例を示しています。特に「ある商品を購入し、別の商品を購入していない」という例では、問題と同様に2つの独立した条件コンテナーを「AND」で結合しています。この例は、各コンテナーが個別に評価され、両方の条件を満たす対象者が抽出されることを明確に示しており、問題のシナリオ（「赤い商品」の購入
        AND 「靴」の購入）の挙動を直接的に説明しています。
      supporting_text: 'この検索条件では、一定の期間内にカヤックを購入し、安全ベストを購入しなかった顧客を検索します。


        例

        販売注文商品 | 件数 | 以上 | 1

        商品名 | 次の値と等しい | カヤック

        および

        注文開始日 | 次の範囲内にある | 2020-05-01 AND 2020-06-01


        および


        販売注文商品 | 件数 | 次の値と等しい | 0

        Product Name | Is Equal To | Safety Vests (商品名 | 次の値と等しい | 安全ベスト)

        および

        注文開始日 | 次の範囲内にある | 2020-05-01 AND 2020-06-01'
    - title: データの整理
      url: basics.pdf
      reason: このドキュメントは、Salesforceの基本的な検索条件ロジックにおける「AND」演算子の機能を「両方の値と一致するレコードを検索します」と明確に定義しています。問題で示されている2つのコンテナーがANDでリンクされている状況は、この基本的なAND演算子の定義に直接当てはまります。これにより、コンテナー1の条件とコンテナー2の条件の両方を満たす必要があると理解できます。
      supporting_text: '両方の値と一致するレコードを検索します。

        1 AND 2'
    - title: 検索条件ノード
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_batch_transform_filter.htm&language=ja&type=5
      reason: このドキュメントは、データ変換における検索条件のロジックについて説明しており、「デフォルトの AND ロジック」や、括弧とAND、OR、NOT
        Boolean演算子を使用してロジックを構築する方法について言及しています。問題の「ANDでリンクされた2つの個別のコンテナー」という概念は、ここで説明されている複数の検索条件をANDで組み合わせるロジックと一致しており、基本的な動作原理を裏付けています。
      supporting_text: '現在の標準検索条件ロジックを表示するには、  および [標準の検索条件ロジックを追加] をクリックします。

        デフォルトの AND ロジックが表示され、各検索条件コンポーネントには番号が割り当てられています。

        ロジックを編集するには、鉛筆アイコン () をクリックします。

        括弧と AND、OR、および NOT Boolean 演算子を使用して、検索条件ロジックを構築します。'
    ai_verification:
      status: 一致
      justification: 問題は、2つの独立した条件コンテナーを `AND` で結合した際のセグメンテーション結果を問うています。コンテナー1は「少なくとも1つの赤い商品を購入した個人」を、コンテナー2は「少なくとも1つのカテゴリが靴の商品を購入した個人」をフィルタリングします。これらを
        `AND` で結合すると、両方の条件を満たす個人、すなわち「少なくとも1つの赤い商品を購入し、**かつ**、少なくとも1足の靴を購入した個人」が対象となります。これは正答Aの内容と完全に一致します。ドキュメント「購入検索条件」に記載されている、複数の条件コンテナーを
        `AND` で結合する例（カヤックを購入し、かつ安全ベストは購入していない顧客）も、各条件が独立して評価されることを裏付けています。選択肢B（「赤い靴」という単一商品の購入）は、1つのコンテナー内で両方の属性を絞り込んだ場合の結果であり、問題の構成とは異なります。
- question_id: 102
  question_text: City | Is Equal To | 'San Jose' でフィルタリングしたセグメンテーション基準の結果は何ですか?
  choices:
    A: 「San Jose」、「San Jose」、「san jose」、または「san jose」を含む都市
    B: 「San Jose」または「san jose」のみを含む都市
    C: 「San Jose」または「San Jose」のみを含む都市
    D: 「San Jose」または「san jose」のみを含む都市
  correct_answer: D
  japanese_explanation: 「City | Is Equal To | 'San Jose'」でセグメンテーション条件をフィルタリングした結果は、「San
    Jose」または「san jose」を含む都市のみになります。これは、セグメンテーション条件が大文字と小文字を区別し、アクセント記号も区別するため、フィルターに入力された値と完全に一致する場合にのみ一致します1。したがって、「San
    Jose」、「san jose」、「San Jose」を含む都市は、フィルター値と完全に一致しないため、結果に含まれません。「San Jose」という名前に異なるバリエーションを持つ都市を含めるには、OR演算子を使用して複数のフィルター値を追加する必要があります（例：'San
    Jose' OR 'San Jose' OR 'san jose' OR 'san jose'2）。参考：セグメンテーション条件、セグメンテーション演算子
  ai_analysis:
    related_docs:
    - title: '[あいまい] および [完全] 照合方法'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_match_rules_criteria_fuzzy_normalized.htm&language=ja&type=5
      reason: 問題はセグメンテーションにおける「Is Equal To」演算子の動作を問うています。このドキュメントは、ID解決の一致ルールにおける「[完全]
        照合方法」について説明しており、その動作がセグメンテーションの「Is Equal To」演算子に類似していると考えられます。ドキュメントには「大文字と小文字に関係なく値が照合されます」と明記されており、これが「San
        Jose」と「san jose」の両方が一致するという正答の直接的な根拠となります。
      supporting_text: '[完全] 照合方法は、すべてのオブジェクトおよび項目に使用できます。この照合方法を使用するときは、大文字と小文字に関係なく値が照合されます。


        例


        完全一致では大文字と小文字が区別されないため、ソースデータの次の 4 つの値が完全一致に該当します。


        Maryanne

        maryanne

        MARYANNE

        MaryAnne'
    ai_verification:
      status: 一致
      justification: 問題は、セグメンテーション基準の「Is Equal To」演算子が、大文字と小文字を区別せずに完全一致する値を返すことを示唆しています。参照ドキュメント「[あいまい]
        および [完全] 照合方法」では、「[完全] 照合方法」が大文字と小文字に関係なく値を照合すると明確に説明されています。この動作は、正答である「『San
        Jose』または『san jose』のみを含む都市」と完全に一致します。
- question_id: 103
  question_text: 'Visual Insights Builder を使用して計算されたインサイトを作成するときに必要な 2 つの最小要件は何ですか?

    2つの回答を選択してください'
  choices:
    A: 少なくとも1つの小節
    B: 少なくとも1つの次元
    C: 結合するオブジェクトが少なくとも2つ
    D: WHERE句
  correct_answer: A,B
  japanese_explanation: '* Visual Insights Builder の紹介:

    Salesforce Data Cloud の Visual Insights Builder は、既存のデータから派生したカスタム メトリックである計算されたインサイトを作成するために使用されるツールです。

    参照：

    * 計算された洞察を作成するための要件:

    メジャー: メジャーとは、収益、購入数、プラットフォームで費やされた合計時間など、分析する定量的な値です。

    ディメンション: ディメンションは、日付、地域、顧客セグメントなどのメジャーを分類またはフィルタリングするために使用する質的属性です。

    * 計算された洞察を作成する手順:

    Salesforce Data Cloud 内の Visual Insights Builder に移動します。

    「新しいインサイトを作成」を選択し、データセットを選択します。

    少なくとも 1 つのメジャーを追加します。これは、「総売上高」など、分析したい任意の指標になります。少なくとも 1 つのディメンションを追加します。これは、「地域別売上高」など、メジャーを細分化するのに役立ちます。

    * 実用的な応用:

    例: 「地域別の平均購入額」に関するインサイトを作成するには、次のものが必要です。

    測定基準: 合計購入額。

    ディメンション: 顧客地域。

    これにより、パフォーマンスの高い地域を特定するなど、実用的な洞察が得られます。'
  ai_analysis:
    related_docs:
    - title: ビルダーを使用した計算済みインサイトの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_a_calculated_insight_using_builder.htm&language=ja&type=5
      reason: このドキュメントは、Visual Insights Builderを使用して計算済みインサイトを作成する手順を具体的に説明しています。その中で、「基準とディメンションをインサイトに追加します」とあり、さらに「少なくとも
        1 つの基準を選択する必要があります」と明確に記載されています。これは、正答である「少なくとも1つの小節（基準/Measure）」と「少なくとも1つの次元（Dimension）」が最小要件であることを直接裏付けるものです。
      supporting_text: '[集計] をクリックして、基準とディメンションをインサイトに追加します。

        少なくとも 1 つの基準を選択する必要があります。

        [基準] で、[+] をクリックします。

        評価指標関数と計算する項目を選択し、[次へ] をクリックします。

        ...

        [ディメンション] で、[+] をクリックします。

        グループ化の基準となる項目を選択し、[次へ] をクリックします。'
    ai_verification:
      status: 一致
      justification: 公式ドキュメント「ビルダーを使用した計算済みインサイトの作成」には、集計ノードの作成手順として「基準とディメンションをインサイトに追加します」と記載されており、さらに「少なくとも
        1 つの基準を選択する必要があります」と明記されています。ここでの「基準」は選択肢Aの「小節 (Measure)」に、「ディメンション」は選択肢Bの「次元
        (Dimension)」に該当します。集計処理を行うには、集計対象の指標（基準/小節）と、グループ化の単位（次元）の両方が不可欠であるため、これら2つが最小要件であるとする正答は、ドキュメントの記述と完全に一致します。
- question_id: 104
  question_text: どのソリューションが、Marketing Cloud の加入者プロファイル属性を毎日 Data Cloud に取り込む簡単な方法を提供しますか?
  choices:
    A: Automation Studio およびプロファイル ファイル API
    B: マーケティングクラウド接続 API
    C: Marketing Cloud データ拡張機能のデータストリーム
    D: Email Studio スターター データ バンドル
  correct_answer: C
  japanese_explanation: '説明​

    Marketing Cloud の購読者プロファイル属性を Data Cloud に日々簡単に取り込むソリューションが、Marketing Cloud データ拡張機能「データストリーム」です。Marketing
    Cloud データ拡張機能「データストリーム」は、Marketing Cloud データ拡張機能から Data Cloud データスペースにデータをストリーミングできる機能です。ストリーミングするデータ拡張機能を選択すると、Data
    Cloud がデータスペース内に対応するデータモデルオブジェクト (DMO) を自動的に作成し、更新します。

    お客様は、ユーザーインターフェースまたはAPIを使用して、データ拡張フィールドをDMO属性にマッピングすることもできます。Marketing Cloudデータ拡張のデータストリームを使用すると、コードを記述したり複雑な統合を設定したりすることなく、Marketing
    CloudからData Cloudにサブスクライバープロファイル属性などのデータを取り込むことができます。

    その他のオプションは、Marketing Cloud の購読者プロファイル属性を Data Cloud に日常的に簡単に取り込むことができるソリューションではありません。Automation
    Studio と Profile file API は、Marketing Cloud から外部システムにデータをエクスポートするために使用できるツールですが、スクリプトの作成、ファイル転送の設定、自動化のスケジュール設定など、お客様自身で行う必要があります。Marketing
    Cloud Connect API は、Sales Cloud や Service Cloud などの他の Salesforce ソリューションで Marketing
    Cloud のデータにアクセスするために使用できる API ですが、Data Cloud へのデータのストリーミングはサポートしていません。Email Studio
    Starter Data Bundle は、Email Studio 用のサンプルデータとセグメントを含むデータキットですが、購読者プロファイル属性は含まれておらず、Data
    Cloud へのデータのストリーミングもサポートされていません。

    参考文献:

    * マーケティングクラウドデータ拡張データストリーム

    * データクラウドデータ取り込み

    * [Marketing Cloud データ拡張データストリーム API]

    * [マーケティングクラウドコネクトAPI]

    * [Email Studio スターター データ バンドル]'
  ai_analysis:
    related_docs:
    - title: Data Cloud の Marketing Cloud Engagement Starter データバンドル
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_starter_data_bundles.htm&language=ja&type=5
      reason: このドキュメントは、Email Studioのスターターデータバンドルに「エンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリーム」が含まれることを明記しており、これが問題の「加入者プロファイル属性」の取り込みに直接対応します。プロファイル属性がデータストリーム経由で取り込まれることを示しています。
      supporting_text: これらのシステム定義のテーブルに加えて、メールコネクタによってエンタープライズプロファイル属性と呼ばれるユーザー定義のデータストリームが取得されます。このデータは、メールを操作している登録者基盤について人口統計上のコンテキストを提供します。
    - title: Data Cloud での Marketing Cloud Engagement 接続の設定
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_set_up_marketing_cloud_connection.htm&language=ja&type=5
      reason: このドキュメントは、Marketing Cloud Engagementとの接続設定において、データバンドルだけでなく「データエクステンションを手動で追加することもできます」と説明しています。これは、正答である「Marketing
        Cloud データ拡張機能のデータストリーム」が、プロファイル属性を含む任意のデータエクステンションを取り込むための標準的な方法であることを裏付けています。
      supporting_text: データバンドルを使用して、複数のデータストリームをすばやく簡単に作成して Engagement からシステム所有のデータを取得します。後でデータエクステンションを手動で追加することもできます。
    - title: Marketing Cloud Engagement Starter バンドルからのデータストリームの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_marketing_cloud_data_stream.htm&language=ja&type=5
      reason: このドキュメントは、Marketing Cloud EngagementからData Cloudへのデータ取り込みを開始する基本的な方法が「データストリームの作成」であることを示しています。問題で問われている「簡単な方法」として、GUIベースで設定できるデータストリームが正解であることを補強します。
      supporting_text: Marketing Cloud Engagement ソースから Data Cloud へのデータフローを開始するには、スターターバンドルからデータストリームを作成します。
    ai_verification:
      status: 一致
      justification: 問題は、Marketing Cloudの加入者プロファイル属性をData Cloudに取り込む簡単な方法を問うている。正答は「Marketing
        Cloud データ拡張機能のデータストリーム」である。公式ドキュメント「Data Cloud の Marketing Cloud Engagement
        Starter データバンドル」では、Email Studioのバンドルにプロファイル属性を取得するデータストリームが含まれると明記されている。さらに、「Data
        Cloud での Marketing Cloud Engagement 接続の設定」ドキュメントでは、標準のバンドルに加えて「データエクステンションを手動で追加することもできます」とあり、データエクステンションをソースとするデータストリームがプロファイル属性のようなカスタムデータを取り込むための標準的な方法であることが示されている。これらの記述は、正答がドキュメントの内容と完全に一致することを示している。
- question_id: 105
  question_text: '顧客はCRMからData Cloudに取り込むためのマスター顧客テーブルを持っています。このテーブルには、氏名、メインのメールアドレス、その他の個人識別情報（PLL）が含まれています。

    ID 解決をサポートするには、フィールドをどのようにマッピングする必要がありますか?'
  choices:
    A: 入力テーブルに直接一致するフィールドを持つ新しいカスタム オブジェクトを作成します。
    B: すべてのフィールドを Customer オブジェクトにマップします。
    C: 名前を個人オブジェクトにマップし、電子メール アドレスを連絡先電話番号電子メール オブジェクトにマップします。
    D: すべてのフィールドを個人オブジェクトにマップし、電子メール アドレスのカスタム フィールドを追加します。
  correct_answer: C
  japanese_explanation: 'Data Cloud で ID 解決をサポートするには、マスター顧客テーブルのフィールドを、この目的のために設計された標準データモデルオブジェクトにマッピングする必要があります。個人オブジェクトは、顧客の名前やその他の個人識別情報
    (PII) を保存するために使用され、連絡先電話番号メールオブジェクトは、顧客の主要なメールアドレスやその他の連絡先情報を保存するために使用されます。これらのオブジェクトは、連絡先情報が個人に属していることを示すリレーションフィールドによってリンクされています。これらのオブジェクトにフィールドをマッピングすることで、Data
    Cloud は ID 解決ルールを使用して、名前とメールアドレスのフィールドに基づいて、さまざまなソースのプロファイルを照合および調整できます。その他のオプションは、標準データモデルに含まれない新しいカスタムオブジェクトを作成するか、すべてのフィールドを
    ID 解決用ではない顧客オブジェクトにマッピングするか、すべてのフィールドを標準のメールアドレスフィールドを持たない個人オブジェクトにマッピングするため、推奨されません。参考資料:
    ID 解決のためのデータモデリング要件、統合された個人プロファイルの作成'
  ai_analysis:
    related_docs:
    - title: ID 解決一致ルール
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_match_rules.htm&language=ja&type=5
      reason: このドキュメントは、個人のID解決を行う際に、どのデータモデルオブジェクト（DMO）にデータをマッピングする必要があるかを明確に示しています。氏名のような個人情報は「個人」オブジェクトに、メールアドレスは「連絡先メール」オブジェクトにマッピングすることが、一致ルールを機能させるための前提条件であることが分かります。これは正答Cを直接的に裏付ける最も強力な根拠です。
      supporting_text: '一致ルールは特定のオブジェクトでのみ作成できます。使用可能なオブジェクトは、個人と取引先のどちらを照合しているかによって異なります。次のオブジェクトが適切にマッピングされていることを確認し、ID
        解決で使用できるようにします。


        個人を照合する場合 — 個人、連絡先住所、連絡先アプリケーション、連絡先メール、連絡先電話、連絡先ソーシャル、関係者 ID'
    - title: ID 解決のデータモデリング要件
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_data_modeling_requirements.htm&language=ja&type=5
      reason: このドキュメントは、ID解決を成功させるためには、データが正しくマッピングされていることが必須要件であると強調しています。問題はまさにこのデータモデリングの要件について問うており、標準のデータモデルに従う重要性を示唆しています。
      supporting_text: ID 解決でデータを処理して統合プロファイルにまとめるには、データが正しくマッピングされている必要があります。データモデリング要件を確認し、個人、取引先、連絡先データの統合準備が整っていることを確認します。
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: このドキュメントは「統合連絡先オブジェクト」の概念について説明しています。個人が複数の連絡先（電話やメール）を持つ可能性を考慮し、それらを専門のオブジェクトで管理する設計思想を示しています。これにより、メールアドレスを「個人」オブジェクトのカスタムフィールドとして追加するのではなく、専用の「連絡先メール」オブジェクトにマッピングするべき理由が補強されます。
      supporting_text: 個人または取引先には、統合個人または統合取引先ごとに保持する必要がある複数の有効な連絡先がある可能性があります。たとえば、個人に自宅電話番号と携帯電話番号の両方がある場合があります。Data
        Cloud では、各ルールセットのマッピングやルールに基づいてさまざまなデータソースの連絡先を集計する統合連絡先オブジェクトが作成されます。
    - title: ID 解決を使用したセールスデータの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_unify_data_dc4sales.htm&language=ja&type=5
      reason: このドキュメントでは、個人のデータを統合する具体的な手順が示されています。プライマリデータオブジェクトとして「個人」を選択し、一致ルールとして「あいまいな名前と標準化されたメール」を使用することから、名前は「個人」オブジェクトに、メールは専用のオブジェクト（連絡先メール）にマッピングされていることが前提となっていることがわかります。
      supporting_text: 'プライマリデータオブジェクトで、[個人] を選択します。

        ...（中略）...

        一致ルールでは、照合のために確認および使用されるデータが識別されます。このガイドでは、すべてのデフォルトの一致ルールを選択します。

        ...（中略）...

        [あいまいな名前と標準化されたメール] を選択して、[次へ] をクリックします。'
    ai_verification:
      status: 一致
      justification: 問題は、Data CloudのID解決のために顧客の氏名とメールアドレスをどのようにマッピングすべきかを問うています。正答Cは、氏名を「個人」オブジェクトに、メールアドレスを「連絡先メール」オブジェクトにマッピングすることを提案しており、これはSalesforceの標準的なデータモデリングのベストプラクティスです。公式ドキュメント「ID
        解決一致ルール」には、個人のID解決を行う際に使用するオブジェクトとして「個人」と「連絡先メール」が明記されています。これにより、各データが標準データモデルの適切なオブジェクトにマッピングされる必要があることが直接的に裏付けられます。他の選択肢、例えばカスタムオブジェクトの作成（A）や個人オブジェクトへのカスタムフィールド追加（D）は、標準機能の利用を妨げる可能性があるため不適切です。
- question_id: 106
  question_text: 'コンサルタントは、先ほど設定したID解決を確認したいと考えています。統合プロファイルのデータを検証するために、コンサルタントが使用できる2つの機能はどれですか？

    2つの回答を選択してください'
  choices:
    A: アイデンティティ解決
    B: データアクション
    C: データエクスプローラー
    D: クエリAPI
  correct_answer: C,D
  japanese_explanation: 'ID解決の設定後、統合プロファイル上のデータを検証するために、コンサルタントはデータエクスプローラーとクエリAPIを使用できます。その理由は次のとおりです。

    アイデンティティ解決検証について

    ID 解決では、複数のソースからのデータを統合されたプロファイルに結合します。

    統合プロファイルを検証することで、解決プロセスが正しく機能していること、およびデータが正確であることが保証されます。

    データ エクスプローラーとクエリ API を使用する理由

    データエクスプローラー:

    Data Explorer は、Salesforce Data Cloud に組み込まれているツールで、ユーザーは統合されたプロファイルを表示および分析できます。

    解決された ID や関連属性など、個々のプロファイルの詳細なビューを提供します。

    クエリAPI:

    クエリ API を使用すると、統合プロファイルおよび関連データへのプログラムによるアクセスが可能になります。

    コンサルタントは API を使用して特定のプロファイルを照会し、ID 解決の結果をプログラムで検証できます。

    その他のオプションはあまり適していません:

    A. アイデンティティ解決: これは検証のためのツールではなく、プロセスそのものを指します。

    B. データアクション: データアクションは、統合プロファイルの検証ではなく、ワークフローまたは統合をトリガーするために使用されます。

    統合プロファイルを検証する手順

    データエクスプローラーの使用:

    [データ クラウド] > [データ エクスプローラー] に移動します。

    特定のプロファイルを検索し、解決された ID と属性を確認します。

    データが ID 解決ルールに基づいて期待どおりに一致していることを確認します。

    クエリ API の使用:

    クエリ API を使用して、統合プロファイルをプログラムで取得します。

    結果を予想される結果と比較して、正確性を確認します。

    結論

    コンサルタントは、データ エクスプローラーとクエリ API を使用して統合プロファイルのデータを検証し、ID 解決が意図したとおりに機能していることを確認する必要があります。'
  ai_analysis:
    related_docs:
    - title: 個人 ID の取得
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_consent_obtaining_individual_id.htm&language=ja&type=5
      reason: 正答の一つである「クエリAPI」が、ID解決によって生成された統合プロファイルのデータ（具体的には個人ID）を取得・検証するために使用できると明確に記載されているため。
      supporting_text: 個人 ID は、セグメンテーション、ソースシステム、クエリ API の 3 つの異なる方法で取得できます。...クエリ
        API に要求を送信することで、個人 ID を取得できます。メールアドレス、電話番号、または名と姓を使用して、クエリ API に要求を送信します。
    - title: ID 解決でのスケジュール済み一致とリアルタイム一致
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution_match_type_compare.htm&language=ja&type=5
      reason: このドキュメントには、ID解決の結果である統合プロファイル情報が「統合個人データモデルオブジェクトに保存されます」と記載されています。データエクスプローラーはデータモデルオブジェクトのレコードを直接表示・確認するための標準機能であるため、これを用いてID解決の結果を検証できることの根拠となります。
      supporting_text: 更新された統合プロファイル情報は、統合取引先または統合個人データモデルオブジェクトに保存されます。
    ai_verification:
      status: 一致
      justification: '正答である「データエクスプローラー」と「クエリAPI」は、ID解決の結果である統合プロファイルのデータを検証するための適切なツールです。

        1. **データエクスプローラー**: ドキュメント「ID 解決でのスケジュール済み一致とリアルタイム一致」に記載の通り、ID解決の結果は「統合個人データモデルオブジェクト」に保存されます。データエクスプローラーは、これらのデータモデルオブジェクト内のレコードを直接UI上で確認するための機能であり、データの検証に直接使用できます。

        2. **クエリAPI**: ドキュメント「個人 ID の取得」で「クエリ API に要求を送信することで、個人 ID を取得できます」と明記されており、API経由で統合プロファイルのデータにアクセスし、検証できることがわかります。

        その他の選択肢（A: アイデンティティ解決、B: データアクション）は、ID解決のプロセス自体や、結果を利用してアクションを起こす機能であり、データの「検証」を主目的とするツールではないため、不適切です。'
- question_id: 107
  question_text: 'Northern Trail Outfitters は、Data Cloud インスタンスで個人を統合します。

    統合プロファイル上のデータを検証するためにコンサルタントが使用できる 3 つの機能はどれですか?

    3つの回答を選択してください'
  choices:
    A: アイデンティティ解決
    B: APL をクエリする
    C: データエクスプローラー
    D: プロファイルエクスプローラー
    E: データアクション
  correct_answer: A,C,D
  japanese_explanation: '統合プロファイル上のデータを検証するために、コンサルタントは次の機能を使用できます。

    アイデンティティ解決: この機能により、コンサルタントは、さまざまなデータ ソースから個人を統合する方法を決定するアイデンティティ解決ルール セットを表示および編集できます1。

    データ エクスプローラー: この機能により、コンサルタントは統合プロファイルを参照およびフィルタリングし、その属性、セグメント、アクティビティを表示できます2。

    プロファイルエクスプローラー：この機能により、コンサルタントは特定の統合プロファイルをドリルダウンし、ソースレコード、アイデンティティグラフ、計算されたインサイト、データアクションなどの詳細を表示できます3。参考：

    1: データクラウドにおけるID解決

    2: データクラウドのデータエクスプローラー

    3: データクラウドのプロファイルエクスプローラー'
  ai_analysis:
    related_docs:
    - title: データ主体の権利の要求
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_subject_rights_request.htm&language=ja&type=5
      reason: 正答の一つである「アイデンティティ解決」によって生成される「統合個人プロファイル」が、複数のソースプロファイルから構成されることを具体例を挙げて説明しており、検証対象のデータを理解する上で参考になるため。
      supporting_text: Northern Trail Outfitters (NTO) には、2 つのソース個人プロファイルで構成される Samantha
        Smith の統合個人プロファイルがあります。これらのソース個人プロファイルは、個人 ID 1234 および 5678 として識別されます。
    - title: 'Customer 360 データモデル: 個人および連絡先'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_cloud_information_model_individual_and_contact_points.htm&language=ja&type=5
      reason: 正答の一つである「アイデンティティ解決」プロセスと、検証対象である統合プロファイルの健全性を保つ上で「個人 ID」が重要であることを説明しているため。
      supporting_text: ID 解決を動作させて、データセグメントを作成するときに正確なデータを受け取るには、インポートしたデータの顧客識別子を
        [個人 ID] 項目にマッピングする必要があります。個人 ID オブジェクトは、Data Cloud のデータの健全性を保つために重要です。
    ai_verification:
      status: 一致
      justification: 問題はData Cloudで統合された個人プロファイルの検証方法を尋ねています。正答である「アイデンティティ解決」「データエクスプローラー」「プロファイルエクスプローラー」は、この目的のための標準的な機能です。「アイデンティティ解決」は、統合のルールや結果を確認する機能を提供し、検証に不可欠です。「データエクスプローラー」は統合プロファイルを含むDMO（データモデルオブジェクト）のレコードレベルのデータを確認できます。「プロファイルエクスプローラー」は、特定の統合プロファイルを検索し、その属性や関連データを視覚的に検証するために特化したUIです。これら3つは、統合プロファイルのデータを検証するための直接的な手段として適切です。
- question_id: 108
  question_text: 'Cumulus Financialは現在、Data Cloudを活用し、S3コネクタを介してバックエンドシステムから取引データをアップサートモードで取り込みています。6ヶ月前の初期設定時に、同社はData
    Cloudにカスタム分類を作成するための数式フィールドを作成しました。現在、より多くの分類に対応するために、この数式を更新する必要があります。

    S3 コネクタを使用する場合、コンサルタントは数式フィールドの更新に関してどのような点に留意する必要がありますか?'
  choices:
    A: Data Cloud は $3 からデータの完全更新を開始し、すべてのレコードの数式を更新します。
    B: Data Cloud は、新しいレコードに対してのみ、今後数式を更新します。
    C: Data Cloud は、upsert タイプのデータ ストリームの数式フィールドの更新をサポートしていません。
    D: Data Cloud は、次回の増分アップサート更新時にすべてのレコードの数式を更新します。
  correct_answer: D
  japanese_explanation: '数式フィールドとは、他のフィールドまたは定数に基づいて値を計算するフィールドです。S3 コネクタを使用して Amazon
    S3 バケットからデータを取り込む場合、Data Cloud は、S3 ソースのデータを格納するデータレイクオブジェクト (DLO) 上の数式フィールドの作成と更新をサポートします。ただし、数式フィールドの更新はすぐには適用されず、データストリームの次回の増分アップサート更新時に適用されます。増分アップサート更新とは、主キーフィールドに基づいて、S3
    ソースから DLO に新しいレコードを追加し、既存のレコードを更新するプロセスです。したがって、コンサルタントは、数式フィールドの更新は新しいレコードと既存のレコードの両方に影響しますが、データストリームの次回の増分アップサート更新後にのみ適用されることを念頭に置く必要があります。Data
    Cloud は S3 からのデータの完全更新を開始せず、新しいレコードに対してのみ数式を更新せず、アップサートタイプのデータストリームに対する数式フィールドの更新をサポートしているため、他のオプションは正しくありません。参考資料:
    数式フィールドの作成、Amazon S3 接続、Data Lake オブジェクト'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供された公式ドキュメントには、Data Cloudのデータストリーム（特にS3コネクタのアップサートモード）において、既存の数式フィールドを更新した場合の再計算の挙動について明確な記述が見つかりません。正答である「次回の増分アップサート更新時にすべてのレコードの数式を更新する」という具体的な動作を裏付ける、または否定する情報がドキュメント内に存在しないため、提示された情報だけでは正誤を判断することができません。
- question_id: 109
  question_text: '正常に構成された Amazon S3 データストリームが「ファイルが見つかりません」というエラーメッセージで更新に失敗した場合、コンサルタントが実行する必要がある
    2 つの手順はどれですか?

    2つの回答を選択してください'
  choices:
    A: Data Cloud ユーザーに正しい権限が設定されているかどうかを確認します。
    B: Data Cloud セットアップで Amazon S3 データ ソースが有効になっているかどうかを確認します。
    C: 指定されたバケットの場所にファイルが存在するかどうかを確認します。
    D: S3 ユーザーに正しい権限が設定されているかどうかを確認します。
  correct_answer: A,C
  japanese_explanation: '「ファイルが見つかりません」というエラーメッセージは、Data Cloud が Amazon S3 ソースのファイルにアクセスできない、またはファイルを見つけられないことを示します。このエラーには
    2 つの原因が考えられ、コンサルタントがトラブルシューティングを行うために実行する必要がある 2 つの手順があります。

    Data Cloud ユーザーに、Amazon S3 バケットからファイルを読み取るための適切な権限がありません。これは、ユーザーの権限セットまたはプロファイルに
    Data Cloud データストリームの読み取り権限が含まれていない場合、またはユーザーの Amazon S3 認証情報が無効または期限切れの場合に発生する可能性があります。この問題を解決するには、コンサルタントが
    Data Cloud と Amazon S3 でそれぞれユーザーの権限と認証情報を確認し、更新する必要があります。

    指定されたバケットの場所にファイルが存在しません。ファイル名またはパスが変更された場合、またはファイルがAmazon S3バケットから削除または移動された場合に発生する可能性があります。この問題を解決するには、コンサルタントはAmazon
    S3バケット内のファイル名とパスを確認し、それに応じてData Cloudのデータストリーム設定を更新する必要があります。参考資料：Data CloudでAmazon
    S3データストリームを作成する、Data CloudでAmazon S3ストレージコネクタを使用する方法、Amazon S3接続'
  ai_analysis:
    related_docs:
    - title: 非構造化データワークフロー
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_unstructured_data_workflow.htm&language=ja&type=5
      reason: 正答A「Data Cloud ユーザーに正しい権限が設定されているかどうかを確認します。」を直接裏付けている。このドキュメントには、非構造化データをData
        Cloudに取り込むために必要な特定のユーザー権限セットが明記されており、権限の確認がトラブルシューティングの重要なステップであることを示しています。
      supporting_text: '必要なユーザー権限

        非構造化データを取り込んで検索インデックスを作成する


        次のいずれかの権限セット:


        Data Cloud 管理者

        Data Cloud Marketing Admin (Data Cloud マーケティング管理者)

        Data Cloud データアウェアスペシャリスト'
    - title: ファイルストレージ有効化対象の作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_cloud_file_storage_activation_target.htm&language=ja&type=5
      reason: 正答C「指定されたバケットの場所にファイルが存在するかどうかを確認します。」は、「ファイルが見つかりません」というエラーメッセージに対する最も基本的なトラブルシューティングです。このドキュメントは、S3バケット内のオブジェクトにアクセスするために`s3:GetObject`や`s3:ListBucket`といった権限が必要であることを示しています。これらの権限を行使する対象であるファイル自体が存在しなければ、当然エラーが発生するため、ファイルの存在確認が根本的な原因究明の第一歩となります。
      supporting_text: S3 ログイン情報は、s3:PutObject、s3:GetObject、s3:ListBucket、s3:DeleteObject、s3:GetBucketLocation
        の権限を持っている必要があります。
    ai_verification:
      status: 一致
      justification: '正答Aは、「非構造化データワークフロー」ドキュメントに記載されている、データ取り込みに必要なData Cloudユーザーの権限セットによって直接支持されています。正答Cは、「ファイルが見つかりません」というエラーメッセージから論理的に導かれる最も基本的なトラブルシューティング手順です。提供されたドキュメントにはこの手順が直接記載されていませんが、S3へのアクセスにはファイルへのアクセス権限（例:
        s3:GetObject）が必要であり、その大前提としてファイルが存在する必要があるため、この確認ステップは妥当です。したがって、両方の解答はドキュメントの内容と論理的なトラブルシューティングプロセスに整合しています。'
- question_id: 110
  question_text: セグメンテーションまたはアクティベーションを実行する場合、データの公開と更新にはどのタイムゾーンが使用されますか?
  choices:
    A: アクティビティ作成時に指定されたタイムゾーン
    B: アクティビティを作成したユーザーのタイムゾーン
    C: データクラウド管理者ユーザーのタイムゾーン
    D: Salesforce Data Cloud 組織によって設定されたタイムゾーン
  correct_answer: D
  japanese_explanation: セグメンテーションまたはアクティベーションを実行する際にデータの公開と更新に使用されるタイムゾーンはDです。Salesforce
    Data Cloud組織によって設定されるタイムゾーンです。このタイムゾーンは、Data Cloudのプロビジョニング時に組織設定で設定されるもので、Data
    Cloud内のすべてのユーザーとアクティビティに適用されます。このタイムゾーンによって、セグメントの更新スケジュールとアクティベーションの公開スケジュールが決まります。したがって、セグメンテーションとアクティベーションの戦略を計画する際には、Data
    Cloud組織と対象システムまたはチャネル間のタイムゾーン差を考慮することが重要です。参考：Salesforce Data Cloudコンサルタント試験ガイド、セグメンテーション、アクティベーション
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 問題は、Data Cloudのセグメンテーションやアクティベーション実行時に使用されるタイムゾーンについて尋ねています。正答は「Salesforce
        Data Cloud 組織によって設定されたタイムゾーン」ですが、提供されたどのドキュメントにも、タイムゾーンに関する具体的な仕様や、どのレベル（組織、ユーザーなど）の設定が適用されるかを直接裏付ける記述が見つかりませんでした。そのため、提供された情報だけでは正答の正しさを検証できません。
- question_id: 111
  question_text: 'Northern Trail Outfitters (NTO) は、あいまい名と正規化された電子メールに基づいて ID 解決ルール
    セットを構成しています。

    最適な電子メール アドレスが確実にアクティブ化されるようにするには、NTO は何をすべきでしょうか?'
  choices:
    A: 連絡先メール オブジェクトの Is Active フィールドを一致ルールとして含めます。
    B: アクティベーションでソースの優先順位を使用して、目的のソースからのコンタクト ポイントがアクティベーション ターゲットに配信されるようにします。
    C: ソース優先度調整ルールで、Marketing Cloud が最初のデータ ソースとして優先されていることを確認します。
    D: デフォルトの調整ルールを「最終更新日」に設定します。
  correct_answer: B
  japanese_explanation: NTOは、あいまい名前と正規化されたメールアドレスを一致ルールとして使用し、異なるソースからのデータを統合された個人プロファイルにリンクしています。しかし、複数のソースから同じメールアドレスが取得される場合があり、NTOはアクティベーションに使用するアドレスを決定する必要があります。例えば、レイチェルがService
    CloudとMarketing Cloudに同じメールアドレスを持っているものの、NTOからの連絡をMarketing Cloud経由で受信することを希望している場合、NTOはMarketing
    Cloudのメールアドレスがアクティベーションされるようにする必要があります。そのために、NTOはアクティベーションにおいてソースの優先順位を使用できます。これにより、アクティベーションの優先順位に従ってデータソースをランク付けできます。Marketing
    CloudをService Cloudよりも高いソース優先順位に設定することで、NTOはMarketing Cloudのメールアドレスがメールキャンペーンやジャーニーなどのアクティベーション対象に確実に配信されるようにすることができます。これにより、NTOはレイチェルの希望を尊重し、より良いカスタマーエクスペリエンスを提供できます。参考資料：アクティベーションの設定、アクティベーションにおけるソースの優先順位の使用
  ai_analysis:
    related_docs:
    - title: ソースプロファイルの統合
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_identity_resolution.htm&language=ja&type=5
      reason: 問題で言及されている「ID 解決ルール セット」について説明しており、それが一致ルールと調整ルールで構成されることを述べているため、問題の背景理解に役立ちます。ただし、正答である「アクティベーションでのソースの優先順位」を直接裏付ける記述はありません。
      supporting_text: ルールセットには、複数のデータソースを統合プロファイルにリンクする方法を Customer Data Platform
        に指示する一致ルールと調整ルールが含まれます。統合プロファイル情報は、ルールセットによって作成されたデータモデルオブジェクトに保存されます。
    - title: 'Customer 360 データモデル: 個人および連絡先'
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_cloud_information_model_individual_and_contact_points.htm&language=ja&type=5
      reason: 問題は「電子メール」というコンタクトポイントを扱っており、このドキュメントはData Cloudにおける「連絡先メール」オブジェクトの定義を示しているため、問題の構成要素を理解する上で関連があります。
      supporting_text: "オブジェクト種別\t内容\t例\n連絡先メール\t個人のメールアドレス\tinfo@northerntrailoutfitters.com"
    ai_verification:
      status: 判断不能
      justification: 問題は、ID解決後の統合プロファイルをアクティベーションする際に、複数のソースから提供された電子メールの中から最適なものを選択する方法を問うています。正答は「アクティベーションでのソースの優先順位」という機能を示唆しています。しかし、提供された公式ドキュメントの候補には、ID解決の概要やデータモデルに関する記述はあるものの、「アクティベーション時のソース優先順位」という特定の機能について直接説明している箇所が見当たりませんでした。そのため、提供された情報だけでは正答の妥当性を検証できません。
- question_id: 112
  question_text: Amazon S3 にアクティブ化するときに .csv ファイルで提供される情報はどれですか?
  choices:
    A: セグメントをアクティブ化したユーザーとアクティブ化した日時を示す監査ログ
    B: アクティブ化されたデータペイロード
    C: セグメント定義に関するメタデータ
    D: Data Cloud 内のオリジンソースのマニフェスト
  correct_answer: B
  japanese_explanation: Amazon S3 にアクティブ化する場合、.csv ファイルで提供される情報は、アクティブ化データペイロードです。アクティブ化データペイロードは、Data
    Cloud からアクティブ化ターゲット (この場合は Amazon S3 バケット) に送信されるデータです1。アクティブ化データペイロードには、アクティブ化されるセグメントに含まれる個人またはエンティティの属性と値が含まれます2。アクティブ化データペイロードは、マーケティング、営業、サービス、分析など、さまざまな目的に使用できます3。その他のオプションは、Amazon
    S3 にアクティブ化するときに .csv ファイルで提供されないため、正しくありません。オプション A は、監査ログが .csv ファイルで提供されないため、正しくありませんが、Data
    Cloud UI の [アクティベーション履歴] タブで表示できます4。オプション C は、セグメント定義に関するメタデータが .csv ファイルで提供されないため、正しくありませんが、Data
    Cloud UI の [セグメンテーション] タブで表示できるため、正しくありません5。選択肢Dは不正解です。データクラウド内のオリジンソースのマニフェストは.csvファイルでは提供されていませんが、データクラウドUIの「データソース」タブで確認できます。参考資料：データアクティベーションの概要、データクラウドでのセグメントの作成とアクティベーション、データアクティベーションのユースケース、アクティベーション履歴の表示、セグメンテーションの概要、[データソースの概要]
  ai_analysis:
    related_docs:
    - title: ファイルストレージ有効化対象の作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_cloud_file_storage_activation_target.htm&language=ja&type=5
      reason: このドキュメントは、Amazon S3などのファイルストレージを有効化対象とした際に出力されるファイルについて具体的に説明しています。「追加の属性を持つセグメントメンバーを含むデータファイル」がCSV形式で出力されると明記されており、これが問題の正答である「アクティブ化されたデータペイロード」と直接的に一致します。
      supporting_text: '有効化対象が作成され、次の項目がファイルストレージ有効化プラットフォームに追加されます。


        セグメント定義を記述するメタデータファイル。

        追加の属性を持つセグメントメンバーを含むデータファイル。

        ... CSV 形式の出力ファイル:'
    - title: クラウドファイルストレージでの外部有効化プラットフォームセグメントの検索
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_package_external_activation_platform_find_metadata.htm&language=ja&type=5
      reason: このドキュメントは、S3に出力されるファイルとして「メタデータファイル」と「有効化出力ファイル」が別々に存在することを説明しています。これにより、CSVファイルに含まれるのは「有効化出力ファイル」、つまりデータペイロードであり、選択肢Cの「メタデータ」は別のファイルであることが裏付けられます。
      supporting_text: 有効化対象ごとに、ユーザー識別子で出力がグループ化されている場合 (PER_USER)、ID 種別ごとに 1 日 1
        回、成功ファイル、メタデータファイル、有効化出力ファイルを受け取ります。...セグメントは 24 時間ごとに複数の CSV、NSVSON、Parquet
        ファイルとして公開されます。
    - title: ファイル名の例 (SFTP、GCS、Azure)
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_file_name_examples.htm&language=ja&type=5
      reason: このドキュメントは、アクティベーションによって生成されるCSVファイルの具体的な命名規則の例を挙げています。ファイル名がセグメント名と有効化名に基づいていることから、このCSVファイルがセグメントのアクティベーション結果（データペイロード）を格納していることを補強します。
      supporting_text: "ファイル名\t説明\nTeenagersInNewyork_EmailCampaign_2023-07-30-17-55-45-216_00000.csv\t\
        \n\n非圧縮/非暗号化 CSV ファイル (日付/時刻のサフィックス付き)。このファイル名は、セグメント名と有効化名に基づいて事前に決定されます。"
    ai_verification:
      status: 一致
      justification: 公式ドキュメント「ファイルストレージ有効化対象の作成」において、Amazon S3へのアクティベーション時に「追加の属性を持つセグメントメンバーを含むデータファイル」が「CSV
        形式の出力ファイル」として提供されると明確に記載されています。これは選択肢Bの「アクティブ化されたデータペイロード」と完全に一致します。また、同ドキュメントや「クラウドファイルストレージでの外部有効化プラットフォームセグメントの検索」では、「メタデータファイル」がデータファイルとは別に出力されることが示されており、選択肢Cが不正解であることも裏付けています。
- question_id: 113
  question_text: 'Cumulus Financialの採用チームは、過去24時間以内にウェブサイトの求人ページを2回以上閲覧した候補者を特定したいと考えています。これらの候補者に関する情報をData
    Cloudでセグメンテーションに利用し、採用システムに追加したいと考えています。

    この目標を達成するためにコンサルタントはどの機能を推奨すべきでしょうか?'
  choices:
    A: ストリーミングデータ変換
    B: ストリーミングの洞察
    C: 計算された洞察力
    D: バッチバタ変換
  correct_answer: B
  japanese_explanation: 'ストリーミングインサイトは、ウェブやモバイルイベントなどのストリーミングデータソースからリアルタイムのメトリクスを作成・監視できる機能です。また、ストリーミングインサイトは、メトリクスの値と条件に基づいて、通知の送信、レコードの作成、フィールドの更新といったデータアクションをトリガーすることもできます。したがって、ストリーミングインサイトは、過去24時間以内にウェブサイトの求人ページを2回以上閲覧した候補者を特定し、採用システムに追加するという目標を達成するのに最適な機能です。その他の選択肢は、以下の理由により誤りです。

    * ストリーミングデータ変換は、SQL式を使用してストリーミングデータを変換・拡充できる機能です。フィルタリング、結合、集計、値の計算などが可能です。ただし、ストリーミングデータ変換では、メトリクスを監視したり、条件に基づいてデータアクションをトリガーしたりすることはできません。

    * 計算インサイトとは、SQL式を用いてLTV、CSAT、平均注文額といった多次元指標をデータから定義・計算できる機能です。ただし、計算インサイトはスケジュールに基づいて実行され、データソースをサポートしていないため、リアルタイムデータ分析には適していません。

    * アクション。

    * バッチ データ変換は、データの結合、集計、フィルタリング、追加など、ビジュアル エディターを使用して複雑なデータ変換を作成およびスケジュールできる機能です。

    ただし、バッチ データ変換はスケジュールに基づいて実行され、データアクションをサポートしていないため、リアルタイムのデータ分析には適していません。参考資料:
    ストリーミング インサイト、ストリーミング インサイトの作成、データクラウドでのインサイトの使用、データクラウド インサイトの学習、SQL を使用したデータクラウド
    インサイト、ストリーミング データ変換、データクラウドでのバッチ データ変換の開始、バッチ データ変換の変換、データクラウドでのバッチ データ変換: クイック
    ルック、Salesforce データクラウド: AI CDP。'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供されたドキュメントには、問題の正解である「ストリーミングの洞察」という機能名や、その具体的な機能（指定した時間枠内でのイベントの集計）に関する直接的な記述が見つかりませんでした。問題は、リアルタイムに近いイベント（過去24時間以内の複数回の閲覧）に基づいて候補者を特定する機能を問うていますが、提供されたドキュメントは主にData
        CloudとMarketing Cloudの連携、バッチ処理ベースのセグメンテーション、およびジャーニー作成のユースケースに焦点を当てています。そのため、これらのドキュメントから正解が「ストリーミングの洞察」であることを直接的に裏付けることはできません。
- question_id: 114
  question_text: 'Northern Trail Outfitters（NTO）は、過去6ヶ月以内に商品を購入した顧客を対象にプロモーションキャンペーンを実施したいと考えています。コンサルタントはこの要件を満たすセグメントを作成しました。

    現在、NTO は過去 1 週間以内に購入した顧客を抑制するための追加要件を導入しています。

    コンサルタントは最近の顧客を削除するために何を使用すべきでしょうか?'
  choices:
    A: バッチ変換
    B: セグメンテーション除外ルール
    C: 関連属性
    D: ストリーミングの洞察
  correct_answer: B
  japanese_explanation: 'コンサルタントは、B. セグメンテーション除外ルールを使用して最近の顧客を除外する必要があります。セグメンテーション除外ルールは、特定の条件を満たすレコードを除外するためにセグメントに適用できるフィルターです。コンサルタントは、セグメンテーション除外ルールを使用して、過去6ヶ月以内に購入した顧客を含むセグメントから、過去1週間以内に購入した顧客を除外することができます。これにより、セグメントにはプロモーションキャンペーンの対象となる顧客のみが含まれます。

    その他の選択肢は正しくありません。選択肢Aは不正解です。バッチ変換は、データストリームまたはデータレイクオブジェクトに適用してデータを変更または拡充できるデータ処理タスクです。バッチ変換はセグメンテーションやアクティベーションには使用されません。選択肢Cは不正解です。関連属性は、データモデルオブジェクト間の関係から派生する属性です。関連属性は、セグメントからレコードを除外するために使用されません。選択肢Dは不正解です。ストリーミングインサイトは、データ取り込み時に計算される派生属性です。ストリーミングインサイトは、セグメントからレコードを除外するために使用されません。参考資料：Salesforce
    Data Cloud Consultant 試験ガイド、セグメンテーション、セグメンテーション除外ルール'
  ai_analysis:
    related_docs:
    - title: Data Cloud での Einstein セグメントの適切なプロンプトの記述方法
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_create_segment_einstein_prompts.htm&language=ja&type=5
      reason: このドキュメントには、Einsteinを使用したセグメント作成プロンプトにおいて「Exclude 演算子は使用できません」と明記されています。これは、Data
        Cloudのセグメンテーション機能に「除外」を行うための専用の機能（UIベースの除外ルールなど）が存在することを示唆しており、問題で問われている「セグメンテーション除外ルール」が正しい選択肢であることを間接的に裏付けています。
      supporting_text: プロンプトを作成するときは、正確な説明テキストを入力します。次の演算子を使用して、情報を指定します。プロンプトを記述する場合、OR
        演算子と Exclude 演算子は使用できません。
    - title: コンテナと属性を使用した絞り込み
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_container_basics.htm&language=ja&type=5
      reason: 問題は、特定の条件（過去1週間以内の購入）に基づいて顧客を除外（抑制）すること、つまりセグメントをさらに絞り込む方法を問うています。このドキュメントは、セグメント作成における属性や検索条件を使用した「絞り込み」の基本概念を説明しており、セグメントの除外が絞り込み操作の一環であることを示しています。
      supporting_text: 1 つのインターフェースとセグメント内で構造化データと非構造化データの両方を絞り込むことができます。
    - title: セグメンテーションでの同意設定の使用
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_using_consent_preferences_in_segmentation.htm&language=ja&type=5
      reason: このドキュメントは、特定の属性（同意状況）を検索条件として使用し、セグメントの対象者を絞り込む具体例を挙げています。問題の要件である「購入履歴に基づいて顧客を除外する」ことと、このドキュメントの「同意設定に基づいて顧客を絞り込む」ことは、どちらも特定の条件でセグメント対象者をフィルタリングする点で類似しており、属性ベースのルールでセグメントを制御する概念を補強します。
      supporting_text: たとえば、Northern Trail Outfitters は、メールコミュニケーションをオプトインし、プロモーションをオプトアウトしていない個人のセグメントを作成しました。セグメントに個人の同意設定が反映されるように、[同意状況]
        属性を検索条件として使用します。
    ai_verification:
      status: 一致
      justification: 問題は、定義済みのセグメント（過去6ヶ月以内に購入した顧客）から、特定の条件（過去1週間以内に購入した顧客）に合致する集団を除外（抑制）する方法を尋ねています。Data
        Cloudのセグメンテーション機能では、このような要件を満たすために、既存のセグメントから別のセグメントや属性条件に合致する対象者を除外する「除外ルール」が提供されています。したがって、「セグメンテーション除外ルール」が正解です。他の選択肢（バッチ変換、関連属性、ストリーミングの洞察）は、セグメントのフィルタリングや除外を行う直接的な機能ではありません。
- question_id: 115
  question_text: 'Northern Trail Outfitters は、Data Cloud に取り込まれる新しい顧客データを毎日 Amazon
    S3 バケットにアップロードします。

    新しくインポートされたデータがどのセグメントでも使用可能であることを確認するには、各プロセスをどのような順序で実行する必要がありますか?'
  choices:
    A: 計算されたインサイト > データストリームの更新 > ID解決
    B: データストリームの更新 > 計算された洞察 > ID解決
    C: アイデンティティ解決 > データストリームの更新 > 計算された洞察
    D: データストリームの更新 > アイデンティティ解決 > 計算された洞察
  correct_answer: D
  japanese_explanation: 'Amazon S3 バケットから新しくインポートされたデータが準備完了し、どのセグメントでも使用できるようにするには、次のプロセスをこの順序で実行する必要があります。

    データストリームの更新：このプロセスは、ソースシステムからの最新データでデータクラウド内のデータレイクオブジェクトを更新します。データストリーム設定1に応じて、自動または手動で実行するように設定できます。データストリームを更新することで、Amazon
    S3バケットからの最新かつ正確なデータがデータクラウドに確実に提供されます。

    アイデンティティ照合：このプロセスは、アイデンティティ照合ルールセットに基づいて、異なるデータストリームからのソースプロファイルを照合・統合することで、統合された個人プロファイルを作成します。デフォルトでは毎日実行されますが、手動で実行することも可能です2。アイデンティティ照合により、Data
    Cloudは異なるデータソースにまたがる各顧客の単一ビューを確保します。

    計算されたインサイト：このプロセスは、データレイクオブジェクトまたはCRMデータに対して計算を実行し、結果を新しいデータオブジェクトとして返します。セグメンテーションや分析のための指標や指標の作成に使用できます3。計算されたインサイトにより、パーソナライゼーションやアクティベーションに使用できる派生データがData
    Cloudに確実に提供されます。

    参照：

    1: データストリームの更新と頻度を設定する - Salesforce

    2: アイデンティティ解決ルールセットの処理結果 - Salesforce

    3: 計算された洞察 - Salesforce'
  ai_analysis:
    related_docs:
    - title: データフロー
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_flow.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudにおけるデータの流れの全体像を説明しています。まずデータソースからデータが「取り込まれ」、その後に「操作、ハーモナイズ、またはセグメント化される」と記述されており、問題で問われているプロセスの基本的な順序（データ取り込み
        → 処理 → 活用）を裏付けています。「ハーモナイズ」にはID解決や計算されたインサイトが含まれると解釈でき、正答の順序性と整合します。
      supporting_text: データソースは、さまざまな方法で Data Cloud に取り込まれるか、Data Cloud に接続されます。...Data
        Cloud でデータが操作、ハーモナイズ、またはセグメント化されたら、データを SFTP (2) などのターゲット (1) に送信したり、Snowflake
        などのインテグレーションと共有したりできます。
    ai_verification:
      status: 一致
      justification: 正答で示されたプロセスの順序は、Data Cloudにおけるデータ活用の論理的なステップと一致します。まず、外部ソース（Amazon
        S3）から「データストリームの更新」によってデータをData Cloudに取り込む必要があります。次に、取り込まれたデータを他のデータと統合し、個人の統一プロファイルを作成するために「ID解決」を実行します。その後、統合されたデータに基づいて高度な指標を計算する「計算されたインサイト」を実行できます。これらのプロセスがこの順序で完了して初めて、最新のデータがセグメントで利用可能になります。この順序はData
        Cloudの機能間の依存関係を正しく反映しています。
- question_id: 116
  question_text: '顧客は、閲覧放棄行動に基づいてジャーニーをトリガーするための要件を概説しました。コンサルタントは、この要件に基づき、ストリーミングインサイトを使用して、Journey
    Builderへのデータアクションを1時間ごとにトリガーすることを決定しました。

    データアクションが必要な頻度でトリガーされるようにするには、コンサルタントはどのようにソリューションを構成する必要がありますか?'
  choices:
    A: アクティベーションスケジュールを時間ごとに設定します。
    B: データを 1 時間ごとに一括して取り込むように設定します。
    C: 旅程エントリスケジュールを 1 時間ごとに実行するように設定します。
    D: インサイトの集計時間ウィンドウを 1 時間に設定します。
  correct_answer: C
  japanese_explanation: 'Explanation:'
  ai_analysis:
    related_docs:
    - title: Journey Builder の Welcome シリーズの作成
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_ra_welcome_series.htm&language=ja&type=5
      reason: このドキュメントには、Journey Builderでジャーニーを定期的に実行するためのスケジュール設定について具体的な手順が記載されています。問題の要件である「1時間ごと」のトリガーは、このスケジュール設定機能で実現可能であることを示唆しており、正答C「旅程エントリスケジュールを
        1 時間ごとに実行するように設定します。」を直接裏付けています。
      supporting_text: 'このジャーニーを継続中のキャンペーンにするには、[スケジュール]、[定期的]、[選択] の順にクリックします。

        [開始日]、[開始時間]、[タイムゾーン] を選択します。このキャンペーンでは、[週単位]、曜日に [月曜日]、終了に [なし] を選択します。'
    ai_verification:
      status: 一致
      justification: 問題は、Journey Builderのジャーニーを1時間ごとに実行する方法を問うています。データアクションやストリーミングインサイトはデータソースの準備段階であり、ジャーニーの実行頻度を直接制御するのはJourney
        Builder自体のスケジュール設定です。公式ドキュメント「Journey Builder の Welcome シリーズの作成」では、データエクステンションをエントリソースとするジャーニーに対して、定期的な実行スケジュール（例：週単位）を設定できることが明記されています。このことから、要件である「1時間ごと」の実行も同様にスケジュール設定で構成できると判断でき、正答C「旅程エントリスケジュールを
        1 時間ごとに実行するように設定します。」が最も適切な選択肢であることが裏付けられます。
- question_id: 117
  question_text: 'コンサルタントは、Amazon 53 がアクティブ化したキャンペーンを顧客の送信先システムに統合しています。

    宛先システムがセグメントに関するメタデータを見つけるために、処理用のこの情報は 53 のどのファイルに含まれますか?'
  choices:
    A: .txt ファイル
    B: jsonファイル
    C: .csvファイル
    D: .zipファイル
  correct_answer: B
  japanese_explanation: 'Amazon S3 上のファイルで、処理対象となるセグメントのメタデータが含まれるファイルは B. json ファイルです。json
    ファイルは、セグメントが Amazon S3 でアクティベートされた際に csv ファイルと共に生成されるメタデータファイルです。json ファイルには、セグメント名、セグメント
    ID、セグメントサイズ、セグメント属性、セグメントフィルタ、セグメントスケジュールなどの情報が含まれています。宛先システムはこのファイルを使用して、セグメントとそのプロパティを識別し、セグメントデータを宛先システムの対応するフィールドと照合することができます。参考資料:
    Salesforce Data Cloud Consultant 試験ガイド、Amazon S3 アクティベーション'
  ai_analysis:
    related_docs:
    - title: ファイル名の例 (SFTP、GCS、Azure)
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_file_name_examples.htm&language=ja&type=5
      reason: このドキュメントは、有効化ペイロードごとにセグメントメタデータが「JSON ファイル」として生成されることを明確に記述しており、ファイル名の例も示しているため、問題の正答を直接裏付ける最も強力な根拠となります。
      supporting_text: 'それぞれの有効化と (Data Cloud からエクスポートされたデータが含まれる) 有効化ペイロードごとに、セグメントメタデータ
        JSON ファイルが生成されます。ファイルには、セグメント ID と名前、レコード件数、公開更新種別、および有効化された各属性のデータ型が示された属性名が含まれます。


        セグメントメタデータの JSON ファイル名の例: TeenagersInNewyork_EmailCampaign_2023-07-30-17-55-45-216_segment_metadata.json'
    - title: クラウドファイルストレージの外部有効化プラットフォームファイル
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_package_external_activation_platform_find_metadata_reference.htm&language=ja&type=5
      reason: このドキュメントは、Amazon S3への有効化において「メタデータファイル」が生成され、特定のファイルパスに配置されることを説明しています。どのファイル形式かは明記されていませんが、メタデータファイル自体の存在を裏付けており、問題の背景を理解する上で役立ちます。
      supporting_text: "すべての成功ファイル、メタデータファイル、有効化出力ファイルが S3 に取り込まれます。 この情報を使用してファイルパス変数を解釈し、ファイルを見つけます。\n\
        ...\nActivation-Run-ID\t同じ有効化対象に公開する複数の顧客を区別するための 36 文字の文字列。複数のフォルダーは、外部有効化プラットフォームの同じ取引先\
        \ ID にデータを送信するさまざまな Data Cloud 組織を表します。メタデータファイルはここにあります。"
    - title: 外部有効化プラットフォームの JSON メタデータの利用状況と例
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_activation_toolkit_isv.htm&language=ja&type=5
      reason: このドキュメントのタイトル自体が「JSON メタデータ」について言及しており、外部有効化プラットフォームの設定においてJSONがメタデータを定義するために使用されることを示しています。これは、出力されるメタデータファイルもJSON形式であるという正答を補強する間接的な証拠となります。
      supporting_text: '外部有効化プラットフォームの JSON メタデータの利用状況と例

        ...出力がセグメントでグループ化されている場合、JSON で定義された outputPartitions はセグメントの公開ごとに適用されます。これは「有効化ジョブ」とみなされます。詳細は、「クラウドファイルストレージでの外部有効化プラットフォームセグメントの検索」を参照してください。'
    ai_verification:
      status: 一致
      justification: 正答である「B. jsonファイル」は、公式ドキュメント「ファイル名の例 (SFTP、GCS、Azure)」の記述と完全に一致します。このドキュメントには、「それぞれの有効化と...有効化ペイロードごとに、セグメントメタデータ
        JSON ファイルが生成されます。」と明確に記載されています。さらに、`_segment_metadata.json` という具体的なファイル名の例も示されており、セグメントに関するメタデータがJSONファイルで提供されることを直接的に裏付けています。
- question_id: 119
  question_text: 'Northern Trail Outfitters のマーケティング マネージャーは、データ クラウド セグメント インテリジェンスからの分析情報を活用して、マーケティングの投資収益率
    (ROI) を向上したいと考えています。

    これを設定するには、ユーザーはどの権限セットが必要ですか?'
  choices:
    A: クラウドマーケティングマネージャー
    B: データクラウド データアウェア スペシャリスト
    C: データクラウド管理者
    D: データクラウドユーザー
  correct_answer: C
  japanese_explanation: ''
  ai_analysis:
    related_docs:
    - title: Data Cloud からのデータの分析
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_business_intelligence_analytics.htm&language=ja&type=5
      reason: 問題文にある「データ クラウド セグメント インテリジェンス」と「マーケティングの投資収益率 (ROI) を向上」という目的が、このドキュメントで直接的に説明されているため。
      supporting_text: Segment Intelligence は、顧客が既存のセグメントをより適切に使用し、マーケティング活動の影響を高めることができるデータ駆動型アプリケーションです。Segment
        Intelligence は、Data Cloud と CRM Analytics を組み合わせて、複数のチャネル、エンゲージメント種別、コンバージョンソース
        (Commerce Cloud からの収益など) のセグメントに関するインサイトを表示します。アクション可能なパフォーマンスインサイトを使用してセグメントを構築および強化し、より関連性の高いオーディエンスとキャンペーンを使用してマーケティングの投資収益率
        (ROI) を向上させます。
    ai_verification:
      status: 判断不能
      justification: 関連ドキュメント「Data Cloud からのデータの分析」は、問題文のキーワードである「セグメント インテリジェンス」と「ROI向上」について説明しており、問題の背景を理解するのに役立つ。しかし、セグメントインテリジェンスを「設定」するために必要な特定の「権限セット」についての記述は、提供されたどのドキュメントにも含まれていない。そのため、正答が「C.
        データクラウド管理者」であることを直接的に裏付けることができず、正誤の判断は不可能である。
- question_id: 120
  question_text: セグメンテーションと計算されたインサイトでの時間ベースの操作にデータを使用するには、どのデータ ストリーム カテゴリを割り当てる必要がありますか?
  choices:
    A: 個人
    B: トランザクション
    C: 販売注文
    D: エンゲージメント
  correct_answer: B
  japanese_explanation: 'データストリームとは、Data Cloud に取り込まれ、データモデルにマッピングされるデータのソースです。データストリームには様々なカテゴリがあり、Data
    Cloud におけるデータの処理方法と使用方法を決定します。

    トランザクションデータストリームは、日付範囲によるフィルタリング、期間による集計、イベント発生までの時間指標の計算など、セグメンテーションや計算によるインサイトにおける時間ベースの操作に使用されます。トランザクションデータストリームは通常、購入、クリック、訪問など、タイムスタンプと値が関連付けられたイベントデータに使用されます。参考資料：データストリーム、データストリームのカテゴリ'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供されたドキュメントには、セグメンテーションや計算済みインサイトで時間ベースの操作を行うために特定のデータストリームカテゴリ（プロファイル、トランザクション、エンゲージメントなど）を割り当てる必要があるという直接的な記述が見つかりませんでした。したがって、提示された情報のみでは正答が「トランザクション」であることを検証できません。
- question_id: 121
  question_text: 'コンサルタントは、複数のDLOに基づいてデータグラフを作成する必要があります。

    これを実現するためにコンサルタントはどのようなステップを踏むべきでしょうか?'
  choices:
    A: データアクションを使用して、DLOデータでデータグラフを更新します。
    B: DLOS を DMOS にマップし、これをデータ グラフで使用します。
    C: DLO をデータ グラフに直接マップします。
    D: DLO を複数の DMO にバッチ変換し、データ グラフでアクティブ化します。
  correct_answer: B
  japanese_explanation: '複数のデータレイクオブジェクト（DLO）に基づくデータグラフを作成するには、コンサルタントはDLOをデータモデルオブジェクト（DMO）にマッピングし、データグラフで使用する必要があります。その理由は次のとおりです。

    データグラフを理解する

    Salesforce Data Cloud のデータ グラフは、エンティティ (顧客、アカウント、注文など) とその属性間の関係を表します。

    これは、統合されたプロファイルと関連データに標準化された構造を提供するデータ モデル オブジェクト (DMO) を使用して構築されます。

    DLO を DMO にマッピングする理由は何ですか?

    DLOとDMOの役割：

    DLO は、Data Cloud に取り込まれた生のデータ ソースです。

    DMO は、ID 解決と統合プロファイルに使用される標準化されたオブジェクトです。

    DLO を DMO にマッピングすると、生のデータがデータ グラフに適した構造化された形式に変換されます。

    データグラフの構築:

    DLO が DMO にマップされると、コンサルタントは DMO を使用して関係を定義し、データ グラフを構築できます。

    このアプローチにより、統一されたデータ モデルとの一貫性と整合性が確保されます。

    その他のオプションはあまり適していません:

    A . データ アクションを使用して、DLO データでデータ グラフを更新します。データ アクションは、データ グラフの構築ではなく、ワークフローのトリガーに使用されます。

    C . DLO をデータ グラフに直接マップする: DLO はデータ グラフに直接マップできないため、最初に DMO に変換する必要があります。

    D. DLO を複数の DMO にバッチ変換し、データ グラフでアクティブ化します。これは、DLO を DMO にマッピングするだけで十分な場合は、過度に複雑で不要です。

    データグラフを作成する手順

    ステップ1: DLOをDMOにマッピングする

    「データ クラウド」>「データ ストリーム」に移動し、DLO の関連フィールドを対応する DMO にマップします。

    ステップ2: 関係を定義する

    データ モデル タブを使用して、DMO 間の関係 (個人とアカウントのリンクなど) を定義します。

    ステップ3: データグラフを構築する

    マップされた DMO を使用してデータ グラフを作成し、ノード (エンティティ) とエッジ (リレーションシップ) を定義します。

    ステップ4: グラフを検証する

    データ グラフをテストして、目的の関係とデータ フローが正確に表現されていることを確認します。

    結論

    コンサルタントは、DLO を DMO にマッピングし、それをデータ グラフで使用して、エンティティ間の関係を構築するための構造化された一貫性のあるアプローチを確保する必要があります。'
  ai_analysis:
    related_docs:
    - title: データの準備とモデル化
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_prepare_and_model_data.htm&language=ja&type=5
      reason: このドキュメントは、データグラフがDMO（データモデルオブジェクト）から作成されること、そしてそのDMOはDLO（データレークオブジェクト）をマッピングすることで作成されるという、問題解決に必要な一連のプロセスを明確に記述しているため。
      supporting_text: データグラフは、データモデルオブジェクト (DMO) の正規化されたテーブルデータを結合し、新しいデータのマテリアライズドビューに変換します。...すべてのデータストリームによって取り込まれたデータは、データレークオブジェクト
        (DLO) に書き込まれます。データストリームを作成したら、DLO をデータモデルオブジェクト (DMO) に関連付ける必要があります。
    - title: データマッピング
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_mapping.htm&language=ja&type=5
      reason: データグラフの構成要素であるDMOを作成するための必須ステップとして、DLOからDMOへのマッピングプロセスが必須であることを詳細に説明しているため。
      supporting_text: すべてのデータストリームによって取り込まれたデータは、データレークオブジェクト (DLO) に書き込まれます。データストリームを作成したら、DLO
        をデータモデルオブジェクト (DMO) に関連付ける必要があります。
    - title: Data Cloud のデータオブジェクト
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_lake_objects.htm&language=ja&type=5
      reason: Data Cloud内のデータオブジェクトの基本的な関係性、特に「DLOはDMOにマッピングされる」という核心部分を簡潔に説明しており、正答のロジックを裏付けているため。
      supporting_text: "オブジェクト\t説明\tメモ\nデータモデルオブジェクト (DMO)\tデータストリーム、インサイト、その他のソースから作成されたデータのハーモナイズされたグルーピング。\t\
        DLO は DMO にマッピングされます。"
    ai_verification:
      status: 一致
      justification: 問題は複数のDLOからデータグラフを作成する方法を問うています。正答は「DLOをDMOにマッピングし、そのDMOをデータグラフで使用する」という手順を示しています。公式ドキュメント「データの準備とモデル化」には、「データグラフは、データモデルオブジェクト
        (DMO) の正規化されたテーブルデータを結合...」と記載されており、データグラフがDMOを入力とすることが明確です。さらに、複数のドキュメントで、DMOを作成するにはDLOをマッピングする必要があることが一貫して説明されています。したがって、「DLO
        -> DMO -> データグラフ」というプロセスを示す正答は、公式ドキュメントの内容と完全に一致します。
- question_id: 122
  question_text: 'あるクライアントは、Salesforce CRMのカスタムオブジェクトからロイヤルティデータをインポートしたいと考えています。このオブジェクトには、ホテルポイントと航空会社ポイントのポイント残高が同一レコード内に格納されています。クライアントは、これらのポイントシステムを2つの別々のレコードに分割することで、追跡と処理を効率化したいと考えています。

    このシナリオではコンサルタントは何を推奨すべきでしょうか?'
  choices:
    A: データ ソース オブジェクトを複製します。
    B: バッチ変換を使用して 2 番目のデータ レイク オブジェクトを作成します。
    C: Salesforce CRM でジャンクション オブジェクトを作成し、取り込み戦略を変更します。
    D: データレイク オブジェクトからデータキットを作成し、同じ Data Cloud 組織にデプロイします。
  correct_answer: B
  japanese_explanation: バッチ変換は、既存のデータレイクオブジェクトに基づいて新しいデータレイクオブジェクトを作成し、それらに変換を適用できる機能です。これは、データモデルやビジネス要件に合わせてデータを分割、結合、または再形成する場合に役立ちます。この場合、コンサルタントはバッチ変換を使用して、元のロイヤルティデータオブジェクトから航空会社のポイントのみを含む2つ目のデータレイクオブジェクトを作成できます。元のオブジェクトは、ホテルのポイントのみを含むように変更できます。これにより、クライアントはポイントシステムごとに2つの個別のレコードを作成し、それらを適切に追跡および処理できます。参考資料：バッチ変換、バッチ変換の作成
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供されたドキュメント候補には、Data Cloudの「バッチ変換 (Batch Data Transform)」機能を使用して、データレイクオブジェクト(DLO)のレコードを加工・分割し、新しいDLOを作成するという具体的なプロセスについて記述されていません。問題のシナリオは、Data
        Cloudのデータ変換機能の典型的なユースケースですが、その根拠となる情報が参照ドキュメント内に見当たらないため、正答の妥当性を判断できません。
- question_id: 123
  question_text: セグメントを再度使用する目的でセグメントのアクティベーションを一時停止するには、ユーザーは何をすればよいですか?
  choices:
    A: セグメントを非アクティブ化します。
    B: セグメントを削除します。
    C: アクティベーションをスキップします。
    D: 公開スケジュールを停止します。
  correct_answer: A
  japanese_explanation: '正解はAです。セグメントを非アクティブ化します。不要になったセグメントは、Data Cloudから非アクティブ化でき、選択したすべてのターゲットに適用されます。非アクティブ化されたセグメントはパブリッシュされなくなりますが、いつでも再アクティブ化できます1。このオプションを使用すると、ユーザーはセグメントのアクティブ化を一時停止し、そのセグメントを再度使用できるようになります。

    その他のオプションは、次の理由により正しくありません。

    B. セグメントを削除します。このオプションを選択すると、セグメントはData Cloudから完全に削除され、元に戻すことはできません。このオプションを選択した場合、ユーザーはセグメントを再度使用できなくなります。

    C . アクティベーションをスキップします。このオプションは、セグメントの現在のアクティベーションサイクルをスキップしますが、将来のアクティベーションサイクルには影響しません3。このオプションは、セグメントのアクティベーションを無期限に停止するものではありません。

    D . 公開スケジュールを停止します。このオプションは、選択したターゲットへのセグメントの公開を停止しますが、セグメントを非アクティブ化しません。このオプションは、セグメントのアクティブ化を完全に一時停止するものではありません。

    参照：

    1: Salesforceヘルプの「セグメントの無効化」の記事

    2: Salesforceヘルプのセグメント記事を削除する

    3: Salesforceヘルプのアクティベーション記事をスキップする

    4: Salesforceヘルプの公開スケジュール記事を停止する'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 提供された公式ドキュメントには、Data Cloudのセグメントのアクティベーションを一時停止する具体的な方法（非アクティブ化、削除、スキップ、公開スケジュールの停止など）に関する記述が含まれていません。ドキュメントはData
        Cloudのアーキテクチャやクロスプロダクトソリューションなど、高レベルの概念を説明していますが、問題で問われているセグメントの操作に関する詳細情報が不足しているため、正答が「セグメントを非アクティブ化します。」であることを検証できません。
- question_id: 124
  question_text: 'アウトドアライフスタイル衣料ブランドのNorthern Trail Outfitters（NTO）は、最近、新たな事業を開始しました。この新事業は、グルメキャンプフードを専門としています。ビジネス上の理由とセキュリティ上の理由から、NTOはすべてのデータクラウドデータをブランドごとに分離して管理することが重要だと考えています。

    ブランドごとにデータを分離するという NTO の要望を最もよくサポートする機能はどれですか?'
  choices:
    A: 各ブランドのデータストリーム
    B: 各ブランドのデータモデルオブジェクト
    C: ブランドごとのデータスペース
    D: 各ブランドのデータソース
  correct_answer: C
  japanese_explanation: 'データスペースは、ブランド、地域、製品、事業部門など、さまざまな基準でデータを分離・整理できる論理コンテナです1。データスペースは、データアクセス、セキュリティ、ガバナンスの管理、そしてクラウド間のデータ統合とアクティベーションに役立ちます2。NTOの場合、データスペースはブランドごとにデータを分離したいという要望をサポートし、アウトドアライフスタイル衣料とグルメキャンプフード事業それぞれに異なるデータモデル、ルール、インサイトを提供できます2。また、データスペースは、NTOがさまざまなブランドに適用される可能性のあるデータプライバシーおよびセキュリティ規制を遵守するのにも役立ちます3。他の選択肢は、データスペースと同じレベルのデータ分離と整理を提供しないため、正しくありません。データストリームは、さまざまなソースからデータクラウドにデータを取り込むために使用されますが、ブランドごとにデータを分離するものではありません4。データモデルオブジェクトは、データの構造と属性を定義するために使用されますが、ブランドごとにデータを分離するものではありません5。データソースは、データの出所と種類を識別するために使用されますが、ブランドごとにデータを分割するものではありません。参考資料:
    データ スペースの概要、データ スペースの作成、データ クラウドにおけるデータのプライバシーとセキュリティ、データ ストリームの概要、データ モデル オブジェクトの概要、[データ
    ソースの概要]'
  ai_analysis:
    related_docs: []
    ai_verification:
      status: 判断不能
      justification: 正解の選択肢である「データスペース」は、Data Cloudにおいてブランド、地域、部署などの単位でデータ、メタデータ、設定を論理的に分離するための機能であり、問題文の「ビジネス上の理由とセキュリティ上の理由から、すべてのデータクラウドデータをブランドごとに分離して管理する」という要件に完全に合致します。しかし、提供された公式ドキュメント候補の中には、「データスペース」の機能や目的を直接説明し、正解を裏付けるものが存在しません。したがって、提供された情報のみに基づいて正解の妥当性を検証することはできません。
- question_id: 125
  question_text: 'ある顧客では、複数のチームメンバーがセグメントオーディエンスを作成しており、それぞれが異なるタイムゾーンで勤務しています。そのうちの1人は、組織のタイムゾーン設定と一致する太平洋標準時の本社で勤務しています。

    別のチームメンバーは東部標準時でリモート勤務しています。

    セグメントとアクティベーション スケジュール領域で自分のホーム タイム ゾーンが表示されるのはどのユーザーですか?'
  choices:
    A: 太平洋時間帯のチーム メンバー。
    B: 東部標準時のチームメンバー。
    C: どちらのチーム メンバーも、Data Cloud ではすべてのスケジュールが GMT で表示されます。
    D: チームメンバー両方。データクラウドは、ログインしたユーザーのタイムゾーンに合わせてセグメントとアクティベーションのスケジュールを調整します。
  correct_answer: D
  japanese_explanation: '正解はD（両方のチームメンバー）です。Data Cloudは、セグメントとアクティベーションのスケジュールをログインユーザーのタイムゾーンに合わせて調整します。Data
    Cloudは、ログインユーザーのタイムゾーン設定を使用して、セグメントとアクティベーションのスケジュールを表示します。つまり、組織のタイムゾーン設定や他のチームメンバーの所在地に関係なく、各ユーザーのホームタイムゾーンでスケジュールが表示されます。この機能は、異なるタイムゾーン間でセグメントとアクティベーションをスケジュールする際の混乱やエラーを回避するのに役立ちます。その他の選択肢は、Data
    Cloudのタイムゾーン処理方法を反映していないため、正しくありません。太平洋標準時（Pacific Time Zone）のチームメンバーは、個人のタイムゾーン設定が組織のタイムゾーン設定と一致しない限り、組織のタイムゾーン設定と同じタイムゾーンを表示しません。東部標準時（Eastern
    Time Zone）のチームメンバーは、個人のタイムゾーン設定が組織のタイムゾーン設定と一致しない限り、組織のタイムゾーン設定でスケジュールを表示しません。Data
    CloudはすべてのスケジュールをGMTではなく、ユーザーのローカルタイムゾーンで表示します。参考資料：

    * データクラウドのタイムゾーン

    * ユーザーと組織のデフォルトのタイムゾーンを変更する

    * Salesforce、Google、Outlook のタイムゾーン設定を変更する

    * SalesforceのDateTimeフィールドとタイムゾーン設定'
  ai_analysis:
    related_docs:
    - title: セグメントのタイムゾーン
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_update_segment_time_zone.htm&language=ja&type=5
      reason: このドキュメントは、セグメントと有効化のスケジュール表示が、ログインしているユーザー個人のタイムゾーンに合わせて調整されることを明確に説明しています。これが、異なるタイムゾーンのチームメンバーがそれぞれ自分のタイムゾーンでスケジュールを確認できるという、問題の正答の直接的な根拠となります。
      supporting_text: セグメント項目と有効化項目には、ユーザーのタイムゾーンで公開スケジュールの開始日時が表示されます。
    - title: Data Cloud のタイムゾーン
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_time_zones.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudの基本的なタイムゾーン設定がSalesforce組織のタイムゾーンに基づいていることを説明しています。UI上ではユーザーのタイムゾーンが優先されますが、バックエンドでの処理の基準となる組織タイムゾーンの概念を理解する上で関連性があります。
      supporting_text: Data Cloud では、セグメントと有効化の公開と更新時に Salesforce で設定されているタイムゾーンが使用されます。セグメントキャンバスでセグメントに追加された日付と時刻でも
        Salesforce のタイムゾーンが使用されます。
    ai_verification:
      status: 一致
      justification: 公式ドキュメント「セグメントのタイムゾーン」に、「セグメント項目と有効化項目には、ユーザーのタイムゾーンで公開スケジュールの開始日時が表示されます。」と記載されています。これは、Data
        CloudのUIが、ログインしている各ユーザー（太平洋標準時のユーザーと東部標準時のユーザー）のタイムゾーンに合わせてスケジュールの日時を調整して表示することを示しており、正答である「チームメンバー両方。データクラウドは、ログインしたユーザーのタイムゾーンに合わせてセグメントとアクティベーションのスケジュールを調整します。」と完全に一致します。
- question_id: 126
  question_text: 'Cloud Kicks は顧客から忘れ去られるリクエストを受け取りました。

    この要求に応えるために、コンサルタントは Data Cloud をどのように使用すべきですか 2 つの方法のうちどれですか?

    2つの回答を選択してください'
  choices:
    A: 受信データ ストリームからデータを削除し、完全更新を実行します。
    B: ヘッダーなしファイルに個人 ID を追加し、ファイルからの削除機能を使用します。
    C: データ エクスプローラーを使用して、個人を特定し、手動で削除します。
    D: Consent API を使用して処理を抑制し、個人および関連レコードをソース データ ストリームから削除します。
  correct_answer: B,D
  japanese_explanation: '顧客からの忘れられるリクエストに応えるために、コンサルタントは Data Cloud を次の 2 つの方法で使用する必要があります。

    * ヘッダーなしファイルに個人IDを追加し、ファイルから削除する機能を使用します。このオプションを使用すると、コンサルタントはIDを記載したCSVファイルをアップロードすることで、複数の個人をData
    Cloudから削除できます1。削除プロセスは非同期で行われ、完了するまでに最大24時間かかる場合があります1。

    * Consent API を使用して処理を抑制し、個人および関連レコードをソースデータストリームから削除します。このオプションを使用すると、コンサルタントは
    Consent API2 を使用して Data Cloud 内の個人プロファイルのデータ削除リクエストを送信できます。データ削除リクエストは、指定された個人エンティティと、そのエンティティの識別属性と個人
    ID 属性2 の間に関係が定義されているすべてのエンティティを削除します。削除プロセスは、完全な削除を確実にするために、30 日、60 日、90 日ごとに再処理されます2。その他のオプションは、以下の理由により正しくありません。

    * 受信データ ストリームからデータを削除し、完全更新を実行しても、Data Cloud 内の既存のデータは削除されず、ソース システム 3 からの新しいデータのみが削除されます。

    * データエクスプローラーを使用して個人を特定し、手動で削除しても、ソースデータストリームから関連レコードは削除されず、データクラウド内の個人エンティティのみが削除されることに注意してください。参考資料：

    * データクラウドから個人を削除する

    * データ削除または忘れられる権利の要求

    * データクラウドのデータ更新

    * [データエクスプローラー]'
  ai_analysis:
    related_docs:
    - title: データ主体の権利
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_subject_rights.htm&language=ja&type=5
      reason: このドキュメントは、問題の中心である「忘れ去られるリクエスト」が「データの削除または忘れられる権利 (RTBF)」に該当することを明記し、その要求に「Salesforce
        同意 API」を使用することを直接説明しているため、正答Dの根拠となります。
      supporting_text: '次に、Data Cloud の規制の例を示します。


        データの削除または忘れられる権利 (RTBF)

        処理の制限 (RofP)

        データのアクセスおよびエクスポート


        Salesforce 同意 API を使用して、すべてのデータ主体の権利の要求を送信します。'
    - title: 個人 ID の取得
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_consent_obtaining_individual_id.htm&language=ja&type=5
      reason: 正答Bで言及されている「個人 ID」は、削除対象の個人を特定するための重要なキーです。このドキュメントは、その「個人 ID」の取得方法を説明しており、忘れられる権利の要求を処理する上での前提知識を提供するため、関連性が高いです。
      supporting_text: 'Data Cloud で個人 ID を取得する方法について説明します。


        個人 ID は、セグメンテーション、ソースシステム、クエリ API の 3 つの異なる方法で取得できます。'
    ai_verification:
      status: 一致
      justification: 問題はData Cloudにおける「忘れ去られるリクエスト」への対応方法を問うています。公式ドキュメント「データ主体の権利」には、「データの削除または忘れられる権利
        (RTBF)」の要求に「Salesforce 同意 API」を使用することが明記されており、これは正答D「Consent API を使用して処理を抑制し、個人および関連レコードをソース
        データ ストリームから削除します。」と完全に一致します。また、もう一つの正答B「ヘッダーなしファイルに個人 ID を追加し、ファイルからの削除機能を使用します。」はData
        Cloudにおけるデータ削除の具体的な方法の一つであり、その際に必須となる「個人 ID」についてドキュメント「個人 ID の取得」で解説されています。したがって、提供されたドキュメントは正答を強く裏付けています。
- question_id: 127
  question_text: 'データ ソースを切断する前に削除する必要がある 2 つの依存関係はどれですか。

    2つの回答を選択してください'
  choices:
    A: 活性化対象
    B: セグメント
    C: アクティベーション
    D: データストリーム
  correct_answer: B,D
  japanese_explanation: '* データクラウドの依存関係:

    データ ソースを切断する前に、データの整合性の問題を防ぐためにすべての依存関係を削除する必要があります。

    参照：

    * 依存関係の特定:

    セグメント: ソースのデータを使用しているセグメントは削除するか、再割り当てする必要があります。

    データ ストリーム: データ ストリームはデータ ソースに直接依存するため、切断されている必要があります。

    * 依存関係を削除する手順:

    セグメントを削除:

    Salesforce Data Cloud のセグメンテーション インターフェースに移動します。

    データ ソースに依存するセグメントを識別して削除します。

    データ ストリームを切断します:

    データ ストリームの設定に移動します。

    ソースに関連付けられたデータ ストリームを見つけて切断します。

    * 実用的な応用:

    例: 従来の CRM システムを切断する準備をするときは、そのデータを使用しているすべてのセグメントとデータ ストリームが適切に削除または移行されていることを確認します。'
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: このドキュメントはData Cloudの全体像を説明しており、「データソース」、「セグメント化」といった問題に関連するコンポーネントに言及しています。データソースが他のコンポーネントの基盤であることを示唆していますが、削除の依存関係に関する直接的な記述はありません。
      supporting_text: 'すべてのデータソースを接続します。

        データを標準データモデルにハーモナイズします。

        ID 解決ルールセットを使用してデータを統合します。

        インサイトを使用してデータの照会および分析を行います。

        AI を使用して行動を予測します。

        データをセグメント化および有効化し、さまざまなチャネルで使用して、パーソナライズした環境を作成します。'
    - title: データスペースへの Salesforce CRM バンドルのリリース
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_deploy_a_salesforce_crm_bundle_to_a_data_space.htm&language=ja&type=5
      reason: このドキュメントでは、データソースであるSalesforce CRMから「データストリーム」を作成する手順が説明されています。これにより、データソースとデータストリームの間に直接的な依存関係があることがわかります。データソースを削除するには、それに紐づくデータストリームを先に削除する必要があるという推測の根拠となります。
      supporting_text: 'Data Cloud の [データストリーム] タブに移動して、[新規] をクリックします。

        [Salesforce CRM] を選択し、[次へ] をクリックします。

        Salesforce 組織を選択します。Data Cloud に接続されている Salesforce 組織が 1 つしかない場合は、それがデフォルトで選択されます。'
    ai_verification:
      status: 判断不能
      justification: 提供された公式ドキュメントには、データソースを切断する前に『データストリーム』と『セグメント』を削除する必要がある、という依存関係について直接的かつ明確に記述した箇所が見つかりませんでした。正解はData
        Cloudのアーキテクチャ上の制約として正しい知識ですが、提示されたドキュメントだけを根拠として正解を導き出すことは困難です。
- question_id: 128
  question_text: データ モデル内に矛盾する情報がある場合、アイデンティティ解決では統合された個人の属性をどのように選択するのでしょうか?
  choices:
    A: 追加の接触点を作成する
    B: 調整ルールを活用する
    C: 追加のルールセットを作成する
    D: マッチルールを活用する
  correct_answer: B
  japanese_explanation: アイデンティティ解決とは、異なるソースからのデータを照合および統合することで、個人の統合プロファイルを作成するプロセスです。データモデル内に、同一人物の異なる名前、住所、電話番号など、矛盾する情報が存在する場合、アイデンティティ解決では調整ルールを活用して、統合プロファイルに最も正確で完全な属性を選択します。調整ルールは、最新性、頻度、ソースの優先度、完全性などの基準に基づいて矛盾を解決する方法を定義する設定可能なルールです。例えば、調整ルールでは、統合プロファイルに最も最近使用した名前や最も頻繁に使用される電話番号を選択するように指定できます。調整ルールは、属性レベルまたは連絡先レベルで適用できます。参考資料：アイデンティティ解決、調整ルール、Salesforce
    Data Cloud 試験問題
  ai_analysis:
    related_docs:
    - title: Salesforce Data Cloud について
      url: https://help.salesforce.com/s/articleView?id=data.c360_a_data_cloud.htm&language=ja&type=5
      reason: このドキュメントは、Data Cloudの機能概要の一部として、データの統合プロセスに「ID 解決ルールセット」が使用されることを記載しています。問題は、アイデンティティ解決において矛盾する情報をどのように扱うかを問うており、このプロセスはID解決ルールセットの一部である「調整ルール」によって管理されます。したがって、このドキュメントは問題の主題であるアイデンティティ解決に直接関連しています。
      supporting_text: ID 解決ルールセットを使用してデータを統合します。
    ai_verification:
      status: 判断不能
      justification: 提供されたドキュメントには「ID 解決ルールセットを使用してデータを統合します」という記述があり、問題のテーマであるアイデンティティ解決に触れています。しかし、そのルールセットが「マッチルール」と「調整ルール」から構成されること、そして属性値が競合した場合に「調整ルール」が使用されるという、正答を直接裏付ける具体的な記述が含まれていません。したがって、提供されたドキュメントのみでは正答Bが正しいと断定することは困難です。
